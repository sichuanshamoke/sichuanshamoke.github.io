<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="超分辨率," />





  <link rel="alternate" href="/atom.xml" title="Hello World" type="application/atom+xml" />






<meta name="description" content="超分辨率第八章-SR&amp;transformer 超分辨率中的transformer-应用于MRI 文献一：3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution：ICASSP 2022会议 文献二：Adjacent slices feature transformer network for">
<meta property="og:type" content="article">
<meta property="og:title" content="超分辨率第八章-SR&amp;transformer">
<meta property="og:url" content="http://example.com/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&transformer/index.html">
<meta property="og:site_name" content="Hello World">
<meta property="og:description" content="超分辨率第八章-SR&amp;transformer 超分辨率中的transformer-应用于MRI 文献一：3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution：ICASSP 2022会议 文献二：Adjacent slices feature transformer network for">
<meta property="og:locale">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADWF9f.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pAD46rF.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADhPl8.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADhnf0.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADhlXF.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADhap6.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADh6AA.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/29/pA0qj3R.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/29/pA0LACd.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADRO1O.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADWuEn.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/01/pADW3gU.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/02/pADxM3F.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/28/pA0d3LD.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/09/27/pAlfQeA.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/09/27/pAlfsYV.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/28/pA0wgBD.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/28/pA0wsc6.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/28/pA0DgBT.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/02/pADzjFP.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/11/02/pArCcp6.png">
<meta property="article:published_time" content="2024-10-28T02:26:24.000Z">
<meta property="article:modified_time" content="2024-11-04T14:07:22.650Z">
<meta property="article:author" content="Shamoke">
<meta property="article:tag" content="超分辨率">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s21.ax1x.com/2024/11/01/pADWF9f.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/2024/10/28/超分辨率第八章-SR&transformer/"/>





  <title>超分辨率第八章-SR&transformer | Hello World</title>
  








<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a target="_blank" rel="noopener" href="https://github.com/sichuanshamoke" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hello World</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Studying and Recording</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>
    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="沙漠客">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">超分辨率第八章-SR&transformer</h1>
        

        <div class="post-meta">
          
          
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-10-28T10:26:24+08:00">
                2024-10-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2024-11-04T22:07:22+08:00">
                2024-11-04
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/" itemprop="url" rel="index">
                    <span itemprop="name">硕士阶段学习笔记(入门阶段)</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index">
                    <span itemprop="name">模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&transformer/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&transformer/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  26
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="超分辨率第八章-SR-amp-transformer"><a href="#超分辨率第八章-SR-amp-transformer" class="headerlink" title="超分辨率第八章-SR&amp;transformer"></a>超分辨率第八章-SR&amp;transformer</h1><blockquote>
<p><strong>超分辨率中的transformer-应用于MRI</strong></p>
<p>文献一：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9746092">3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution</a>：ICASSP 2022会议</p>
<p>文献二：<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S1746809421009368">Adjacent slices feature transformer network for single anisotropic 3D brain MRI image super-resolution</a>：《Biomedical Signal Processing and Control》 期刊，2022 </p>
</blockquote>
<span id="more"></span>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="1-attention"><a href="#1-attention" class="headerlink" title="1.attention"></a>1.attention</h3><ul>
<li><p>参考视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV15v411W78M?spm_id_from=333.788.videopod.sections&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">Transformer中Self-Attention以及Multi-Head Attention详解</a></p>
</li>
<li><p><strong>通过 Query (查询对象) 这个信息从 Values （被查询对象）中筛选出重要信息，简单点说，就是计算 Query 和 Values 中每个信息的相关程度</strong>。</p>
</li>
<li><p>通过上图，Attention 通常可以进行如下描述，表示为将 Query(Q) 和 key-value pairs（<strong>把 Values 拆分成了键值对</strong>) 映射到输出上，其中 query、每个 key、每个 value 都是向量，输出是 <strong>V （被查询对象）中所有 values 的加权</strong>，其中<strong>权重是由 Query 和每个 key 计算出来</strong>的，计算方法分为三步：</p>
<ul>
<li>第一步：Query与每一个Key计算相似性得到相似性评分s</li>
<li>第二步：将s评分进行softmax转换成[0,1]之间的概率分布</li>
<li>第三步：将[a1,a2,a3…an]作为权值矩阵对Value进行加权求和得到最后的Attention值</li>
<li><script type="math/tex; mode=display">A t t e n t i o n ( Q , K , V ) = s o f t m a x ( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } ) V</script><ul>
<li><p><img src="https://s21.ax1x.com/2024/11/01/pADWF9f.png" alt="pADWF9f.png"></p>
<p><img src="https://s21.ax1x.com/2024/11/01/pAD46rF.png" alt="pAD46rF.png"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>多头注意力机制</p>
<ul>
<li><p>首先将q、k、v序列进行均分，分为head组</p>
<ul>
<li><p><img src="https://s21.ax1x.com/2024/11/01/pADhPl8.png" alt="pADhPl8.png"></p>
</li>
<li><p><img src="https://s21.ax1x.com/2024/11/01/pADhnf0.png" alt="pADhnf0.png"></p>
</li>
</ul>
</li>
<li><p>分别计算各head的注意力</p>
<ul>
<li><img src="https://s21.ax1x.com/2024/11/01/pADhlXF.png" alt="pADhlXF.png"></li>
</ul>
</li>
<li><p>将各head的值进行拼接</p>
<ul>
<li><img src="https://s21.ax1x.com/2024/11/01/pADhap6.png" alt="pADhap6.png"></li>
</ul>
</li>
<li><p>使用Wo进行融合</p>
<ul>
<li><img src="https://s21.ax1x.com/2024/11/01/pADh6AA.png" alt="pADh6AA.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-通道注意力机制与空间注意力机制"><a href="#2-通道注意力机制与空间注意力机制" class="headerlink" title="2.通道注意力机制与空间注意力机制"></a>2.通道注意力机制与空间注意力机制</h3><ul>
<li>通道注意力机制<ul>
<li>通道注意力机制的代表模型是：压缩和激励网络(Squeeze-and-Excitation Networks,SENet)</li>
<li>SENet分为压缩和激励两个部分，其中压缩部分的目的是对全局空间信息进行压缩，然后在通道维度进行特征学习，形成各个通对道的重要性，最后通过激励部分对各个通道进行分配不同权重的。</li>
<li><img src="https://s21.ax1x.com/2024/10/29/pA0qj3R.png" alt="pA0qj3R.png"></li>
<li>上图是SE模块的结构，在压缩部分，输入的元素特征图的维度是H×WxC，H、W和C分别代表高度、宽度和通道数。压缩部分的功能是将维数从H×W×C压缩至1×1×C，即把H×W压缩为1×1维，<strong>这个过程由空间维度的全局平均池化实现</strong>。</li>
<li>在激励部分，需要将压缩部分得到的1×1×C的维度融入全连接层，预测各个通道的重要程度，然后再激励到前面特征图对应通道上进行操作。<strong>采用简单的门控机制与Sigmoid激活函数</strong>。</li>
</ul>
</li>
<li>空间注意力机制<ul>
<li><img src="https://s21.ax1x.com/2024/10/29/pA0LACd.png" alt="pA0LACd.png"></li>
<li>首先，对一个尺寸为 H×W×C的输入特征图F进行<strong>通道维度的全局最大池化和全局平均池化</strong>，得到两个 H×W×1 的特征图（在通道维度进行池化，压缩通道大小，便于后面学习空间的特征）</li>
<li>然后，将全局最大池化和全局平均池化的结果，按照通道拼接(concat)，得到特征图尺寸为HxWx2，</li>
<li>最后，对拼接的结果进行卷积操作，得到特征图尺寸为 HxWx1</li>
<li>接着通过Sigmoid激活函数 ，得到空间注意力权重矩阵 </li>
</ul>
</li>
</ul>
<h3 id="3-transformer"><a href="#3-transformer" class="headerlink" title="3.transformer"></a>3.transformer</h3><ul>
<li>参考视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1UL411g7aX/?spm_id_from=333.1365.top_right_bar_window_default_collection.content.click&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">手推transformer</a><ul>
<li>2017年提出，分为encoder与decoder两个部分</li>
<li>input embedding：可以将高维的离散输入数据转换为低维的连续向量表示</li>
<li>位置编码（Positional Encoding）：由于Transformer没有内置的序列位置信息，它需要额外的位置编码来表达输入序列中单词的位置顺序。</li>
<li>多头注意力（Multi-Head Attention）：Transformer中的自注意力机制被扩展为多个注意力头，每个头可以学习不同的注意权重，以更好地捕捉不同类型的关系。多头注意力允许模型并行处理不同的信息子空间。</li>
<li><img src="https://s21.ax1x.com/2024/11/01/pADRO1O.png" alt="pADRO1O.png"></li>
</ul>
</li>
</ul>
<h3 id="4-vision-transformer"><a href="#4-vision-transformer" class="headerlink" title="4.vision transformer"></a>4.vision transformer</h3><ul>
<li><p>参考视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Jh411Y7WQ?spm_id_from=333.788.videopod.sections&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">Vision Transformer(vit)网络详解</a></p>
</li>
<li><p>简称vit，2020年提出</p>
</li>
<li><p>网络结构</p>
<ul>
<li>patch embedding&amp;Linear Projection of Flattened Patches：<ul>
<li><strong>将输入的2维图像（3通道）分割为多个小块（patches）(若干个不重叠的 patch)，并将每个小块映射到特定维度的嵌入（embedding）向量空间中，原来的一个图像块patch（3通道）映射成特征图的一个像素点（值）</strong></li>
<li>将输入图片(224x224)按照16x16大小的Patch进行划分，划分后会得到$(224/16)^2=14^2=196$个Patches。接着通过线性映射将每个Patch映射到一维向量中，以ViT-B/16为例，每个Patche数据shape为<strong>[16, 16, 3]</strong>，<strong>每个 patch 最终会被映射到 768 维的向量空间</strong><ul>
<li>输入图片<224，224，3>经过卷积核（16*16）得到<14，14，768>，再经过展平得到<196，768></196，768></14，14，768></224，224，3></li>
</ul>
</li>
</ul>
</li>
<li>class token与position embedding<ul>
<li>token与分类token拼接得到<197，768>，之后再与位置embedding相加得到具有分类与位置信息的token</197，768></li>
</ul>
</li>
<li>encoder：12个编码器堆叠而成，进行多头自注意力计算</li>
<li>extract class token：通过编码器之后，在进入MLP head之前，需要将分类token提取出来，此时<197，768> -&gt; <1，768></1，768></197，768></li>
<li>MLP Head：原论文中说在训练ImageNet21K时是由<code>Linear</code>+<code>tanh激活函数</code>+<code>Linear</code>组成。但是迁移到ImageNet1K上或者你自己的数据上时，只用一个<code>Linear</code>即可。</li>
<li><img src="https://s21.ax1x.com/2024/11/01/pADWuEn.png" alt="pADWuEn.png"></li>
</ul>
</li>
<li><p>流程</p>
<ul>
<li><strong>Q,K,V的生成使用全连接层模拟</strong></li>
<li><img src="https://s21.ax1x.com/2024/11/01/pADW3gU.png" alt="pADW3gU.png"></li>
</ul>
</li>
<li><p>模型参数</p>
<ul>
<li><img src="https://s21.ax1x.com/2024/11/02/pADxM3F.png" alt="pADxM3F.png"></li>
</ul>
</li>
</ul>
<h3 id="5-vit代码"><a href="#5-vit代码" class="headerlink" title="5.vit代码"></a>5.vit代码</h3><h4 id="①patch-embedding块"><a href="#①patch-embedding块" class="headerlink" title="①patch embedding块"></a>①patch embedding块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span></span>):   </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># 将输入的img_size转换为二维元组，假设图像是正方形  </span></span><br><span class="line">        img_size = (img_size, img_size)  </span><br><span class="line">        <span class="comment"># 将输入的patch_size转换为二维元组，表示每个patch的大小  </span></span><br><span class="line">        patch_size = (patch_size, patch_size)   </span><br><span class="line">        <span class="comment"># 存储图像的尺寸  </span></span><br><span class="line">        <span class="variable language_">self</span>.img_size = img_size  </span><br><span class="line">        <span class="comment"># 存储每个patch的尺寸  </span></span><br><span class="line">        <span class="variable language_">self</span>.patch_size = patch_size  </span><br><span class="line">        <span class="comment"># 计算图像被划分成多少个patch（网格大小）  </span></span><br><span class="line">        <span class="variable language_">self</span>.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])  </span><br><span class="line">        <span class="comment"># 计算总的patch数量  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_patches = <span class="variable language_">self</span>.grid_size[<span class="number">0</span>] * <span class="variable language_">self</span>.grid_size[<span class="number">1</span>]  </span><br><span class="line">        <span class="comment"># 定义一个卷积层，用于将图像划分为patch，并将每个patch映射到嵌入向量空间  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)   </span><br><span class="line">        <span class="comment"># 定义一个可选的归一化层，如果norm_layer为None，则使用nn.Identity()作为占位符，不进行归一化  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 提取输入x的批次大小、通道数、高度和宽度  </span></span><br><span class="line">        B, C, H, W = x.shape  </span><br><span class="line">        <span class="comment"># 断言输入图像的大小与模型期望的大小匹配  </span></span><br><span class="line">        <span class="keyword">assert</span> H == <span class="variable language_">self</span>.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == <span class="variable language_">self</span>.img_size[<span class="number">1</span>], \  </span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span>  </span><br><span class="line">        <span class="comment"># flatten: [B, C, H, W] -&gt; [B, C, HW]</span></span><br><span class="line">        <span class="comment"># transpose: [B, C, HW] -&gt; [B, HW, C]  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  </span><br><span class="line">        <span class="comment"># 对嵌入向量进行归一化  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)   </span><br><span class="line">        <span class="comment"># 返回处理后的嵌入向量  </span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="②-multi-head-attention块"><a href="#②-multi-head-attention块" class="headerlink" title="② multi-head attention块"></a>② multi-head attention块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,  </span></span><br><span class="line"><span class="params">                 dim,   <span class="comment"># 输入token的特征维度（dim）  </span></span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">8</span>,  <span class="comment"># 多头注意力机制中头的数量  </span></span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,  <span class="comment"># qkv线性变换是否使用偏置项  </span></span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,  <span class="comment"># q和k相乘后的缩放因子，默认为head_dim的负0.5次方  </span></span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,  <span class="comment"># attention分数应用dropout的比率  </span></span></span><br><span class="line"><span class="params">                 proj_drop_ratio=<span class="number">0.</span></span>):  <span class="comment"># 最终投影后应用dropout的比率  </span></span><br><span class="line">        <span class="built_in">super</span>(Attention, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads  <span class="comment"># 存储头的数量  </span></span><br><span class="line">        head_dim = dim // num_heads  <span class="comment"># 每个头的特征维度  </span></span><br><span class="line">        <span class="variable language_">self</span>.scale = qk_scale <span class="keyword">or</span> head_dim ** -<span class="number">0.5</span>  <span class="comment"># 计算缩放因子  </span></span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)  <span class="comment"># qkv的线性变换，输出是输入的3倍，对应q, k, v ,使用全连接层模拟</span></span><br><span class="line">        <span class="variable language_">self</span>.attn_drop = nn.Dropout(attn_drop_ratio)  <span class="comment"># attention分数的dropout  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Linear(dim, dim)  <span class="comment"># 最终的线性投影  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj_drop = nn.Dropout(proj_drop_ratio)  <span class="comment"># 投影后的dropout  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># x的形状为[batch_size, num_patches + 1, total_embed_dim]  </span></span><br><span class="line">        B, N, C = x.shape  <span class="comment"># 分别获取batch大小、序列长度和特征维度  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 通过qkv线性变换，得到[batch_size, num_patches + 1, 3 * total_embed_dim]  </span></span><br><span class="line">        <span class="comment">#reshape操作将张量重塑为[batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]的形状，其中num_heads是多头注意力中的头数，embed_dim_per_head是每个头的特征维度（即总特征维度除以头数）。</span></span><br><span class="line">        <span class="comment">#permute操作则是为了调整张量的维度顺序，使其更便于后续处理。经过permute操作后，张量的形状变为[3, batch_size, num_heads,num_patches + 1, embed_dim_per_head]。   </span></span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x).reshape(B, N, <span class="number">3</span>, <span class="variable language_">self</span>.num_heads, C // <span class="variable language_">self</span>.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)  </span><br><span class="line">        <span class="comment">#分别获取q, k, v，这里的索引操作是基于第一维进行的。由于q、k、v分别对应着这一维上的前、中、后三个部分，因此我们可以通过索引0、1、2来分别获取它们。  </span></span><br><span class="line">        q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]  <span class="comment">#[batch_size, num_heads,num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># transpose: -&gt; [batch_size, num_heads, embed_dim_per_head, num_patches + 1]</span></span><br><span class="line">        <span class="comment"># @: multiply -&gt; [batch_size, num_heads, num_patches + 1, num_patches + 1] </span></span><br><span class="line">        <span class="comment"># 接着乘以缩放因子，应用softmax进行归一化，最后应用dropout</span></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * <span class="variable language_">self</span>.scale  </span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)  </span><br><span class="line">        attn = <span class="variable language_">self</span>.attn_drop(attn)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 使用attention分数对v进行加权计算，得到[batch_size, num_heads, num_patches + 1, embed_dim_per_head]  </span></span><br><span class="line">        <span class="comment"># 然后transpose和reshape操作，将结果转换回[batch_size, num_patches + 1, total_embed_dim]  </span></span><br><span class="line">        x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)  </span><br><span class="line">        <span class="comment"># 对结果进行最终的线性投影  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x)  </span><br><span class="line">        <span class="comment"># 应用dropout后返回最终结果  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj_drop(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br></pre></td></tr></table></figure>
<h4 id="③MLP块"><a href="#③MLP块" class="headerlink" title="③MLP块"></a>③MLP块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置输入特征数、隐藏层特征数（默认为输入特征数）、输出特征数（默认为输入特征数）、激活层（默认为GELU）、丢弃率  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  <span class="comment"># 调用父类初始化方法  </span></span><br><span class="line">        <span class="comment"># 如果没有指定输出特征数，则默认为输入特征数  </span></span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features  </span><br><span class="line">        <span class="comment"># 如果没有指定隐藏层特征数，则默认为输入特征数  </span></span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features  </span><br><span class="line">        <span class="comment"># 定义第一个全连接层，将输入特征数映射到隐藏层特征数  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(in_features, hidden_features)  </span><br><span class="line">        <span class="comment"># 定义激活层，默认为GELU  </span></span><br><span class="line">        <span class="variable language_">self</span>.act = act_layer()  </span><br><span class="line">        <span class="comment"># 定义第二个全连接层，将隐藏层特征数映射到输出特征数  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(hidden_features, out_features)  </span><br><span class="line">        <span class="comment"># 定义丢弃层，用于防止过拟合  </span></span><br><span class="line">        <span class="variable language_">self</span>.drop = nn.Dropout(drop)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):   </span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.act(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.drop(x)   </span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)   </span><br><span class="line">        x = <span class="variable language_">self</span>.drop(x)   </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="④encoder-block块"><a href="#④encoder-block块" class="headerlink" title="④encoder block块"></a>④encoder block块</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置维度、头数、MLP比率、qkv偏置、qk缩放、丢弃率、注意力丢弃率、路径丢弃率、激活层、归一化层  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,  </span></span><br><span class="line"><span class="params">                 dim,  </span></span><br><span class="line"><span class="params">                 num_heads,  </span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>,  </span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,  </span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">                 drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 drop_path_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU,  </span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Block, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化方法  </span></span><br><span class="line">        <span class="comment"># 定义第一个归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm1 = norm_layer(dim)  </span><br><span class="line">        <span class="comment"># 定义注意力机制层  </span></span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,  </span><br><span class="line">                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)  </span><br><span class="line">        <span class="comment"># 如果路径丢弃率大于0，则定义路径丢弃层，否则使用恒等操作（即不改变输入）  </span></span><br><span class="line">        <span class="variable language_">self</span>.drop_path = DropPath(drop_path_ratio) <span class="keyword">if</span> drop_path_ratio &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">        <span class="comment"># 定义第二个归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm2 = norm_layer(dim)  </span><br><span class="line">        <span class="comment"># 计算MLP隐藏层维度  </span></span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)  </span><br><span class="line">        <span class="comment"># 定义MLP层  </span></span><br><span class="line">        <span class="variable language_">self</span>.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># x加上经过归一化、注意力机制、路径丢弃处理后的结果  </span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x)))  </span><br><span class="line">        <span class="comment"># x再加上经过归一化、MLP、路径丢弃处理后的结果  </span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.mlp(<span class="variable language_">self</span>.norm2(x)))  </span><br><span class="line">        <span class="comment"># 返回最终结果  </span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="⑤vit整体结构"><a href="#⑤vit整体结构" class="headerlink" title="⑤vit整体结构"></a>⑤vit整体结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个VisionTransformer类，继承自nn.Module，用于图像分类等任务  </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置多个参数，包括图像大小、块大小、输入通道数、类别数、嵌入维度、encoder个数、head数量、mlp缩放倍数等 </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, num_classes=<span class="number">1000</span>,  </span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.0</span>, qkv_bias=<span class="literal">True</span>,  </span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>, distilled=<span class="literal">False</span>, drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>, drop_path_ratio=<span class="number">0.</span>, embed_layer=PatchEmbed, norm_layer=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">                 act_layer=<span class="literal">None</span></span>):  </span><br><span class="line">          </span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, <span class="variable language_">self</span>).__init__()   </span><br><span class="line">        <span class="comment"># 设置类别数和嵌入维度（也作为特征数）  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_classes = num_classes  </span><br><span class="line">        <span class="variable language_">self</span>.num_features = <span class="variable language_">self</span>.embed_dim = embed_dim  </span><br><span class="line">        <span class="comment"># 设置token数量，该模型设置为1  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_tokens = <span class="number">2</span> <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 如果没有指定归一化层，则默认为LayerNorm，并设置eps为1e-6  </span></span><br><span class="line">        norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)  </span><br><span class="line">        <span class="comment"># 如果没有指定激活层，则默认为GELU  </span></span><br><span class="line">        act_layer = act_layer <span class="keyword">or</span> nn.GELU  </span><br><span class="line">        <span class="comment"># 定义图像块嵌入层，将图像分割成小块并嵌入到高维空间中  </span></span><br><span class="line">        <span class="variable language_">self</span>.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim)  </span><br><span class="line">        <span class="comment"># 获取图像块的数量  </span></span><br><span class="line">        num_patches = <span class="variable language_">self</span>.patch_embed.num_patches  </span><br><span class="line">        <span class="comment"># 初始化类别token和蒸馏token（可忽略）  </span></span><br><span class="line">        <span class="variable language_">self</span>.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))  </span><br><span class="line">        <span class="variable language_">self</span>.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim)) <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="literal">None</span>  </span><br><span class="line">        <span class="comment"># 初始化位置嵌入  </span></span><br><span class="line">        <span class="variable language_">self</span>.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="variable language_">self</span>.num_tokens, embed_dim))  </span><br><span class="line">        <span class="comment"># 定义位置嵌入的丢弃层  </span></span><br><span class="line">        <span class="variable language_">self</span>.pos_drop = nn.Dropout(p=drop_ratio)  </span><br><span class="line">        <span class="comment"># 根据深度生成每个Block的路径丢弃率（使用随机深度衰减规则）  </span></span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_ratio, depth)]   </span><br><span class="line">        <span class="comment"># 定义一系列Block，每个Block包含注意力机制和MLP  </span></span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.Sequential(*[  </span><br><span class="line">            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,  </span><br><span class="line">                  drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i],  </span><br><span class="line">                  norm_layer=norm_layer, act_layer=act_layer)  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)  </span><br><span class="line">        ])     </span><br><span class="line">        <span class="comment"># 定义最后的归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm = norm_layer(embed_dim)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 如果指定了表示层的大小且不是蒸馏模型，则定义表示层 mlp head </span></span><br><span class="line">        <span class="keyword">if</span> representation_size <span class="keyword">and</span> <span class="keyword">not</span> distilled:  </span><br><span class="line">            <span class="variable language_">self</span>.has_logits = <span class="literal">True</span>  </span><br><span class="line">            <span class="variable language_">self</span>.num_features = representation_size  </span><br><span class="line">            <span class="variable language_">self</span>.pre_logits = nn.Sequential(OrderedDict([  </span><br><span class="line">                (<span class="string">&quot;fc&quot;</span>, nn.Linear(embed_dim, representation_size)),  </span><br><span class="line">                (<span class="string">&quot;act&quot;</span>, nn.Tanh())  </span><br><span class="line">            ]))  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.has_logits = <span class="literal">False</span>  </span><br><span class="line">            <span class="variable language_">self</span>.pre_logits = nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 定义分类头，如果类别数大于0则定义线性层，否则为恒等操作  </span></span><br><span class="line">        <span class="variable language_">self</span>.head = nn.Linear(<span class="variable language_">self</span>.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 如果蒸馏模型，则定义额外的分类头（可忽略）  </span></span><br><span class="line">        <span class="variable language_">self</span>.head_dist = <span class="literal">None</span>  </span><br><span class="line">        <span class="keyword">if</span> distilled:  </span><br><span class="line">            <span class="variable language_">self</span>.head_dist = nn.Linear(<span class="variable language_">self</span>.embed_dim, <span class="variable language_">self</span>.num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 初始化权重  </span></span><br><span class="line">        nn.init.trunc_normal_(<span class="variable language_">self</span>.pos_embed, std=<span class="number">0.02</span>)  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            nn.init.trunc_normal_(<span class="variable language_">self</span>.dist_token, std=<span class="number">0.02</span>)  </span><br><span class="line">        nn.init.trunc_normal_(<span class="variable language_">self</span>.cls_token, std=<span class="number">0.02</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.apply(_init_vit_weights)  <span class="comment"># 应用自定义的权重初始化函数  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 定义前向传播函数（特征提取部分）  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 将输入图像通过图像块嵌入层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.patch_embed(x)  </span><br><span class="line">        <span class="comment"># 扩展类别token的维度以匹配输入批次大小  </span></span><br><span class="line">        cls_token = <span class="variable language_">self</span>.cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 根据是否有蒸馏token，将类别token（和蒸馏token）与图像块嵌入拼接  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            x = torch.cat((cls_token, x), dim=<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            x = torch.cat((cls_token, <span class="variable language_">self</span>.dist_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>), x), dim=<span class="number">1</span>)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 将位置嵌入加到输入上，并通过位置嵌入的丢弃层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.pos_drop(x + <span class="variable language_">self</span>.pos_embed)  </span><br><span class="line">        <span class="comment"># 将输入通过一系列Block  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.blocks(x)  </span><br><span class="line">        <span class="comment"># 通过最后的归一化层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)  </span><br><span class="line">        <span class="comment"># 根据是否有蒸馏token，返回不同的输出  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.pre_logits(x[:, <span class="number">0</span>])  <span class="comment"># 提取class token(应用此项)</span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">return</span> x[:, <span class="number">0</span>], x[:, <span class="number">1</span>]  <span class="comment"># 返回类别token和蒸馏token对应的表示  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 定义完整的前向传播函数（包括分类头）  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 通过前向传播函数（特征提取部分）获取表示  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.forward_features(x)    </span><br><span class="line">        <span class="comment"># 如果是蒸馏模型，则分别通过两个分类头获取预测结果  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.head_dist <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            x, x_dist = <span class="variable language_">self</span>.head(x[<span class="number">0</span>]), <span class="variable language_">self</span>.head_dist(x[<span class="number">1</span>])  </span><br><span class="line">            <span class="comment"># 如果是训练模式且不是在使用TorchScript，则返回两个分类头的预测结果  </span></span><br><span class="line">            <span class="comment"># 否则，返回两个分类头预测结果的平均值（用于推理）  </span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> <span class="keyword">not</span> torch.jit.is_scripting():  </span><br><span class="line">                <span class="keyword">return</span> x, x_dist  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="keyword">return</span> (x + x_dist) / <span class="number">2</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 如果不是蒸馏模型，则只通过一个分类头获取预测结果   (应用此项)</span></span><br><span class="line">            x = <span class="variable language_">self</span>.head(x)  </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="一-文献一（CFTN）"><a href="#一-文献一（CFTN）" class="headerlink" title="一.文献一（CFTN）"></a>一.文献一（CFTN）</h2><p><strong>3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution（CFTN）</strong></p>
<h3 id="1-文献介绍"><a href="#1-文献介绍" class="headerlink" title="1.文献介绍"></a>1.文献介绍</h3><h4 id="①先前模型的缺点"><a href="#①先前模型的缺点" class="headerlink" title="①先前模型的缺点"></a>①先前模型的缺点</h4><ul>
<li>仅探索外部图像资源，没有挖掘<strong>内部先验</strong>，在针对特定MR图像和大规模SR重建精细纹理方面仍然存在不足。</li>
</ul>
<h4 id="②关于内部先验（internal-priors）"><a href="#②关于内部先验（internal-priors）" class="headerlink" title="②关于内部先验（internal priors）"></a>②关于内部先验（internal priors）</h4><p>先验知识：</p>
<blockquote>
<p>图片处理中的先验知识是指在处理图像时使用的已知信息或假设。以下是一些常见的图片处理先验知识及其应用：</p>
<ol>
<li><strong>平滑性先验</strong>：<ul>
<li><strong>应用</strong>：假设图像中像素值变化较为平滑，这种假设在去噪、去模糊等任务中非常有用。通过这个先验，可以确保图像的平滑区域保持一致，而不引入伪影。</li>
</ul>
</li>
<li><strong>稀疏性先验</strong>：<ul>
<li><strong>应用</strong>：假设图像在某个变换域（如傅里叶变换或小波变换）中是稀疏的，即大多数变换系数接近于零。这一先验在图像压缩和重建中非常重要。</li>
</ul>
</li>
<li><strong>边缘先验</strong>：<ul>
<li><strong>应用</strong>：假设图像中存在明显的边缘和轮廓。边缘先验在边缘检测、图像分割和超分辨率重建中有很大作用，能够帮助模型更好地识别和恢复图像中的细节。</li>
</ul>
</li>
<li><strong>结构先验</strong>：<ul>
<li><strong>应用</strong>：假设图像具有某些已知的结构特性，如对称性和纹理。这些先验在图像修复、去雾等任务中可以显著提高性能。</li>
</ul>
</li>
</ol>
<p>在深度学习模型中，先验知识可以通过设计合适的损失函数、网络结构或通过预训练的方式融入模型中，从而提升模型的处理能力和泛化能力。</p>
</blockquote>
<p>内部先验与外部先验：</p>
<blockquote>
<p><strong>内部先验</strong>：</p>
<ul>
<li><strong>定义</strong>：基于输入图像本身的特性和信息的先验知识。</li>
<li><strong>例子</strong>：图像的平滑性、边缘特性、局部一致性等。在图像去噪中，假设图像的某些部分应该是平滑的或者连贯的，这就是一种内部先验。</li>
<li><strong>应用</strong>：例如图像增强、去噪、去模糊等任务，通过分析和利用图像自身的统计特性和结构信息来提升处理效果。</li>
</ul>
<p><strong>外部先验</strong>：</p>
<ul>
<li><strong>定义</strong>：来自于输入图像之外的额外知识或数据的先验信息。</li>
<li><strong>例子</strong>：预训练模型的权重、从大型数据集中学习到的统计规律等。在图像分类任务中，使用从大量标注数据中学到的特征，可以作为一种强有力的外部先验。</li>
<li><strong>应用</strong>：例如图像识别、语义分割等任务，通过利用大规模数据训练的模型来提供外部先验，增强模型的泛化能力和准确性。</li>
</ul>
</blockquote>
<p>超分辨率中：</p>
<blockquote>
<p><strong>内部先验</strong>：</p>
<ul>
<li><strong>定义</strong>：利用图像自身的特性和结构信息来提高重建质量。</li>
<li><strong>应用</strong>：在超分辨率任务中，内部先验可以帮助模型保留和强化图像的细节和纹理。例如，通过分析低分辨率图像中的边缘和纹理信息，可以生成更清晰、更细致的高分辨率图像。此外，内部先验还可以帮助模型减少噪声和伪影，使得重建结果更加自然。</li>
</ul>
<p><strong>外部先验</strong>：</p>
<ul>
<li><strong>定义</strong>：依靠外部数据或预训练模型的知识来辅助图像重建。</li>
<li><strong>应用</strong>：在超分辨率任务中，外部先验通常通过预训练模型来实现。这些模型在大量高分辨率和低分辨率图像对上进行了训练，学到了如何从低分辨率图像中恢复出高分辨率细节。例如，GAN（生成对抗网络）和VDSR（超深卷积神经网络）等方法都依赖于外部先验，通过使用大规模数据集进行训练，模型能够捕捉到更丰富的细节和结构信息，从而生成质量更高的高分辨率图像。</li>
</ul>
</blockquote>
<h4 id="③文章贡献"><a href="#③文章贡献" class="headerlink" title="③文章贡献"></a>③文章贡献</h4><ul>
<li>CFTN自适应地将MRI特征的<strong><u>全局跨尺度自相似先验</u></strong>集成到深度网络中。<ul>
<li>全局跨尺度自相似性先验（the global cross-scale self-similarity priors）<ul>
<li><strong>“全局跨尺度自相似先验 (global cross-scale self-similarity priors)”是指在不同尺度（大小）上存在的全局图像特征的相似性。这些先验知识用于指导深度网络在图像处理任务中更好地重建和保留图像细节。</strong></li>
<li>在图像超分辨率等任务中，图像的局部区域可能在不同的尺度上显示出相似的模式。例如，一个物体的纹理或边缘在不同分辨率下可能看起来相似。利用这些自相似性先验，模型可以更有效地填补低分辨率图像中的细节，从而生成高质量的高分辨率图像。</li>
</ul>
</li>
</ul>
</li>
<li>mutual-projection feature enhancement module（MFEM）<ul>
<li>CFTN对整个MR特征内的跨尺度相关性进行建模，可以捕捉MR特征内的跨尺度自相似性先验。</li>
</ul>
</li>
<li>spatial attention fusion module（SAFM）<ul>
<li>通过空间注意力融合模块削弱无用的跨尺度特征并增强重要的信息区域。</li>
<li>可以自适应地调整和融合目标尺度特征和上采样特征</li>
</ul>
</li>
</ul>
<h3 id="2-网络结构（CFTN）"><a href="#2-网络结构（CFTN）" class="headerlink" title="2.网络结构（CFTN）"></a>2.网络结构（CFTN）</h3><p><img src="https://s21.ax1x.com/2024/10/28/pA0d3LD.png" alt="pA0d3LD.png"></p>
<h4 id="①residual-channel-attention-block-RCAB"><a href="#①residual-channel-attention-block-RCAB" class="headerlink" title="①residual channel attention block (RCAB)"></a>①residual channel attention block (RCAB)</h4><ul>
<li>作为主干网络的基本单元，该模块来自”RCAN”</li>
<li><img src="https://s21.ax1x.com/2024/09/27/pAlfQeA.png" alt="pAlfQeA.png"></li>
</ul>
<p><img src="https://s21.ax1x.com/2024/09/27/pAlfsYV.png" alt="pAlfsYV.png"></p>
<h4 id="②mutual-projection-feature-enhancement-module-MFEM"><a href="#②mutual-projection-feature-enhancement-module-MFEM" class="headerlink" title="②mutual-projection feature enhancement module (MFEM)"></a>②mutual-projection feature enhancement module (MFEM)</h4><ul>
<li><strong>原理：对于超分辨率等任务，在不同尺度上的特征有更丰富的细节和纹理。</strong></li>
<li><p>结构:</p>
<ul>
<li><strong>融合低尺度特征权重的$Y_m$与原始图片上采样残差连接后，组合为 $Y^{‘}_m$ 。输出带有 HR 细节的目标尺度特征 $Y^{‘}_m$ 和相应的下采样特征 $X^{‘}_m$</strong></li>
<li>$X^{‘}_m$作为$RCAB_{m+1}$的输入，使网络探索更多跨尺度的信息。</li>
<li><img src="https://s21.ax1x.com/2024/10/28/pA0wgBD.png" alt="pA0wgBD.png"></li>
</ul>
</li>
<li><p><strong>Cross-scale Transformer（CST）</strong></p>
<ul>
<li>结构（通过transform结构可以学习到低尺度-高尺度对的相似性，可生成对应的权重）<ul>
<li>将输入的$x_m$降维得到$z_m$</li>
<li>embedding（1*1*1）：将高维的离散数据映射到低维的连续向量空间中，使得相似的数据点在向量空间中距离更近，分别展开形成V,Q,K</li>
<li>Q：高尺度图片序列，K：低尺度图片序列，通过size=p、stride=g，将序列展开为各p个块$q_i$ and $k_j$，即：<ul>
<li><script type="math/tex; mode=display">i \in \left[ 1 , \frac { H } { g } \times \frac { W } { g } \times \frac { L } { g } \right]</script></li>
<li><script type="math/tex; mode=display">j \in \left[ 1 , \frac { H } { r g } \times \frac { W } { r g } \times \frac { L } { r g } \right]</script></li>
</ul>
</li>
<li>之后将两个特征矩阵进行点乘，并经过softmax层进行归一化，生成高-低对尺度图片的特征相似度的权重。<ul>
<li><script type="math/tex; mode=display">s _ { i , j } = \langle q _ { i } , k _ { j } \rangle</script></li>
<li><script type="math/tex; mode=display">\omega _ { i , j } = \frac { e x p ( s _ { i , j } ) } { \sum _ { j } e x p ( s _ { i , j } ) }</script></li>
</ul>
</li>
<li>再将该权重与vi（高尺度，上升r倍）序列逐元素相乘得到具有跨尺度特征的$Y_m$<ul>
<li><script type="math/tex; mode=display">y _ { j } = \sum _ { j } \omega _ { i , j } \otimes v _ { j }</script></li>
</ul>
</li>
<li>最后通过转置卷积将$yj$序列折叠为高维的$y_m$</li>
<li><img src="https://s21.ax1x.com/2024/10/28/pA0wsc6.png" alt="pA0wsc6.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="③spatial-attention-fusion-module-SAFM"><a href="#③spatial-attention-fusion-module-SAFM" class="headerlink" title="③spatial attention fusion module (SAFM)"></a>③spatial attention fusion module (SAFM)</h4><ul>
<li>上采样特征 Y 和 HR 特征 $Y^′_m$经过此模块产生准确的 HR 融合特征 $Y_f$</li>
<li>考虑到MFEM输出的目标尺度特征Y’m可能包含一些无用的重复信息，为了将Y’m更有意义的部分集成到主干网络中，利用空间注意力来自适应调整和融合特征。</li>
<li>参考前部分空间注意力机制</li>
<li><img src="https://s21.ax1x.com/2024/10/28/pA0DgBT.png" alt="pA0DgBT.png"></li>
</ul>
<h2 id="二-文献二（ASFT）"><a href="#二-文献二（ASFT）" class="headerlink" title="二.文献二（ASFT）"></a>二.文献二（ASFT）</h2><ul>
<li><strong>Adjacent slices feature transformer network for single anisotropic 3D brain MRI image super-resolution</strong></li>
</ul>
<h3 id="1-文献介绍-1"><a href="#1-文献介绍-1" class="headerlink" title="1.文献介绍"></a>1.文献介绍</h3><p>主要贡献：</p>
<ul>
<li>构建了 ASFT 网络，将脑 MRI 图像 SR 问题视为<strong>在各向异性脑 MRI 图像的相邻平面内切片中插入附加切片的任务。</strong></li>
<li><strong>多分支特征转换和提取（MFTE）块利用相邻平面内切片的相似性，变换相邻 HR 参考切片的特征，以丰富目标切片的细节</strong>。</li>
<li>使用SA方法来自适应细化空间特征，增强参考切片中有意义的特征区域并过滤掉无用的特征区域。此外，使用 CA 来学习多级特征的权重，以保留有助于提高 SR 性能的重要特征。</li>
<li>设计了一个内容和梯度混合损失函数来监督SR网络学习几何失真较少的精细纹理和上下文。<strong>内容和梯度项可以分别保持保真度并约束与相邻像素的关系。</strong></li>
<li>创新性地将其转换为向高分辨率层面插入额外切片的问题，利用各向异性 3D MRI 图像的 3D  空间连续性与相邻切片的相似性，从高分辨率层面中自适应地学习与挖掘有利于提高目标切片分辨率的信息，从 2D 角度解决 3D MRI 图像的超分辨率问题。在此基础上，进一步提出基于图像梯度与内容的联合优化函数，保留 MRI 图像原有结构信息的同时,提升 3D MRI 图像的分辨率。</li>
</ul>
<h3 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2.网络结构"></a>2.网络结构</h3><ul>
<li><img src="https://s21.ax1x.com/2024/11/02/pADzjFP.png" alt="pADzjFP.png"></li>
</ul>
<h4 id="①initial-feature-extraction-IFE-operation"><a href="#①initial-feature-extraction-IFE-operation" class="headerlink" title="①initial feature extraction (IFE) operation"></a>①initial feature extraction (IFE) operation</h4><ul>
<li><p>ASFT由给定的LR脑部MRI图像<script type="math/tex">I _ { L R } \in R ^ { W \times H \times  D }</script>以尺度因子s生成HR脑部MRI图像<script type="math/tex">I _ { S R } \in R ^ { W \times H \times s D }</script></p>
</li>
<li><p>$  x _ { I n } , x _ { I n } ^ { U } , x _ { I n } ^ { N }     f r o m       I _ { L R } ^ {\uparrow} , I _ { R e f } ^ { U }  I _ { R e f } ^ { N }$，</p>
<ul>
<li>分为三个分支，$ X _ { I n } = \left\{ x _ { I n } ^ { U } , x _ { I n } , x _ { I n } ^ { N } \right\} .$</li>
<li>上标 U 和 N 分别表示目标切片的前一个与后一个相邻的高分辨率切片</li>
</ul>
</li>
<li><p>后分别通过卷积层初步提取特征得到<script type="math/tex">X _ { 1 } = \left\{ x _ { 1 } ^ { U } , x _ { 1 } , x _ { 1 } ^ { N } \right\}</script></p>
</li>
</ul>
<h4 id="②feature-mapping-sub-network-FMNet"><a href="#②feature-mapping-sub-network-FMNet" class="headerlink" title="②feature mapping sub-network (FMNet)"></a>②feature mapping sub-network (FMNet)</h4><ul>
<li><strong>Multi-branch Features Transformation and Extraction</strong><ul>
<li>主分支被用于提取多层次特征，上、下两个分支用于从相邻的高分辨率切片中提取特征并进行特征的转换，即对与目标切片不相关的特征信息进行抑制，相关的特征信息进行增强</li>
<li>上下相近切片的两个分支将通过SA，之后采用沿通道方向的均值操作来融合所有分支的特征。</li>
<li><img src="https://s21.ax1x.com/2024/11/02/pArCcp6.png" alt="pArCcp6.png"></li>
</ul>
</li>
</ul>
<h4 id="③reconstruction-sub-network-RecNet"><a href="#③reconstruction-sub-network-RecNet" class="headerlink" title="③reconstruction sub-network (RecNet)"></a>③reconstruction sub-network (RecNet)</h4><ul>
<li>通过SA增强较强特征，之后再进行一次融合并与原始图片残差连接得到最终输出</li>
</ul>

      
    </div>
    
    
    



    

    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>-------------</div>
    
</div>

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/" rel="tag"><i class="fa fa-tag"></i> 超分辨率</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2024/10/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%83%E7%AB%A0-SRFBN/" rel="next" title="超分辨率第七章-SRFBN">
                <i class="fa fa-chevron-left"></i> 超分辨率第七章-SRFBN
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2024/11/04/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B9%9D%E7%AB%A0-RDN/" rel="prev" title="超分辨率第九章-RDN">
                超分辨率第九章-RDN <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>

  </div>
  
  
  
  </article>
  



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">
      
      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/header.gif"
                alt="沙漠客" />
            
              <p class="site-author-name" itemprop="name">沙漠客</p>
              <p class="site-description motion-element" itemprop="description">Action speak louder than words!</p>
          </div>
        <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=100 src="//music.163.com/outchain/player?type=2&id=1396311816&auto=1&height=66"></iframe>
        </iframe>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/sichuanshamoke" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/m0_51960673?spm=1000.2115.3001.5343" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-fa fa-codiepie"></i>CSDN</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.kaggle.com/sichuanshamoke" target="_blank" title="kaggle">
                      
                        <i class="fa fa-fw fa-stack-overflow"></i>kaggle</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://leetcode.cn/u/amazing-snyderdc5/" target="_blank" title="LeetCode">
                      
                        <i class="fa fa-fw fa-skype"></i>LeetCode</a>
                  </span>
                
            </div>
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <!-- modify icon to fire by szw -->
                <i class="fa fa-history fa-" aria-hidden="true"></i>
                近期文章
              </div>
              <ul class="links-of-blogroll-list">
                
                
                  <li class="recent_posts_li">
                    <a href="/2024/12/02/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%8D%81%E7%AB%A0-NormalizingFlow-SR/" title="超分辨率第十章-NormalizingFlow&SR" target="_blank">超分辨率第十章-NormalizingFlow&SR</a>
                  </li>
                
                  <li class="recent_posts_li">
                    <a href="/2024/11/04/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B9%9D%E7%AB%A0-RDN/" title="超分辨率第九章-RDN" target="_blank">超分辨率第九章-RDN</a>
                  </li>
                
                  <li class="recent_posts_li">
                    <a href="/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&transformer/" title="超分辨率第八章-SR&transformer" target="_blank">超分辨率第八章-SR&transformer</a>
                  </li>
                
                  <li class="recent_posts_li">
                    <a href="/2024/10/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%83%E7%AB%A0-SRFBN/" title="超分辨率第七章-SRFBN" target="_blank">超分辨率第七章-SRFBN</a>
                  </li>
                
                  <li class="recent_posts_li">
                    <a href="/2024/09/26/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AD%E7%AB%A0-RCAN/" title="超分辨率第六章-RCAN" target="_blank">超分辨率第六章-RCAN</a>
                  </li>
                
              </ul>
            </div>
          


          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://space.bilibili.com/562700874?spm_id_from=333.1365.0.0" title="风翼飞镰" target="_blank">风翼飞镰</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR-amp-transformer"><span class="nav-text">超分辨率第八章-SR&amp;transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86"><span class="nav-text">前置知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-attention"><span class="nav-text">1.attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-text">2.通道注意力机制与空间注意力机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-transformer"><span class="nav-text">3.transformer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-vision-transformer"><span class="nav-text">4.vision transformer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-vit%E4%BB%A3%E7%A0%81"><span class="nav-text">5.vit代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0patch-embedding%E5%9D%97"><span class="nav-text">①patch embedding块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1-multi-head-attention%E5%9D%97"><span class="nav-text">② multi-head attention块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2MLP%E5%9D%97"><span class="nav-text">③MLP块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A3encoder-block%E5%9D%97"><span class="nav-text">④encoder block块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A4vit%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-text">⑤vit整体结构</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80-%E6%96%87%E7%8C%AE%E4%B8%80%EF%BC%88CFTN%EF%BC%89"><span class="nav-text">一.文献一（CFTN）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%96%87%E7%8C%AE%E4%BB%8B%E7%BB%8D"><span class="nav-text">1.文献介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0%E5%85%88%E5%89%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-text">①先前模型的缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1%E5%85%B3%E4%BA%8E%E5%86%85%E9%83%A8%E5%85%88%E9%AA%8C%EF%BC%88internal-priors%EF%BC%89"><span class="nav-text">②关于内部先验（internal priors）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2%E6%96%87%E7%AB%A0%E8%B4%A1%E7%8C%AE"><span class="nav-text">③文章贡献</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%88CFTN%EF%BC%89"><span class="nav-text">2.网络结构（CFTN）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0residual-channel-attention-block-RCAB"><span class="nav-text">①residual channel attention block (RCAB)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1mutual-projection-feature-enhancement-module-MFEM"><span class="nav-text">②mutual-projection feature enhancement module (MFEM)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2spatial-attention-fusion-module-SAFM"><span class="nav-text">③spatial attention fusion module (SAFM)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C-%E6%96%87%E7%8C%AE%E4%BA%8C%EF%BC%88ASFT%EF%BC%89"><span class="nav-text">二.文献二（ASFT）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%96%87%E7%8C%AE%E4%BB%8B%E7%BB%8D-1"><span class="nav-text">1.文献介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">2.网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0initial-feature-extraction-IFE-operation"><span class="nav-text">①initial feature extraction (IFE) operation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1feature-mapping-sub-network-FMNet"><span class="nav-text">②feature mapping sub-network (FMNet)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2reconstruction-sub-network-RecNet"><span class="nav-text">③reconstruction sub-network (RecNet)</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2023 &mdash; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shamoke</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">221.4k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'wsUYJtlLslOYlG6pA3pS9i30-gzGzoHsz',
        appKey: 'd1H2YDHxgJkfTsFw0UhNNMFJ',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

    <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }
 
    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }
 
    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }
 
    .highlight-wrap {
      position: relative;
    }
  </style>
 
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
 
        if(result)$(this).text('复制成功')
        else $(this).text('复制失败')
 
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>	
  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
