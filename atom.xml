<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hello World</title>
  
  <subtitle>Studying and Recording</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-12-03T05:07:24.874Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Shamoke</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>超分辨率第十章-NormalizingFlow&amp;SR</title>
    <link href="http://example.com/2024/12/02/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%8D%81%E7%AB%A0-NormalizingFlow-SR/"/>
    <id>http://example.com/2024/12/02/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%8D%81%E7%AB%A0-NormalizingFlow-SR/</id>
    <published>2024-12-02T05:38:03.000Z</published>
    <updated>2024-12-03T05:07:24.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第十章-NormalizingFlow-amp-SR"><a href="#超分辨率第十章-NormalizingFlow-amp-SR" class="headerlink" title="超分辨率第十章-NormalizingFlow&amp;SR"></a>超分辨率第十章-NormalizingFlow&amp;SR</h1><blockquote><p><strong>本文介绍标准化流（Normalizing Flow）以及其对应的超分辨率模型SRflow</strong></p><p>参考文献：<a href="https://arxiv.org/pdf/1908.09257"> Normalizing Flows: An Introduction and Review of Current Methods</a></p><p>参考博客：<a href="https://zhuanlan.zhihu.com/p/358281628">SRFlow: Learning the Super-Resolution Space with Normalizing Flow</a></p></blockquote><span id="more"></span><h2 id="一-Normalizing-Flows（标准化流）"><a href="#一-Normalizing-Flows（标准化流）" class="headerlink" title="一.Normalizing Flows（标准化流）"></a>一.Normalizing Flows（标准化流）</h2><p>标准化流，与VAE、GAN同属于生成式方法</p><h3 id="1-标准化流的概念"><a href="#1-标准化流的概念" class="headerlink" title="1.标准化流的概念"></a>1.标准化流的概念</h3><h4 id="①标准化流的方法"><a href="#①标准化流的方法" class="headerlink" title="①标准化流的方法"></a>①标准化流的方法</h4><p><strong>通过一系列可逆且可微的变换（invertible and differentiable）将简单(复杂)的概率分布转换为复杂(简单)的概率分布</strong></p><blockquote><p>The density of a sample can be evaluated by transforming it back to the original simple distribution and then computing the product of i) the density of the inverse-transformed sample under this distribution and ii) the associated change in volume induced by the sequence of inverse transformations. The change in volume is the product of the absolute values of the determinants of the Jacobians for each transformation, as required by the change of variables formula.</p><p><strong>样本的密度可以通过将其转换回原始简单分布，然后计算以下两者的乘积来评估：i) 该分布下逆变换后样本的密度；ii) 由一系列逆变换引起的相关体积变化。体积的变化是按照变量替换公式的要求，等于每个变换的雅可比行列式的绝对值的乘积。</strong></p></blockquote><p>由此可见，标准化流需要用到：行列式(Determinant)、雅可比矩阵(Jacobi)、变量替换定理(Change of Variable Theorem)</p><h4 id="②雅可比行列式（Jacobians）"><a href="#②雅可比行列式（Jacobians）" class="headerlink" title="②雅可比行列式（Jacobians）"></a>②雅可比行列式（Jacobians）</h4><ol><li><strong>密度计算</strong>：在逆变换后的分布中，我们可以计算样本的密度。但是，由于我们进行了变换，所以还需要考虑由变换引起的体积变化（在多维空间中，这通常被称为“雅可比行列式”）。</li><li><strong>雅可比行列式</strong>：在多维空间中，雅可比行列式是一个矩阵，其行列式值表示了从一个空间到另一个空间的体积变化因子。在进行变量替换时，我们需要计算雅可比行列式的绝对值，以确保体积的变化被正确考虑。</li></ol><p>由$x=f(z)$的变化后的相关雅可比矩阵：$J_f = \begin{bmatrix} \frac{\partial z_1}{\partial x_1} &amp; \frac{\partial z_1}{\partial x_2} \\ \frac{\partial z_2}{\partial x_1} &amp; \frac{\partial z_2}{\partial x_2} \end{bmatrix}$</p><h4 id="③概率密度函数的计算"><a href="#③概率密度函数的计算" class="headerlink" title="③概率密度函数的计算"></a>③概率密度函数的计算</h4><p>进行可逆变化后<script type="math/tex">Y = g ( Z )</script> ，计算Y的概率密度函数的方法</p><script type="math/tex; mode=display">p _ { Y } ( y ) = p _ { Z } ( f ( y ) ) | d e t D f ( y ) | \\ = p _ { Z } ( f ( y ) ) | d e t D g ( f ( y ) ) | ^ { - 1 }</script><p><img src="https://s21.ax1x.com/2024/12/02/pAID0G4.png" alt="pAID0G4.png"></p><h4 id="④损失函数-最大似然估计"><a href="#④损失函数-最大似然估计" class="headerlink" title="④损失函数-最大似然估计"></a>④损失函数-最大似然估计</h4><p>高-低分辨率图片对，通过可逆神经网络进行编码，将y编码为z</p><script type="math/tex; mode=display">z=f _ { \theta } ( y , x )</script><p>此时可以逆向解码</p><script type="math/tex; mode=display">y = f _ { \theta } ^ { - 1 } ( z , x ) , z \sim p _ { z } 。</script><p>若需通过$z$分布下的概率密度函数计算y分布下的概率密度函数，需要乘雅可比矩阵的绝对值</p><script type="math/tex; mode=display">p _ { y | x } ( y | x , \theta ) = p _ { z } ( f _ { \theta } ( y ; x ) ) | d e t \frac { \partial f _ { \theta } } { \partial y } ( y ; x ) | .</script><p>此时计算极大似然估计，使用负对数似然的方法，两边取负对数，使负对数似然最小：</p><script type="math/tex; mode=display">\complement ( \theta ; x , y ) = - \log p _ { y / x } ( y | x , \theta ) = - \log p _ { z } ( f _ { \theta } ( y ; x ) ) - \log | d e t \frac { \partial f _ { \theta } } { \partial y } ( y ; x ) | .</script><h4 id="⑤关于flow"><a href="#⑤关于flow" class="headerlink" title="⑤关于flow"></a>⑤关于flow</h4><p>为了将一个高斯分布 $z0$ 转换为一个复杂的分布 $zK$，normalizing flow 会对初始的分布 $z0$ 进行多次可逆的变换，将其逐渐转换为 $zK$。由于每一次变换都是可逆的，从 $zK$ 出发也能得到高斯分布 $z0$。这样，我们就实现了复杂分布与高斯分布之间的互相转换，从而能从简单的高斯分布建立任意复杂分布。</p><p><img src="https://s21.ax1x.com/2024/12/02/pAI7eUg.png" alt="pAI7eUg.png"></p><p><img src="https://s21.ax1x.com/2024/12/03/pAIX4Mj.png" alt="pAIX4Mj.png"></p><p><strong>关键：计算每一层的雅可比行列式</strong></p><h2 id="二-SRflow"><a href="#二-SRflow" class="headerlink" title="二.SRflow"></a>二.SRflow</h2><h3 id="1-SRflow解决的问题"><a href="#1-SRflow解决的问题" class="headerlink" title="1.SRflow解决的问题"></a>1.SRflow解决的问题</h3><p>对于生成式方法GAN，容易出现模式崩溃的问题。</p><p>SRFlow：一种基于归一化流的超分辨率方法，能够学习给定低分辨率输入$x$的在高分辨率图像下$y$的条件概率分布。模型使用单一损失（即负对数似然）进行训练，可以生成多幅SR图片，解决了”ill-posed”问题 </p><h3 id="2-模型架构"><a href="#2-模型架构" class="headerlink" title="2.模型架构"></a>2.模型架构</h3><p><img src="https://s21.ax1x.com/2024/12/03/pAIXILn.png" alt="pAIXILn.png"></p><p>本模型基于GLOW</p><p>模型由一个可逆流网络 $f_{\theta}$ 组成，以低分辨率图像的编码（绿色）为条件。流网络在多个比例级别（灰色）上运行。输入通过一系列流步骤（蓝色）进行处理，每个流步骤由四个不同的层组成。通过精确的对数似然训练，我们的网络学习将高斯密度 $p_{z}(z)$ 转换为条件 HR 图像分布 $p_{y | x}(y | x, \theta)$。</p><p>在训练期间，输入 LR-HR $(x, y)$ 图像对，以计算负对数似然损失。</p><script type="math/tex; mode=display">L ( \theta ; x , y ) = - \log p _ { x } ( z ) - \sum _ { n = 0 } ^ { N - 1 } \log | d e t \frac { \partial f _ { \theta } ^ { n } } { \partial h ^ { n } } ( h ^ { n } ; g_0 ( x ) ) |</script><p>在推理过程中，网络通过输入 LR 图像和随机变量 $z=(z_{l})_{l=1}^{L} ~ p_{z}$ 来反向运行，该随机变量从学习的分布 $p_{y | x}$ 生成样本 SR 图像。</p><p>编码器g0架构基于RRDB，用于提取低分辨率图像的特征。</p><blockquote><p>SRFlow是一种基于归一化流（Normalizing Flow）的超分辨率（Super - Resolution，SR）方法，能够学习到高分辨率图像的分布，并在给定低分辨率图像时生成高分辨率图像。以下是从图中详细介绍SRFlow的训练流程和推理流程： </p><p><strong>一、训练流程</strong> </p><ol><li><strong>输入数据</strong>   <ul><li><strong>训练输入（Training Input）</strong>：高分辨率图像（High - Resolution）。</li></ul></li><li><strong>低分辨率编码器（Low Resolution Encoder $g_{\theta}$）</strong>   <ul><li>高分辨率图像首先经过下采样得到低分辨率图像。   -</li><li>低分辨率图像被送入低分辨率编码器($g_{\theta}$)，该编码器基于残差密集块（RRDB）架构，用于提取低分辨率图像的特征。</li></ul></li><li><p><strong>可逆归一化流（Invertible Normalizing Flow ($f_{\theta}$）</strong>   -</p><ul><li>低分辨率编码器的输出被送入可逆归一化流$f{\theta}$。   </li><li>可逆归一化流由多个条件流步骤（Conditional Flow Step）和过渡步骤（Transition Step）组成。   </li><li>每个条件流步骤包括仿射耦合层（Affine Coupling）、1x1卷积（1x1 Convolution）、Actnorm和Squeeze操作。    </li><li>过渡步骤用于在不同尺度级别（Scale Level）之间进行转换。   </li><li>可逆归一化流的目标是学习从低分辨率图像到高分辨率图像的映射。 </li></ul></li><li><p><strong>训练目标</strong>   </p><ul><li>训练过程中，模型通过最小化负对数似然（Negative Log - Likelihood）来优化参数。   </li><li>模型学习到低分辨率图像和高分辨率图像之间的条件分布。 </li></ul></li></ol><p><strong>二、推理流程</strong> </p><ol><li><p><strong>输入数据</strong>   - <strong>推理输入（Inference Input）</strong>：低分辨率图像（Low - Resolution）。 </p></li><li><p><strong>低分辨率编码器（Low Resolution Encoder $g_{\theta}$)）</strong> </p><ul><li>低分辨率图像被送入低分辨率编码器$g_{\theta}$，提取特征。 </li></ul></li><li><strong>可逆归一化流（Invertible Normalizing Flow $f_{\theta}$</strong> <ul><li>低分辨率编码器的输出被送入可逆归一化流$f_{\theta}$。   </li><li>通过可逆归一化流的正向传播，生成高分辨率图像。 </li></ul></li><li><strong>输出数据</strong>   <ul><li><strong>推理输出（Inference Output）</strong>：高分辨率图像（Super - Resolution）。 </li></ul></li></ol></blockquote><h3 id="3-可逆归一化流结构"><a href="#3-可逆归一化流结构" class="headerlink" title="3.可逆归一化流结构"></a>3.可逆归一化流结构</h3><p>分为四块，每块由squeeze(挤压层)、过度步骤，条件流步骤（多个）、split。</p><h4 id="①squeeze"><a href="#①squeeze" class="headerlink" title="①squeeze"></a>①squeeze</h4><p>将输入图像分辨率减半</p><h4 id="②Actnorm"><a href="#②Actnorm" class="headerlink" title="②Actnorm"></a>②Actnorm</h4><p><strong>归一化层</strong></p><h4 id="③Invertible-1-×-1-Convolution"><a href="#③Invertible-1-×-1-Convolution" class="headerlink" title="③Invertible 1 × 1 Convolution"></a>③Invertible 1 × 1 Convolution</h4><p><strong>基于：Glow: Generative Flow with Invertible 1x1 Convolutions</strong></p><script type="math/tex; mode=display">h _ { i j } ^ { n + 1 } = W h _ { i j } ^ { n }</script><p>形成块对角结构，减少计算量</p><h4 id="④Affine-Injector（仿射注入）"><a href="#④Affine-Injector（仿射注入）" class="headerlink" title="④Affine Injector（仿射注入）"></a>④Affine Injector（仿射注入）</h4><script type="math/tex; mode=display">h ^ { n + 1 } = e x p ( f _ { \theta , s } ^ { n } ( u ) ) \cdot h ^ { n } + f _ { \theta , b } ( u )</script><p>其中<script type="math/tex">f _ { \theta , s } ^ { n } ( u )</script>用于预测缩放因子，<script type="math/tex">f _ { \theta , b } ( u )</script>用于预测偏差。通过将激活图与基于条件编码预测得到的缩放因子相乘，并加上偏差，得到更新后的激活图$h_n+1$</p><p>能够实现从低分辨率图像编码到流分支的直接信息传递，通过这样的缩放和偏差操作，仿射注入层能够有效地将低分辨率图像的信息融入到流网络的处理过程中，使得模型能够更好地学习高分辨率图像的条件分布</p><h4 id="⑤Conditional-Affine-Coupling-条件仿射耦合"><a href="#⑤Conditional-Affine-Coupling-条件仿射耦合" class="headerlink" title="⑤Conditional Affine Coupling(条件仿射耦合)"></a>⑤Conditional Affine Coupling(条件仿射耦合)</h4><p>条件仿射耦合层的核心原理基于对激活图在通道维度上的划分，将其分为两部分，对于给定的低分辨率图像，其编码<script type="math/tex">u = g _ { \theta } ( x )</script>作为条件变量参与到仿射变换中。</p><p>神经网络$f_0$被分成 N个可逆层 $ h ^ { n + 1 } = f _ { \theta } ^ { n } ( h ^ { n } ; g _ { \theta } ( x ) )$，$h^0=y,h^N=z$</p><p>在通道维度上的特征图被划分成两部分<script type="math/tex">h ^ { n } = ( h _ { A } ^ { n } , h _ { B } ^ { n } )</script>，分别进行以下操作：</p><script type="math/tex; mode=display">h _ { A } ^ { n + 1 } = h _ { A } ^ { n }</script><script type="math/tex; mode=display">h _ { B } ^ { n + 1 } = e x p ( f _ { \theta , s } ^ { n } ( h _ { A } ^ { n } ; u ) ) \cdot h _ { B } ^ { n } + f _ { \theta , b } ^ { n } ( h _ { A } ^ { n } ; u )</script><p>u是一个条件变量，即低分辨率图像的编码，$u=g_θ(x)$。</p><script type="math/tex; mode=display">f _ { \theta , s } ^ { n }$$和$$ f _ { \theta , b } ^ { n }$$代表产生$$ h _ { B } ^ { n }$$的scaling和bias的任意神经网络。此时该层的雅可比矩阵为块三角矩阵，可以简化对行列式的计算，使网络在训练过程中可以高效计算负对数似然损失：$$ \sum _ { i j k } f _ { \theta , s } ^ { n } ( h _ { A } ^ { n } ; u ) _ { i j k }</script><p><img src="https://s21.ax1x.com/2024/12/03/pAIxBM4.png" alt="pAIxBM4.png"></p><h4 id="⑥Split"><a href="#⑥Split" class="headerlink" title="⑥Split"></a>⑥Split</h4><p>Split 层主要用于将输入数据分成两部分。在 SRFlow 架构中，它将来自条件耦合层（Conditional Coupling Layer）的数据进行分割。</p><p>一部分数据被传递到下一个条件流步骤（Conditional Flow Step），而另一部分数据则被分流出去。这有助于模型在不同尺度和层次上提取特征。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第十章-NormalizingFlow-amp-SR&quot;&gt;&lt;a href=&quot;#超分辨率第十章-NormalizingFlow-amp-SR&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第十章-NormalizingFlow&amp;amp;SR&quot;&gt;&lt;/a&gt;超分辨率第十章-NormalizingFlow&amp;amp;SR&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;本文介绍标准化流（Normalizing Flow）以及其对应的超分辨率模型SRflow&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;a href=&quot;https://arxiv.org/pdf/1908.09257&quot;&gt; Normalizing Flows: An Introduction and Review of Current Methods&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考博客：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/358281628&quot;&gt;SRFlow: Learning the Super-Resolution Space with Normalizing Flow&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第九章-RDN</title>
    <link href="http://example.com/2024/11/04/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B9%9D%E7%AB%A0-RDN/"/>
    <id>http://example.com/2024/11/04/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B9%9D%E7%AB%A0-RDN/</id>
    <published>2024-11-04T05:09:14.000Z</published>
    <updated>2024-12-02T05:48:12.351Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第九章-RDN"><a href="#超分辨率第九章-RDN" class="headerlink" title="超分辨率第九章-RDN"></a>超分辨率第九章-RDN</h1><blockquote><p>Residual Dense Network for Image Super-Resolution（RDN）发表于2018年的CVPR</p><p>论文地址：<a href="https://arxiv.org/abs/1802.08797">Residual Dense Network for Image Super-Resolution</a></p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><ul><li>残差密集块( RDB )，它不仅可以通过连续内存( CM )机制从前一个RDB中读取状态，还可以通过局部密集连接充分利用其内部的所有层。</li><li>局部特征融合( LFF )，自适应地保留积累的特征。</li><li>全局特征融合，以自适应地融合来自LR空间中所有RDB的分层特征。</li><li>通过全局残差学习，将浅层特征和深层特征结合在一起，从而得到原始LR图像的全局稠密特征</li><li><img src="https://s21.ax1x.com/2024/11/04/pArHBpd.png" alt="pArHBpd.png"></li><li><img src="https://s21.ax1x.com/2024/11/04/pArHsXt.png" alt="pArHsXt.png"></li></ul><h2 id="二-网络结构"><a href="#二-网络结构" class="headerlink" title="二.网络结构"></a>二.网络结构</h2><h3 id="1-RDB模块"><a href="#1-RDB模块" class="headerlink" title="1.RDB模块"></a>1.RDB模块</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RDB_Conv</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化方法，接收输入通道数inChannels，增长率growRate，以及可选的卷积核大小kSize（默认为3）  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inChannels, growRate, kSize=<span class="number">3</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(RDB_Conv, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的初始化方法  </span></span><br><span class="line">        Cin = inChannels  <span class="comment"># 输入通道数  </span></span><br><span class="line">        G  = growRate  <span class="comment"># 增长率  </span></span><br><span class="line">        <span class="comment"># 构建一个卷积层序列，包含一个2D卷积层和一个ReLU激活函数  </span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Sequential(*[  </span><br><span class="line">            nn.Conv2d(Cin, G, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>),  <span class="comment"># 2D卷积层，使用适当的填充以保持输入和输出尺寸相同  </span></span><br><span class="line">            nn.ReLU()  <span class="comment"># ReLU激活函数  </span></span><br><span class="line">        ])  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播方法，接收输入x  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        out = <span class="variable language_">self</span>.conv(x)  <span class="comment"># 通过卷积层和激活函数处理输入x  </span></span><br><span class="line">        <span class="comment"># 将处理后的输出out与原始输入x在通道维度（维度1）上拼接起来  </span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((x, out), <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 定义一个名为RDB的类，它继承自nn.Module，表示一个残差密集块  </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RDB</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, growRate0, growRate, nConvLayers, kSize=<span class="number">3</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(RDB, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的初始化方法  </span></span><br><span class="line">        G0 = growRate0  <span class="comment"># 初始特征数 </span></span><br><span class="line">        G  = growRate  <span class="comment"># 每个RDB_Conv层的最终输出特征数 </span></span><br><span class="line">        C  = nConvLayers  <span class="comment"># RDB_Conv层的数量  </span></span><br><span class="line">          </span><br><span class="line">        convs = []  <span class="comment"># 初始化一个空列表，用于存储RDB_Conv层  </span></span><br><span class="line">        <span class="comment"># 循环创建RDB_Conv层，每个层的输入通道数根据增长率和层数动态计算  </span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(C):  </span><br><span class="line">            convs.append(RDB_Conv(G0 + c*G, G))  </span><br><span class="line">        <span class="variable language_">self</span>.convs = nn.Sequential(*convs)  <span class="comment"># 将RDB_Conv层序列化为一个nn.Sequential模块  </span></span><br><span class="line">          </span><br><span class="line">        <span class="comment"># Local Feature Fusion（局部特征融合），使用一个1x1卷积层来融合所有RDB_Conv层的输出  </span></span><br><span class="line">        <span class="variable language_">self</span>.LFF = nn.Conv2d(G0 + C*G, G0, <span class="number">1</span>, padding=<span class="number">0</span>, stride=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播方法，接收输入x  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 通过所有RDB_Conv层处理输入x，并通过局部特征融合层LFF融合特征  </span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.LFF(<span class="variable language_">self</span>.convs(x)) + x  <span class="comment"># 将融合后的特征与原始输入x相加，形成残差连接</span></span><br></pre></td></tr></table></figure><h3 id="2-RDN模块"><a href="#2-RDN模块" class="headerlink" title="2.RDN模块"></a>2.RDN模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RDN</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化RDN网络，包括输入通道数、输出通道数、特征数、RDB块数、每一个RDB所含卷积层数、上采样因子  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, num_features, num_blocks, num_layers, upscale_factor</span>):  </span><br><span class="line">        <span class="built_in">super</span>(RDN, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类nn.Module的初始化方法  </span></span><br><span class="line">        r = upscale_factor  <span class="comment"># 上采样因子  </span></span><br><span class="line">        G0 = num_features  <span class="comment"># 初始特征数  </span></span><br><span class="line">        kSize = <span class="number">3</span>  <span class="comment"># 卷积核大小  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 将RDB块数、卷积层数、特征数分别赋值给D、C、G  </span></span><br><span class="line">        <span class="variable language_">self</span>.D, C, G = [num_blocks, num_layers, num_features]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 浅层特征提取网络  </span></span><br><span class="line">        <span class="variable language_">self</span>.SFENet1 = nn.Conv2d(in_channels, G0, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># 第一个卷积层  </span></span><br><span class="line">        <span class="variable language_">self</span>.SFENet2 = nn.Conv2d(G0, G0, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># 第二个卷积层  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 残差密集块和密集特征融合  </span></span><br><span class="line">        <span class="variable language_">self</span>.RDBs = nn.ModuleList()  <span class="comment"># 创建一个模块列表来存储RDB块  </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.D):  </span><br><span class="line">            <span class="variable language_">self</span>.RDBs.append(  </span><br><span class="line">                RDB(growRate0 = G0, growRate = G, nConvLayers = C)  <span class="comment"># 向列表中添加RDB块  </span></span><br><span class="line">            )  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 全局特征融合  </span></span><br><span class="line">        <span class="variable language_">self</span>.GFF = nn.Sequential(*[  </span><br><span class="line">            nn.Conv2d(<span class="variable language_">self</span>.D * G0, G0, <span class="number">1</span>, padding=<span class="number">0</span>, stride=<span class="number">1</span>),  <span class="comment"># 1x1卷积层，用于融合RDB块的输出  </span></span><br><span class="line">            nn.Conv2d(G0, G0, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># 3x3卷积层  </span></span><br><span class="line">        ])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 上采样网络  </span></span><br><span class="line">        <span class="keyword">if</span> r == <span class="number">2</span> <span class="keyword">or</span> r == <span class="number">3</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.UPNet = nn.Sequential(*[  </span><br><span class="line">                nn.Conv2d(G0, G * r * r, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>),  <span class="comment"># 卷积层，调整通道数以匹配PixelShuffle  </span></span><br><span class="line">                nn.PixelShuffle(r),  <span class="comment"># PixelShuffle层，实现上采样  </span></span><br><span class="line">                nn.Conv2d(G, out_channels, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># 输出卷积层  </span></span><br><span class="line">            ])  </span><br><span class="line">        <span class="keyword">elif</span> r == <span class="number">4</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.UPNet = nn.Sequential(*[  </span><br><span class="line">                nn.Conv2d(G0, G * <span class="number">2</span> * <span class="number">2</span>, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>),  <span class="comment"># 第一步卷积层  </span></span><br><span class="line">                nn.PixelShuffle(<span class="number">2</span>),  <span class="comment"># 第一次PixelShuffle，上采样2倍  </span></span><br><span class="line">                nn.Conv2d(G, G * <span class="number">2</span> * <span class="number">2</span>, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>),  <span class="comment"># 第二步卷积层  </span></span><br><span class="line">                nn.PixelShuffle(<span class="number">2</span>),  <span class="comment"># 第二次PixelShuffle，再次上采样2倍，总共4倍  </span></span><br><span class="line">                nn.Conv2d(G, out_channels, kSize, padding=(kSize-<span class="number">1</span>)//<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># 输出卷积层  </span></span><br><span class="line">            ])  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;scale must be 2 or 3 or 4.&quot;</span>)  <span class="comment"># 如果上采样因子不是2、3或4，抛出错误  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        f__1 = <span class="variable language_">self</span>.SFENet1(x)  <span class="comment"># 通过第一个浅层特征提取网络  </span></span><br><span class="line">        x  = <span class="variable language_">self</span>.SFENet2(f__1)  <span class="comment"># 通过第二个浅层特征提取网络  </span></span><br><span class="line">  </span><br><span class="line">        RDBs_out = []  <span class="comment"># 创建一个列表来存储RDB块的输出  </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.D):  </span><br><span class="line">            x = <span class="variable language_">self</span>.RDBs[i](x)  <span class="comment"># 通过每个RDB块  </span></span><br><span class="line">            RDBs_out.append(x)  <span class="comment"># 将RDB块的输出添加到列表中  </span></span><br><span class="line">  </span><br><span class="line">        x = <span class="variable language_">self</span>.GFF(torch.cat(RDBs_out,<span class="number">1</span>))  <span class="comment"># 将所有RDB块的输出拼接起来，并通过全局特征融合网络  </span></span><br><span class="line">        x += f__1  <span class="comment"># 将全局特征融合的输出与第一个浅层特征提取网络的输出相加，形成残差连接  </span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.UPNet(x)  <span class="comment"># 通过上采样网络，输出最终结果  </span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第九章-RDN&quot;&gt;&lt;a href=&quot;#超分辨率第九章-RDN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第九章-RDN&quot;&gt;&lt;/a&gt;超分辨率第九章-RDN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Residual Dense Network for Image Super-Resolution（RDN）发表于2018年的CVPR&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1802.08797&quot;&gt;Residual Dense Network for Image Super-Resolution&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第八章-SR&amp;transformer</title>
    <link href="http://example.com/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&amp;transformer/"/>
    <id>http://example.com/2024/10/28/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AB%E7%AB%A0-SR&amp;transformer/</id>
    <published>2024-10-28T02:26:24.000Z</published>
    <updated>2024-11-04T14:07:22.650Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第八章-SR-amp-transformer"><a href="#超分辨率第八章-SR-amp-transformer" class="headerlink" title="超分辨率第八章-SR&amp;transformer"></a>超分辨率第八章-SR&amp;transformer</h1><blockquote><p><strong>超分辨率中的transformer-应用于MRI</strong></p><p>文献一：<a href="https://ieeexplore.ieee.org/document/9746092">3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution</a>：ICASSP 2022会议</p><p>文献二：<a href="https://www.sciencedirect.com/science/article/pii/S1746809421009368">Adjacent slices feature transformer network for single anisotropic 3D brain MRI image super-resolution</a>：《Biomedical Signal Processing and Control》 期刊，2022 </p></blockquote><span id="more"></span><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="1-attention"><a href="#1-attention" class="headerlink" title="1.attention"></a>1.attention</h3><ul><li><p>参考视频：<a href="https://www.bilibili.com/video/BV15v411W78M?spm_id_from=333.788.videopod.sections&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">Transformer中Self-Attention以及Multi-Head Attention详解</a></p></li><li><p><strong>通过 Query (查询对象) 这个信息从 Values （被查询对象）中筛选出重要信息，简单点说，就是计算 Query 和 Values 中每个信息的相关程度</strong>。</p></li><li><p>通过上图，Attention 通常可以进行如下描述，表示为将 Query(Q) 和 key-value pairs（<strong>把 Values 拆分成了键值对</strong>) 映射到输出上，其中 query、每个 key、每个 value 都是向量，输出是 <strong>V （被查询对象）中所有 values 的加权</strong>，其中<strong>权重是由 Query 和每个 key 计算出来</strong>的，计算方法分为三步：</p><ul><li>第一步：Query与每一个Key计算相似性得到相似性评分s</li><li>第二步：将s评分进行softmax转换成[0,1]之间的概率分布</li><li>第三步：将[a1,a2,a3…an]作为权值矩阵对Value进行加权求和得到最后的Attention值</li><li><script type="math/tex; mode=display">A t t e n t i o n ( Q , K , V ) = s o f t m a x ( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } ) V</script><ul><li><p><img src="https://s21.ax1x.com/2024/11/01/pADWF9f.png" alt="pADWF9f.png"></p><p><img src="https://s21.ax1x.com/2024/11/01/pAD46rF.png" alt="pAD46rF.png"></p></li></ul></li></ul></li><li><p>多头注意力机制</p><ul><li><p>首先将q、k、v序列进行均分，分为head组</p><ul><li><p><img src="https://s21.ax1x.com/2024/11/01/pADhPl8.png" alt="pADhPl8.png"></p></li><li><p><img src="https://s21.ax1x.com/2024/11/01/pADhnf0.png" alt="pADhnf0.png"></p></li></ul></li><li><p>分别计算各head的注意力</p><ul><li><img src="https://s21.ax1x.com/2024/11/01/pADhlXF.png" alt="pADhlXF.png"></li></ul></li><li><p>将各head的值进行拼接</p><ul><li><img src="https://s21.ax1x.com/2024/11/01/pADhap6.png" alt="pADhap6.png"></li></ul></li><li><p>使用Wo进行融合</p><ul><li><img src="https://s21.ax1x.com/2024/11/01/pADh6AA.png" alt="pADh6AA.png"></li></ul></li></ul></li></ul><h3 id="2-通道注意力机制与空间注意力机制"><a href="#2-通道注意力机制与空间注意力机制" class="headerlink" title="2.通道注意力机制与空间注意力机制"></a>2.通道注意力机制与空间注意力机制</h3><ul><li>通道注意力机制<ul><li>通道注意力机制的代表模型是：压缩和激励网络(Squeeze-and-Excitation Networks,SENet)</li><li>SENet分为压缩和激励两个部分，其中压缩部分的目的是对全局空间信息进行压缩，然后在通道维度进行特征学习，形成各个通对道的重要性，最后通过激励部分对各个通道进行分配不同权重的。</li><li><img src="https://s21.ax1x.com/2024/10/29/pA0qj3R.png" alt="pA0qj3R.png"></li><li>上图是SE模块的结构，在压缩部分，输入的元素特征图的维度是H×WxC，H、W和C分别代表高度、宽度和通道数。压缩部分的功能是将维数从H×W×C压缩至1×1×C，即把H×W压缩为1×1维，<strong>这个过程由空间维度的全局平均池化实现</strong>。</li><li>在激励部分，需要将压缩部分得到的1×1×C的维度融入全连接层，预测各个通道的重要程度，然后再激励到前面特征图对应通道上进行操作。<strong>采用简单的门控机制与Sigmoid激活函数</strong>。</li></ul></li><li>空间注意力机制<ul><li><img src="https://s21.ax1x.com/2024/10/29/pA0LACd.png" alt="pA0LACd.png"></li><li>首先，对一个尺寸为 H×W×C的输入特征图F进行<strong>通道维度的全局最大池化和全局平均池化</strong>，得到两个 H×W×1 的特征图（在通道维度进行池化，压缩通道大小，便于后面学习空间的特征）</li><li>然后，将全局最大池化和全局平均池化的结果，按照通道拼接(concat)，得到特征图尺寸为HxWx2，</li><li>最后，对拼接的结果进行卷积操作，得到特征图尺寸为 HxWx1</li><li>接着通过Sigmoid激活函数 ，得到空间注意力权重矩阵 </li></ul></li></ul><h3 id="3-transformer"><a href="#3-transformer" class="headerlink" title="3.transformer"></a>3.transformer</h3><ul><li>参考视频：<a href="https://www.bilibili.com/video/BV1UL411g7aX/?spm_id_from=333.1365.top_right_bar_window_default_collection.content.click&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">手推transformer</a><ul><li>2017年提出，分为encoder与decoder两个部分</li><li>input embedding：可以将高维的离散输入数据转换为低维的连续向量表示</li><li>位置编码（Positional Encoding）：由于Transformer没有内置的序列位置信息，它需要额外的位置编码来表达输入序列中单词的位置顺序。</li><li>多头注意力（Multi-Head Attention）：Transformer中的自注意力机制被扩展为多个注意力头，每个头可以学习不同的注意权重，以更好地捕捉不同类型的关系。多头注意力允许模型并行处理不同的信息子空间。</li><li><img src="https://s21.ax1x.com/2024/11/01/pADRO1O.png" alt="pADRO1O.png"></li></ul></li></ul><h3 id="4-vision-transformer"><a href="#4-vision-transformer" class="headerlink" title="4.vision transformer"></a>4.vision transformer</h3><ul><li><p>参考视频：<a href="https://www.bilibili.com/video/BV1Jh411Y7WQ?spm_id_from=333.788.videopod.sections&amp;vd_source=f9578e20917b03f6b5eb19c9031cefd2">Vision Transformer(vit)网络详解</a></p></li><li><p>简称vit，2020年提出</p></li><li><p>网络结构</p><ul><li>patch embedding&amp;Linear Projection of Flattened Patches：<ul><li><strong>将输入的2维图像（3通道）分割为多个小块（patches）(若干个不重叠的 patch)，并将每个小块映射到特定维度的嵌入（embedding）向量空间中，原来的一个图像块patch（3通道）映射成特征图的一个像素点（值）</strong></li><li>将输入图片(224x224)按照16x16大小的Patch进行划分，划分后会得到$(224/16)^2=14^2=196$个Patches。接着通过线性映射将每个Patch映射到一维向量中，以ViT-B/16为例，每个Patche数据shape为<strong>[16, 16, 3]</strong>，<strong>每个 patch 最终会被映射到 768 维的向量空间</strong><ul><li>输入图片<224，224，3>经过卷积核（16*16）得到<14，14，768>，再经过展平得到<196，768></196，768></14，14，768></224，224，3></li></ul></li></ul></li><li>class token与position embedding<ul><li>token与分类token拼接得到<197，768>，之后再与位置embedding相加得到具有分类与位置信息的token</197，768></li></ul></li><li>encoder：12个编码器堆叠而成，进行多头自注意力计算</li><li>extract class token：通过编码器之后，在进入MLP head之前，需要将分类token提取出来，此时<197，768> -&gt; <1，768></1，768></197，768></li><li>MLP Head：原论文中说在训练ImageNet21K时是由<code>Linear</code>+<code>tanh激活函数</code>+<code>Linear</code>组成。但是迁移到ImageNet1K上或者你自己的数据上时，只用一个<code>Linear</code>即可。</li><li><img src="https://s21.ax1x.com/2024/11/01/pADWuEn.png" alt="pADWuEn.png"></li></ul></li><li><p>流程</p><ul><li><strong>Q,K,V的生成使用全连接层模拟</strong></li><li><img src="https://s21.ax1x.com/2024/11/01/pADW3gU.png" alt="pADW3gU.png"></li></ul></li><li><p>模型参数</p><ul><li><img src="https://s21.ax1x.com/2024/11/02/pADxM3F.png" alt="pADxM3F.png"></li></ul></li></ul><h3 id="5-vit代码"><a href="#5-vit代码" class="headerlink" title="5.vit代码"></a>5.vit代码</h3><h4 id="①patch-embedding块"><a href="#①patch-embedding块" class="headerlink" title="①patch embedding块"></a>①patch embedding块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span></span>):   </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># 将输入的img_size转换为二维元组，假设图像是正方形  </span></span><br><span class="line">        img_size = (img_size, img_size)  </span><br><span class="line">        <span class="comment"># 将输入的patch_size转换为二维元组，表示每个patch的大小  </span></span><br><span class="line">        patch_size = (patch_size, patch_size)   </span><br><span class="line">        <span class="comment"># 存储图像的尺寸  </span></span><br><span class="line">        <span class="variable language_">self</span>.img_size = img_size  </span><br><span class="line">        <span class="comment"># 存储每个patch的尺寸  </span></span><br><span class="line">        <span class="variable language_">self</span>.patch_size = patch_size  </span><br><span class="line">        <span class="comment"># 计算图像被划分成多少个patch（网格大小）  </span></span><br><span class="line">        <span class="variable language_">self</span>.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])  </span><br><span class="line">        <span class="comment"># 计算总的patch数量  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_patches = <span class="variable language_">self</span>.grid_size[<span class="number">0</span>] * <span class="variable language_">self</span>.grid_size[<span class="number">1</span>]  </span><br><span class="line">        <span class="comment"># 定义一个卷积层，用于将图像划分为patch，并将每个patch映射到嵌入向量空间  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)   </span><br><span class="line">        <span class="comment"># 定义一个可选的归一化层，如果norm_layer为None，则使用nn.Identity()作为占位符，不进行归一化  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 提取输入x的批次大小、通道数、高度和宽度  </span></span><br><span class="line">        B, C, H, W = x.shape  </span><br><span class="line">        <span class="comment"># 断言输入图像的大小与模型期望的大小匹配  </span></span><br><span class="line">        <span class="keyword">assert</span> H == <span class="variable language_">self</span>.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == <span class="variable language_">self</span>.img_size[<span class="number">1</span>], \  </span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span>  </span><br><span class="line">        <span class="comment"># flatten: [B, C, H, W] -&gt; [B, C, HW]</span></span><br><span class="line">        <span class="comment"># transpose: [B, C, HW] -&gt; [B, HW, C]  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  </span><br><span class="line">        <span class="comment"># 对嵌入向量进行归一化  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)   </span><br><span class="line">        <span class="comment"># 返回处理后的嵌入向量  </span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h4 id="②-multi-head-attention块"><a href="#②-multi-head-attention块" class="headerlink" title="② multi-head attention块"></a>② multi-head attention块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,  </span></span><br><span class="line"><span class="params">                 dim,   <span class="comment"># 输入token的特征维度（dim）  </span></span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">8</span>,  <span class="comment"># 多头注意力机制中头的数量  </span></span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,  <span class="comment"># qkv线性变换是否使用偏置项  </span></span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,  <span class="comment"># q和k相乘后的缩放因子，默认为head_dim的负0.5次方  </span></span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,  <span class="comment"># attention分数应用dropout的比率  </span></span></span><br><span class="line"><span class="params">                 proj_drop_ratio=<span class="number">0.</span></span>):  <span class="comment"># 最终投影后应用dropout的比率  </span></span><br><span class="line">        <span class="built_in">super</span>(Attention, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads  <span class="comment"># 存储头的数量  </span></span><br><span class="line">        head_dim = dim // num_heads  <span class="comment"># 每个头的特征维度  </span></span><br><span class="line">        <span class="variable language_">self</span>.scale = qk_scale <span class="keyword">or</span> head_dim ** -<span class="number">0.5</span>  <span class="comment"># 计算缩放因子  </span></span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)  <span class="comment"># qkv的线性变换，输出是输入的3倍，对应q, k, v ,使用全连接层模拟</span></span><br><span class="line">        <span class="variable language_">self</span>.attn_drop = nn.Dropout(attn_drop_ratio)  <span class="comment"># attention分数的dropout  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Linear(dim, dim)  <span class="comment"># 最终的线性投影  </span></span><br><span class="line">        <span class="variable language_">self</span>.proj_drop = nn.Dropout(proj_drop_ratio)  <span class="comment"># 投影后的dropout  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># x的形状为[batch_size, num_patches + 1, total_embed_dim]  </span></span><br><span class="line">        B, N, C = x.shape  <span class="comment"># 分别获取batch大小、序列长度和特征维度  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 通过qkv线性变换，得到[batch_size, num_patches + 1, 3 * total_embed_dim]  </span></span><br><span class="line">        <span class="comment">#reshape操作将张量重塑为[batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]的形状，其中num_heads是多头注意力中的头数，embed_dim_per_head是每个头的特征维度（即总特征维度除以头数）。</span></span><br><span class="line">        <span class="comment">#permute操作则是为了调整张量的维度顺序，使其更便于后续处理。经过permute操作后，张量的形状变为[3, batch_size, num_heads,num_patches + 1, embed_dim_per_head]。   </span></span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x).reshape(B, N, <span class="number">3</span>, <span class="variable language_">self</span>.num_heads, C // <span class="variable language_">self</span>.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)  </span><br><span class="line">        <span class="comment">#分别获取q, k, v，这里的索引操作是基于第一维进行的。由于q、k、v分别对应着这一维上的前、中、后三个部分，因此我们可以通过索引0、1、2来分别获取它们。  </span></span><br><span class="line">        q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]  <span class="comment">#[batch_size, num_heads,num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># transpose: -&gt; [batch_size, num_heads, embed_dim_per_head, num_patches + 1]</span></span><br><span class="line">        <span class="comment"># @: multiply -&gt; [batch_size, num_heads, num_patches + 1, num_patches + 1] </span></span><br><span class="line">        <span class="comment"># 接着乘以缩放因子，应用softmax进行归一化，最后应用dropout</span></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * <span class="variable language_">self</span>.scale  </span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)  </span><br><span class="line">        attn = <span class="variable language_">self</span>.attn_drop(attn)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 使用attention分数对v进行加权计算，得到[batch_size, num_heads, num_patches + 1, embed_dim_per_head]  </span></span><br><span class="line">        <span class="comment"># 然后transpose和reshape操作，将结果转换回[batch_size, num_patches + 1, total_embed_dim]  </span></span><br><span class="line">        x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)  </span><br><span class="line">        <span class="comment"># 对结果进行最终的线性投影  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x)  </span><br><span class="line">        <span class="comment"># 应用dropout后返回最终结果  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj_drop(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br></pre></td></tr></table></figure><h4 id="③MLP块"><a href="#③MLP块" class="headerlink" title="③MLP块"></a>③MLP块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置输入特征数、隐藏层特征数（默认为输入特征数）、输出特征数（默认为输入特征数）、激活层（默认为GELU）、丢弃率  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  <span class="comment"># 调用父类初始化方法  </span></span><br><span class="line">        <span class="comment"># 如果没有指定输出特征数，则默认为输入特征数  </span></span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features  </span><br><span class="line">        <span class="comment"># 如果没有指定隐藏层特征数，则默认为输入特征数  </span></span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features  </span><br><span class="line">        <span class="comment"># 定义第一个全连接层，将输入特征数映射到隐藏层特征数  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(in_features, hidden_features)  </span><br><span class="line">        <span class="comment"># 定义激活层，默认为GELU  </span></span><br><span class="line">        <span class="variable language_">self</span>.act = act_layer()  </span><br><span class="line">        <span class="comment"># 定义第二个全连接层，将隐藏层特征数映射到输出特征数  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(hidden_features, out_features)  </span><br><span class="line">        <span class="comment"># 定义丢弃层，用于防止过拟合  </span></span><br><span class="line">        <span class="variable language_">self</span>.drop = nn.Dropout(drop)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):   </span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.act(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.drop(x)   </span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)   </span><br><span class="line">        x = <span class="variable language_">self</span>.drop(x)   </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="④encoder-block块"><a href="#④encoder-block块" class="headerlink" title="④encoder block块"></a>④encoder block块</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置维度、头数、MLP比率、qkv偏置、qk缩放、丢弃率、注意力丢弃率、路径丢弃率、激活层、归一化层  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,  </span></span><br><span class="line"><span class="params">                 dim,  </span></span><br><span class="line"><span class="params">                 num_heads,  </span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>,  </span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,  </span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">                 drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 drop_path_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU,  </span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Block, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化方法  </span></span><br><span class="line">        <span class="comment"># 定义第一个归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm1 = norm_layer(dim)  </span><br><span class="line">        <span class="comment"># 定义注意力机制层  </span></span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,  </span><br><span class="line">                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)  </span><br><span class="line">        <span class="comment"># 如果路径丢弃率大于0，则定义路径丢弃层，否则使用恒等操作（即不改变输入）  </span></span><br><span class="line">        <span class="variable language_">self</span>.drop_path = DropPath(drop_path_ratio) <span class="keyword">if</span> drop_path_ratio &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">        <span class="comment"># 定义第二个归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm2 = norm_layer(dim)  </span><br><span class="line">        <span class="comment"># 计算MLP隐藏层维度  </span></span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)  </span><br><span class="line">        <span class="comment"># 定义MLP层  </span></span><br><span class="line">        <span class="variable language_">self</span>.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># x加上经过归一化、注意力机制、路径丢弃处理后的结果  </span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x)))  </span><br><span class="line">        <span class="comment"># x再加上经过归一化、MLP、路径丢弃处理后的结果  </span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.mlp(<span class="variable language_">self</span>.norm2(x)))  </span><br><span class="line">        <span class="comment"># 返回最终结果  </span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h4 id="⑤vit整体结构"><a href="#⑤vit整体结构" class="headerlink" title="⑤vit整体结构"></a>⑤vit整体结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个VisionTransformer类，继承自nn.Module，用于图像分类等任务  </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置多个参数，包括图像大小、块大小、输入通道数、类别数、嵌入维度、encoder个数、head数量、mlp缩放倍数等 </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, num_classes=<span class="number">1000</span>,  </span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.0</span>, qkv_bias=<span class="literal">True</span>,  </span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>, distilled=<span class="literal">False</span>, drop_ratio=<span class="number">0.</span>,  </span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>, drop_path_ratio=<span class="number">0.</span>, embed_layer=PatchEmbed, norm_layer=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">                 act_layer=<span class="literal">None</span></span>):  </span><br><span class="line">          </span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, <span class="variable language_">self</span>).__init__()   </span><br><span class="line">        <span class="comment"># 设置类别数和嵌入维度（也作为特征数）  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_classes = num_classes  </span><br><span class="line">        <span class="variable language_">self</span>.num_features = <span class="variable language_">self</span>.embed_dim = embed_dim  </span><br><span class="line">        <span class="comment"># 设置token数量，该模型设置为1  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_tokens = <span class="number">2</span> <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 如果没有指定归一化层，则默认为LayerNorm，并设置eps为1e-6  </span></span><br><span class="line">        norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)  </span><br><span class="line">        <span class="comment"># 如果没有指定激活层，则默认为GELU  </span></span><br><span class="line">        act_layer = act_layer <span class="keyword">or</span> nn.GELU  </span><br><span class="line">        <span class="comment"># 定义图像块嵌入层，将图像分割成小块并嵌入到高维空间中  </span></span><br><span class="line">        <span class="variable language_">self</span>.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim)  </span><br><span class="line">        <span class="comment"># 获取图像块的数量  </span></span><br><span class="line">        num_patches = <span class="variable language_">self</span>.patch_embed.num_patches  </span><br><span class="line">        <span class="comment"># 初始化类别token和蒸馏token（可忽略）  </span></span><br><span class="line">        <span class="variable language_">self</span>.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))  </span><br><span class="line">        <span class="variable language_">self</span>.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim)) <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="literal">None</span>  </span><br><span class="line">        <span class="comment"># 初始化位置嵌入  </span></span><br><span class="line">        <span class="variable language_">self</span>.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="variable language_">self</span>.num_tokens, embed_dim))  </span><br><span class="line">        <span class="comment"># 定义位置嵌入的丢弃层  </span></span><br><span class="line">        <span class="variable language_">self</span>.pos_drop = nn.Dropout(p=drop_ratio)  </span><br><span class="line">        <span class="comment"># 根据深度生成每个Block的路径丢弃率（使用随机深度衰减规则）  </span></span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_ratio, depth)]   </span><br><span class="line">        <span class="comment"># 定义一系列Block，每个Block包含注意力机制和MLP  </span></span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.Sequential(*[  </span><br><span class="line">            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,  </span><br><span class="line">                  drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i],  </span><br><span class="line">                  norm_layer=norm_layer, act_layer=act_layer)  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)  </span><br><span class="line">        ])     </span><br><span class="line">        <span class="comment"># 定义最后的归一化层  </span></span><br><span class="line">        <span class="variable language_">self</span>.norm = norm_layer(embed_dim)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 如果指定了表示层的大小且不是蒸馏模型，则定义表示层 mlp head </span></span><br><span class="line">        <span class="keyword">if</span> representation_size <span class="keyword">and</span> <span class="keyword">not</span> distilled:  </span><br><span class="line">            <span class="variable language_">self</span>.has_logits = <span class="literal">True</span>  </span><br><span class="line">            <span class="variable language_">self</span>.num_features = representation_size  </span><br><span class="line">            <span class="variable language_">self</span>.pre_logits = nn.Sequential(OrderedDict([  </span><br><span class="line">                (<span class="string">&quot;fc&quot;</span>, nn.Linear(embed_dim, representation_size)),  </span><br><span class="line">                (<span class="string">&quot;act&quot;</span>, nn.Tanh())  </span><br><span class="line">            ]))  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.has_logits = <span class="literal">False</span>  </span><br><span class="line">            <span class="variable language_">self</span>.pre_logits = nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 定义分类头，如果类别数大于0则定义线性层，否则为恒等操作  </span></span><br><span class="line">        <span class="variable language_">self</span>.head = nn.Linear(<span class="variable language_">self</span>.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 如果蒸馏模型，则定义额外的分类头（可忽略）  </span></span><br><span class="line">        <span class="variable language_">self</span>.head_dist = <span class="literal">None</span>  </span><br><span class="line">        <span class="keyword">if</span> distilled:  </span><br><span class="line">            <span class="variable language_">self</span>.head_dist = nn.Linear(<span class="variable language_">self</span>.embed_dim, <span class="variable language_">self</span>.num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 初始化权重  </span></span><br><span class="line">        nn.init.trunc_normal_(<span class="variable language_">self</span>.pos_embed, std=<span class="number">0.02</span>)  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            nn.init.trunc_normal_(<span class="variable language_">self</span>.dist_token, std=<span class="number">0.02</span>)  </span><br><span class="line">        nn.init.trunc_normal_(<span class="variable language_">self</span>.cls_token, std=<span class="number">0.02</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.apply(_init_vit_weights)  <span class="comment"># 应用自定义的权重初始化函数  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 定义前向传播函数（特征提取部分）  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 将输入图像通过图像块嵌入层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.patch_embed(x)  </span><br><span class="line">        <span class="comment"># 扩展类别token的维度以匹配输入批次大小  </span></span><br><span class="line">        cls_token = <span class="variable language_">self</span>.cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 根据是否有蒸馏token，将类别token（和蒸馏token）与图像块嵌入拼接  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            x = torch.cat((cls_token, x), dim=<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            x = torch.cat((cls_token, <span class="variable language_">self</span>.dist_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>), x), dim=<span class="number">1</span>)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 将位置嵌入加到输入上，并通过位置嵌入的丢弃层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.pos_drop(x + <span class="variable language_">self</span>.pos_embed)  </span><br><span class="line">        <span class="comment"># 将输入通过一系列Block  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.blocks(x)  </span><br><span class="line">        <span class="comment"># 通过最后的归一化层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)  </span><br><span class="line">        <span class="comment"># 根据是否有蒸馏token，返回不同的输出  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.dist_token <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.pre_logits(x[:, <span class="number">0</span>])  <span class="comment"># 提取class token(应用此项)</span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">return</span> x[:, <span class="number">0</span>], x[:, <span class="number">1</span>]  <span class="comment"># 返回类别token和蒸馏token对应的表示  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 定义完整的前向传播函数（包括分类头）  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 通过前向传播函数（特征提取部分）获取表示  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.forward_features(x)    </span><br><span class="line">        <span class="comment"># 如果是蒸馏模型，则分别通过两个分类头获取预测结果  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.head_dist <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            x, x_dist = <span class="variable language_">self</span>.head(x[<span class="number">0</span>]), <span class="variable language_">self</span>.head_dist(x[<span class="number">1</span>])  </span><br><span class="line">            <span class="comment"># 如果是训练模式且不是在使用TorchScript，则返回两个分类头的预测结果  </span></span><br><span class="line">            <span class="comment"># 否则，返回两个分类头预测结果的平均值（用于推理）  </span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> <span class="keyword">not</span> torch.jit.is_scripting():  </span><br><span class="line">                <span class="keyword">return</span> x, x_dist  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="keyword">return</span> (x + x_dist) / <span class="number">2</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 如果不是蒸馏模型，则只通过一个分类头获取预测结果   (应用此项)</span></span><br><span class="line">            x = <span class="variable language_">self</span>.head(x)  </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="一-文献一（CFTN）"><a href="#一-文献一（CFTN）" class="headerlink" title="一.文献一（CFTN）"></a>一.文献一（CFTN）</h2><p><strong>3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution（CFTN）</strong></p><h3 id="1-文献介绍"><a href="#1-文献介绍" class="headerlink" title="1.文献介绍"></a>1.文献介绍</h3><h4 id="①先前模型的缺点"><a href="#①先前模型的缺点" class="headerlink" title="①先前模型的缺点"></a>①先前模型的缺点</h4><ul><li>仅探索外部图像资源，没有挖掘<strong>内部先验</strong>，在针对特定MR图像和大规模SR重建精细纹理方面仍然存在不足。</li></ul><h4 id="②关于内部先验（internal-priors）"><a href="#②关于内部先验（internal-priors）" class="headerlink" title="②关于内部先验（internal priors）"></a>②关于内部先验（internal priors）</h4><p>先验知识：</p><blockquote><p>图片处理中的先验知识是指在处理图像时使用的已知信息或假设。以下是一些常见的图片处理先验知识及其应用：</p><ol><li><strong>平滑性先验</strong>：<ul><li><strong>应用</strong>：假设图像中像素值变化较为平滑，这种假设在去噪、去模糊等任务中非常有用。通过这个先验，可以确保图像的平滑区域保持一致，而不引入伪影。</li></ul></li><li><strong>稀疏性先验</strong>：<ul><li><strong>应用</strong>：假设图像在某个变换域（如傅里叶变换或小波变换）中是稀疏的，即大多数变换系数接近于零。这一先验在图像压缩和重建中非常重要。</li></ul></li><li><strong>边缘先验</strong>：<ul><li><strong>应用</strong>：假设图像中存在明显的边缘和轮廓。边缘先验在边缘检测、图像分割和超分辨率重建中有很大作用，能够帮助模型更好地识别和恢复图像中的细节。</li></ul></li><li><strong>结构先验</strong>：<ul><li><strong>应用</strong>：假设图像具有某些已知的结构特性，如对称性和纹理。这些先验在图像修复、去雾等任务中可以显著提高性能。</li></ul></li></ol><p>在深度学习模型中，先验知识可以通过设计合适的损失函数、网络结构或通过预训练的方式融入模型中，从而提升模型的处理能力和泛化能力。</p></blockquote><p>内部先验与外部先验：</p><blockquote><p><strong>内部先验</strong>：</p><ul><li><strong>定义</strong>：基于输入图像本身的特性和信息的先验知识。</li><li><strong>例子</strong>：图像的平滑性、边缘特性、局部一致性等。在图像去噪中，假设图像的某些部分应该是平滑的或者连贯的，这就是一种内部先验。</li><li><strong>应用</strong>：例如图像增强、去噪、去模糊等任务，通过分析和利用图像自身的统计特性和结构信息来提升处理效果。</li></ul><p><strong>外部先验</strong>：</p><ul><li><strong>定义</strong>：来自于输入图像之外的额外知识或数据的先验信息。</li><li><strong>例子</strong>：预训练模型的权重、从大型数据集中学习到的统计规律等。在图像分类任务中，使用从大量标注数据中学到的特征，可以作为一种强有力的外部先验。</li><li><strong>应用</strong>：例如图像识别、语义分割等任务，通过利用大规模数据训练的模型来提供外部先验，增强模型的泛化能力和准确性。</li></ul></blockquote><p>超分辨率中：</p><blockquote><p><strong>内部先验</strong>：</p><ul><li><strong>定义</strong>：利用图像自身的特性和结构信息来提高重建质量。</li><li><strong>应用</strong>：在超分辨率任务中，内部先验可以帮助模型保留和强化图像的细节和纹理。例如，通过分析低分辨率图像中的边缘和纹理信息，可以生成更清晰、更细致的高分辨率图像。此外，内部先验还可以帮助模型减少噪声和伪影，使得重建结果更加自然。</li></ul><p><strong>外部先验</strong>：</p><ul><li><strong>定义</strong>：依靠外部数据或预训练模型的知识来辅助图像重建。</li><li><strong>应用</strong>：在超分辨率任务中，外部先验通常通过预训练模型来实现。这些模型在大量高分辨率和低分辨率图像对上进行了训练，学到了如何从低分辨率图像中恢复出高分辨率细节。例如，GAN（生成对抗网络）和VDSR（超深卷积神经网络）等方法都依赖于外部先验，通过使用大规模数据集进行训练，模型能够捕捉到更丰富的细节和结构信息，从而生成质量更高的高分辨率图像。</li></ul></blockquote><h4 id="③文章贡献"><a href="#③文章贡献" class="headerlink" title="③文章贡献"></a>③文章贡献</h4><ul><li>CFTN自适应地将MRI特征的<strong><u>全局跨尺度自相似先验</u></strong>集成到深度网络中。<ul><li>全局跨尺度自相似性先验（the global cross-scale self-similarity priors）<ul><li><strong>“全局跨尺度自相似先验 (global cross-scale self-similarity priors)”是指在不同尺度（大小）上存在的全局图像特征的相似性。这些先验知识用于指导深度网络在图像处理任务中更好地重建和保留图像细节。</strong></li><li>在图像超分辨率等任务中，图像的局部区域可能在不同的尺度上显示出相似的模式。例如，一个物体的纹理或边缘在不同分辨率下可能看起来相似。利用这些自相似性先验，模型可以更有效地填补低分辨率图像中的细节，从而生成高质量的高分辨率图像。</li></ul></li></ul></li><li>mutual-projection feature enhancement module（MFEM）<ul><li>CFTN对整个MR特征内的跨尺度相关性进行建模，可以捕捉MR特征内的跨尺度自相似性先验。</li></ul></li><li>spatial attention fusion module（SAFM）<ul><li>通过空间注意力融合模块削弱无用的跨尺度特征并增强重要的信息区域。</li><li>可以自适应地调整和融合目标尺度特征和上采样特征</li></ul></li></ul><h3 id="2-网络结构（CFTN）"><a href="#2-网络结构（CFTN）" class="headerlink" title="2.网络结构（CFTN）"></a>2.网络结构（CFTN）</h3><p><img src="https://s21.ax1x.com/2024/10/28/pA0d3LD.png" alt="pA0d3LD.png"></p><h4 id="①residual-channel-attention-block-RCAB"><a href="#①residual-channel-attention-block-RCAB" class="headerlink" title="①residual channel attention block (RCAB)"></a>①residual channel attention block (RCAB)</h4><ul><li>作为主干网络的基本单元，该模块来自”RCAN”</li><li><img src="https://s21.ax1x.com/2024/09/27/pAlfQeA.png" alt="pAlfQeA.png"></li></ul><p><img src="https://s21.ax1x.com/2024/09/27/pAlfsYV.png" alt="pAlfsYV.png"></p><h4 id="②mutual-projection-feature-enhancement-module-MFEM"><a href="#②mutual-projection-feature-enhancement-module-MFEM" class="headerlink" title="②mutual-projection feature enhancement module (MFEM)"></a>②mutual-projection feature enhancement module (MFEM)</h4><ul><li><strong>原理：对于超分辨率等任务，在不同尺度上的特征有更丰富的细节和纹理。</strong></li><li><p>结构:</p><ul><li><strong>融合低尺度特征权重的$Y_m$与原始图片上采样残差连接后，组合为 $Y^{‘}_m$ 。输出带有 HR 细节的目标尺度特征 $Y^{‘}_m$ 和相应的下采样特征 $X^{‘}_m$</strong></li><li>$X^{‘}_m$作为$RCAB_{m+1}$的输入，使网络探索更多跨尺度的信息。</li><li><img src="https://s21.ax1x.com/2024/10/28/pA0wgBD.png" alt="pA0wgBD.png"></li></ul></li><li><p><strong>Cross-scale Transformer（CST）</strong></p><ul><li>结构（通过transform结构可以学习到低尺度-高尺度对的相似性，可生成对应的权重）<ul><li>将输入的$x_m$降维得到$z_m$</li><li>embedding（1*1*1）：将高维的离散数据映射到低维的连续向量空间中，使得相似的数据点在向量空间中距离更近，分别展开形成V,Q,K</li><li>Q：高尺度图片序列，K：低尺度图片序列，通过size=p、stride=g，将序列展开为各p个块$q_i$ and $k_j$，即：<ul><li><script type="math/tex; mode=display">i \in \left[ 1 , \frac { H } { g } \times \frac { W } { g } \times \frac { L } { g } \right]</script></li><li><script type="math/tex; mode=display">j \in \left[ 1 , \frac { H } { r g } \times \frac { W } { r g } \times \frac { L } { r g } \right]</script></li></ul></li><li>之后将两个特征矩阵进行点乘，并经过softmax层进行归一化，生成高-低对尺度图片的特征相似度的权重。<ul><li><script type="math/tex; mode=display">s _ { i , j } = \langle q _ { i } , k _ { j } \rangle</script></li><li><script type="math/tex; mode=display">\omega _ { i , j } = \frac { e x p ( s _ { i , j } ) } { \sum _ { j } e x p ( s _ { i , j } ) }</script></li></ul></li><li>再将该权重与vi（高尺度，上升r倍）序列逐元素相乘得到具有跨尺度特征的$Y_m$<ul><li><script type="math/tex; mode=display">y _ { j } = \sum _ { j } \omega _ { i , j } \otimes v _ { j }</script></li></ul></li><li>最后通过转置卷积将$yj$序列折叠为高维的$y_m$</li><li><img src="https://s21.ax1x.com/2024/10/28/pA0wsc6.png" alt="pA0wsc6.png"></li></ul></li></ul></li></ul><h4 id="③spatial-attention-fusion-module-SAFM"><a href="#③spatial-attention-fusion-module-SAFM" class="headerlink" title="③spatial attention fusion module (SAFM)"></a>③spatial attention fusion module (SAFM)</h4><ul><li>上采样特征 Y 和 HR 特征 $Y^′_m$经过此模块产生准确的 HR 融合特征 $Y_f$</li><li>考虑到MFEM输出的目标尺度特征Y’m可能包含一些无用的重复信息，为了将Y’m更有意义的部分集成到主干网络中，利用空间注意力来自适应调整和融合特征。</li><li>参考前部分空间注意力机制</li><li><img src="https://s21.ax1x.com/2024/10/28/pA0DgBT.png" alt="pA0DgBT.png"></li></ul><h2 id="二-文献二（ASFT）"><a href="#二-文献二（ASFT）" class="headerlink" title="二.文献二（ASFT）"></a>二.文献二（ASFT）</h2><ul><li><strong>Adjacent slices feature transformer network for single anisotropic 3D brain MRI image super-resolution</strong></li></ul><h3 id="1-文献介绍-1"><a href="#1-文献介绍-1" class="headerlink" title="1.文献介绍"></a>1.文献介绍</h3><p>主要贡献：</p><ul><li>构建了 ASFT 网络，将脑 MRI 图像 SR 问题视为<strong>在各向异性脑 MRI 图像的相邻平面内切片中插入附加切片的任务。</strong></li><li><strong>多分支特征转换和提取（MFTE）块利用相邻平面内切片的相似性，变换相邻 HR 参考切片的特征，以丰富目标切片的细节</strong>。</li><li>使用SA方法来自适应细化空间特征，增强参考切片中有意义的特征区域并过滤掉无用的特征区域。此外，使用 CA 来学习多级特征的权重，以保留有助于提高 SR 性能的重要特征。</li><li>设计了一个内容和梯度混合损失函数来监督SR网络学习几何失真较少的精细纹理和上下文。<strong>内容和梯度项可以分别保持保真度并约束与相邻像素的关系。</strong></li><li>创新性地将其转换为向高分辨率层面插入额外切片的问题，利用各向异性 3D MRI 图像的 3D  空间连续性与相邻切片的相似性，从高分辨率层面中自适应地学习与挖掘有利于提高目标切片分辨率的信息，从 2D 角度解决 3D MRI 图像的超分辨率问题。在此基础上，进一步提出基于图像梯度与内容的联合优化函数，保留 MRI 图像原有结构信息的同时,提升 3D MRI 图像的分辨率。</li></ul><h3 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2.网络结构"></a>2.网络结构</h3><ul><li><img src="https://s21.ax1x.com/2024/11/02/pADzjFP.png" alt="pADzjFP.png"></li></ul><h4 id="①initial-feature-extraction-IFE-operation"><a href="#①initial-feature-extraction-IFE-operation" class="headerlink" title="①initial feature extraction (IFE) operation"></a>①initial feature extraction (IFE) operation</h4><ul><li><p>ASFT由给定的LR脑部MRI图像<script type="math/tex">I _ { L R } \in R ^ { W \times H \times  D }</script>以尺度因子s生成HR脑部MRI图像<script type="math/tex">I _ { S R } \in R ^ { W \times H \times s D }</script></p></li><li><p>$  x _ { I n } , x _ { I n } ^ { U } , x _ { I n } ^ { N }     f r o m       I _ { L R } ^ {\uparrow} , I _ { R e f } ^ { U }  I _ { R e f } ^ { N }$，</p><ul><li>分为三个分支，$ X _ { I n } = \left\{ x _ { I n } ^ { U } , x _ { I n } , x _ { I n } ^ { N } \right\} .$</li><li>上标 U 和 N 分别表示目标切片的前一个与后一个相邻的高分辨率切片</li></ul></li><li><p>后分别通过卷积层初步提取特征得到<script type="math/tex">X _ { 1 } = \left\{ x _ { 1 } ^ { U } , x _ { 1 } , x _ { 1 } ^ { N } \right\}</script></p></li></ul><h4 id="②feature-mapping-sub-network-FMNet"><a href="#②feature-mapping-sub-network-FMNet" class="headerlink" title="②feature mapping sub-network (FMNet)"></a>②feature mapping sub-network (FMNet)</h4><ul><li><strong>Multi-branch Features Transformation and Extraction</strong><ul><li>主分支被用于提取多层次特征，上、下两个分支用于从相邻的高分辨率切片中提取特征并进行特征的转换，即对与目标切片不相关的特征信息进行抑制，相关的特征信息进行增强</li><li>上下相近切片的两个分支将通过SA，之后采用沿通道方向的均值操作来融合所有分支的特征。</li><li><img src="https://s21.ax1x.com/2024/11/02/pArCcp6.png" alt="pArCcp6.png"></li></ul></li></ul><h4 id="③reconstruction-sub-network-RecNet"><a href="#③reconstruction-sub-network-RecNet" class="headerlink" title="③reconstruction sub-network (RecNet)"></a>③reconstruction sub-network (RecNet)</h4><ul><li>通过SA增强较强特征，之后再进行一次融合并与原始图片残差连接得到最终输出</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第八章-SR-amp-transformer&quot;&gt;&lt;a href=&quot;#超分辨率第八章-SR-amp-transformer&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第八章-SR&amp;amp;transformer&quot;&gt;&lt;/a&gt;超分辨率第八章-SR&amp;amp;transformer&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;超分辨率中的transformer-应用于MRI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;文献一：&lt;a href=&quot;https://ieeexplore.ieee.org/document/9746092&quot;&gt;3d Cross-Scale Feature Transformer Network for Brain Mr Image Super-Resolution&lt;/a&gt;：ICASSP 2022会议&lt;/p&gt;
&lt;p&gt;文献二：&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1746809421009368&quot;&gt;Adjacent slices feature transformer network for single anisotropic 3D brain MRI image super-resolution&lt;/a&gt;：《Biomedical Signal Processing and Control》 期刊，2022 &lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第七章-SRFBN</title>
    <link href="http://example.com/2024/10/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%83%E7%AB%A0-SRFBN/"/>
    <id>http://example.com/2024/10/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%83%E7%AB%A0-SRFBN/</id>
    <published>2024-10-20T14:44:16.000Z</published>
    <updated>2024-10-28T08:12:50.407Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第七章-SRFBN"><a href="#超分辨率第七章-SRFBN" class="headerlink" title="超分辨率第七章-SRFBN"></a>超分辨率第七章-SRFBN</h1><blockquote><p>SRFBN发表于2019年，引入了反馈网络机制，不会增加额外的参数，并且多次回传相当于加深了网络。</p><p>论文地址：<a href="https://arxiv.org/abs/1903.09814">Feedback Network for Image Super-Resoluition</a></p><p>MRI论文：<a href="https://www.sciencedirect.com/science/article/pii/S0933365719310073">A trusted medical image super-resolution method based on feedback adaptive weighted dense network</a></p><p>参考博客：<a href="https://blog.csdn.net/m0_37615398/article/details/89199251">【CVPR2019】超分辨率文章，SRFBN: Feedback Network for Image Super-Resoluition</a></p><p>代码位置：F:\Github下载\SRFBN_CVPR19-master</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><p><strong>之前基于RNN的模型，如DRCN、DRRN使用前馈方式，先前的层无法从之后的层得到有效信息。</strong></p><p>由于跳跃连接是从浅层到深层的路径，因此底层特征只能接受先前层的信息，感受野较小，影响了重建的质量</p><h3 id="1-前置模型：DRCN"><a href="#1-前置模型：DRCN" class="headerlink" title="1.前置模型：DRCN"></a>1.前置模型：DRCN</h3><ul><li><p>DRCN是一种基于递归结构，使用递归监督和跳跃连接的SISR深度网络模型</p></li><li><p>递归监督（每次递归后都与重建层直接连接），用每次递归的输出直接与重建层相连，最终得到D个重建SR图像，再对这D幅SR图像进行加权求和。</p><blockquote><ul><li>对于每一次递归，都输出到重建层，作为总和Loss的一部分，也就是说每一次递归都通过监督学习来学习参数，故称之为递归监督。对于D次的递归，最终的Loss由D个小loss通过加权平均得到，当反向传播的时候，每一次递归都会获取属于自己的那一部分梯度，这样就算来自深层递归的梯度消失了，自己的那份也可以用来训练更新参数。</li></ul></blockquote></li><li><p>跳层连接（共享低频信息）：将原始图像直接连接至重建层，保留低分辨率图像原始特征。</p><ul><li><img src="https://s21.ax1x.com/2024/10/21/pAa20Xt.png" alt="pAa20Xt.png"></li></ul></li></ul><h3 id="2-关于RNN、LSTM"><a href="#2-关于RNN、LSTM" class="headerlink" title="2.关于RNN、LSTM"></a>2.关于RNN、LSTM</h3><ul><li><p>RNN：<a href="https://zhuanlan.zhihu.com/p/123211148">参考博客</a></p><ul><li><p><img src="https://s21.ax1x.com/2024/10/21/pAasUEQ.png" alt="pAasUEQ.png"></p></li><li><p><strong>s是隐藏层的值，W是每个时间点之间的权重矩阵，我们注意到，RNN之所以可以解决序列问题，是因为它可以记住每一时刻的信息（即隐藏层的值s）。</strong></p></li><li><p><strong>每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定，公式如下，其中 $O_t$ 代表$t$时刻的输出, $S_t$ 代表$t$时刻的隐藏层的值。</strong></p></li><li><p>$ S _ { t } = f ( U . X _ { t } + W . S _ { t - 1 } ) $</p></li><li><p>$ O _ { t } = g ( V . S _ { t } ) $</p></li><li><p><strong>在整个训练过程中，每一时刻所用的都是同样的W，每一时刻的输出结果都与上一时刻的输入有着非常大的关系，如果我们将输入序列换个顺序，那么我们得到的结果也将是截然不同，这就是RNN的特性，可以处理序列数据，同时对序列也很敏感。</strong></p></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 超参数  </span></span><br><span class="line">input_size = <span class="number">10</span>  <span class="comment"># 输入特征维度  </span></span><br><span class="line">hidden_size = <span class="number">20</span>  <span class="comment"># 隐藏层神经元数量  </span></span><br><span class="line">num_layers = <span class="number">2</span>  <span class="comment"># RNN隐藏层数  </span></span><br><span class="line">num_classes = <span class="number">3</span>  <span class="comment"># 输出类别数  </span></span><br><span class="line">seq_len = <span class="number">5</span>  <span class="comment"># 序列长度  </span></span><br><span class="line">batch_size = <span class="number">32</span>  <span class="comment"># 批次大小  </span></span><br><span class="line">num_epochs = <span class="number">10</span>  <span class="comment"># 训练轮数  </span></span><br><span class="line">learning_rate = <span class="number">0.001</span>  <span class="comment"># 学习率  </span></span><br><span class="line"> </span><br><span class="line">x_train = torch.randn(<span class="number">100</span>, seq_len, input_size)  <span class="comment"># 训练数据  </span></span><br><span class="line">y_train = torch.randint(<span class="number">0</span>, num_classes, (<span class="number">100</span>,))  <span class="comment"># 类别标签  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建数据加载器  </span></span><br><span class="line">train_dataset = TensorDataset(x_train, y_train)  </span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 定义RNN模型  </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RNNClassifier</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_layers, num_classes</span>):  </span><br><span class="line">        <span class="built_in">super</span>(RNNClassifier, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.hidden_size = hidden_size  </span><br><span class="line">        <span class="variable language_">self</span>.num_layers = num_layers  </span><br><span class="line">        <span class="variable language_">self</span>.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 初始化隐藏层状态  </span></span><br><span class="line">        h0 = torch.zeros(<span class="variable language_">self</span>.num_layers, x.size(<span class="number">0</span>), <span class="variable language_">self</span>.hidden_size).to(x.device)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 前向传播RNN  </span></span><br><span class="line">        out, _ = <span class="variable language_">self</span>.rnn(x, h0)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 取最后一个时间步的输出  </span></span><br><span class="line">        out = out[:, -<span class="number">1</span>, :]  <span class="comment">#从out中提取每个样本的最后一个时间步的所有特征，从而得到一个形状为 (batch_size, features) 的二维张量。</span></span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 通过全连接层得到最终的输出  </span></span><br><span class="line">        out = <span class="variable language_">self</span>.fc(out)  </span><br><span class="line">        <span class="keyword">return</span> out  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 实例化模型、损失函数和优化器  </span></span><br><span class="line">model = RNNClassifier(input_size, hidden_size, num_layers, num_classes).to(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)  </span><br><span class="line">criterion = nn.CrossEntropyLoss()  </span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 训练循环  </span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):  </span><br><span class="line">    <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:  </span><br><span class="line">        batch_x, batch_y = batch_x.to(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>), batch_y.to(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 前向传播  </span></span><br><span class="line">        outputs = model(batch_x)  </span><br><span class="line">        loss = criterion(outputs, batch_y)  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 反向传播和优化  </span></span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()  </span><br><span class="line">      </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成！&quot;</span>)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>LSTM（Long short-term memory，长短期记忆）：<a href="https://zhuanlan.zhihu.com/p/518848475">参考博客</a></p><ul><li><p><strong>LSTM主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题</strong></p></li><li><p>普通RNN存储所有序列信息，LSTM通过门控装置选择性的存储信息（门是用来控制每一时刻信息的记忆与遗忘）</p></li><li><p>相比于原始的RNN的隐层(hidden state)， LSTM增加了一个状态Ct；sigmoid激活函数会将值变为【0，1】，tanh函数将值变为【-1,1】之间。</p></li><li><p>整体结构</p><ul><li><img src="https://s21.ax1x.com/2024/10/21/pAagZRA.png" alt="pAagZRA.png"></li></ul></li><li><p>单独结构</p><ul><li><img src="https://s21.ax1x.com/2024/10/21/pAagkIe.md.png" alt="pAagkIe.md.png"></li></ul></li><li><p>门控系统</p><ul><li>遗忘门：<ul><li>$ f _ { t } = \sigma ( W _ { f } \cdot \left[ h _ { t - 1 } , x _ { t } \right] + b _ { f } )$</li><li><strong>遗忘门作用于LSTM的状态向量C上，用于控制上一个时间戳的记忆对当前时间戳的影响</strong>。它通过对之前的记忆状态进行加权选择来控制遗忘程度，这个加权选择的过程是通过一个线性变换后经过sigmoid激活函数来实现的，因此遗忘门的输出是一个介于0和1之间的数值，表示遗忘的程度。</li><li><strong>遗忘门决定了记忆单元中哪些信息应该被遗忘</strong>。当遗忘门的输出为0时，表示完全遗忘之前的信息；当输出为1时，表示完全保留之前的信息；当输出为0到1之间的数值时，表示部分遗忘之前的信息。这有助于LSTM在处理序列数据时，选择性地遗忘那些不重要或冗余的信息。</li></ul></li><li>输入门：<ul><li>$ i _ { t } = \sigma \left( W _ { i } \cdot \left[ h _ { t - 1 } , x _ { t } \right] + b _ { i } \right)$</li><li>$ \tilde { C } _ { t } = \tan h ( W _ { C } \cdot \left[ h _ { t - 1 } , x _ { t } \right] + b _ { C } )$</li><li>$ C _ { t } = f _ { t } \ast C _ { t - 1 } + i _ { t } \ast \tilde { C } _ { t }$</li><li><strong>输入门用于控制新的输入信息对记忆单元的影响。</strong>它同样是通过一个线性变换后经过激活函数（sigmoid和tanh）来实现的。<strong>sigmoid函数的输出决定了哪些新信息应该被加入到记忆中，而tanh函数的输出则是对新信息的候选值进行缩放。</strong></li><li>输入门的作用是决定多少新信息应该进入记忆单元。当输入门的输出为0时，表示不接受新的输入信息；当输出为1时，表示完全接受新的输入信息。输入门则更侧重于控制当前时刻的输入和前一时刻的隐藏状态如何结合来更新记忆单元的状态</li></ul></li><li>输出门：<ul><li>$ o _ { t } = \sigma ( W _ { o } \left[ h _ { t - 1 } , x _ { t } \right] + b _ { o } )$</li><li>$ h _ { t } = o _ { t } \ast \tan h ( C _ { t } )$</li><li><strong>输出门控制着从记忆单元中输出信息的数量</strong>。它的输入包括当前时刻的输入、上一个时刻的隐藏状态以及当前时刻的记忆单元状态，输出则是一个介于0和1之间的数值，表示输出的信息量。这个输出过程同样是通过一个线性变换后经过sigmoid激活函数来实现的。</li><li>输出门的作用是控制哪些记忆状态应该被输出到网络的其他部分。当输出门的输出为0时，表示不输出任何信息；当输出为1时，表示完全输出当前时刻的记忆单元状态。这有助于LSTM在不同情境下灵活地应用记忆，从而产生适当的输出。</li></ul></li></ul></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size=<span class="number">1</span>, hidden_size=<span class="number">50</span>, num_layers=<span class="number">1</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(LSTM, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.hidden_size = hidden_size  </span><br><span class="line">        <span class="variable language_">self</span>.num_layers = num_layers  </span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_size, <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        h0 = torch.zeros(<span class="variable language_">self</span>.num_layers, x.size(<span class="number">0</span>), <span class="variable language_">self</span>.hidden_size).to(x.device)  </span><br><span class="line">        c0 = torch.zeros(<span class="variable language_">self</span>.num_layers, x.size(<span class="number">0</span>), <span class="variable language_">self</span>.hidden_size).to(x.device)  </span><br><span class="line">  </span><br><span class="line">        out, _ = <span class="variable language_">self</span>.lstm(x, (h0, c0))  </span><br><span class="line">        out = <span class="variable language_">self</span>.fc(out[:, -<span class="number">1</span>, :])  </span><br><span class="line">        <span class="keyword">return</span> out  </span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="3-模型特点"><a href="#3-模型特点" class="headerlink" title="3.模型特点"></a>3.模型特点</h3><ul><li><p>采取了具有反馈块（FB）的RNN结构，反馈块由多组上采样层和下采样层构成，具有密集的跳跃连接，通过上采样和下采样，网络能够在不同的尺度上捕捉图像的特征。上采样有助于恢复图像的细节信息，而下采样则有助于提取更高层次的语义信息。这种多尺度处理可以帮助网络更好地理解图像内容</p></li><li><p>反馈块（FB）接收输入$F_{IN}$和上一次迭代$F^{t−1}_{out}$的隐藏层的信息，然后将其隐藏状态$F^t_{out}$传递到下一次迭代和输出。</p></li><li><p>该模型可以使高层的信息自上而下流经反馈连接，以使用更多上下文信息来纠正低级特征。</p></li><li><p>在SRFBN中，有三个不可缺少的部分：</p><ul><li>每次的迭代都会计算loss，迫使网络每次迭代都重建图像，将高层特征信息传入。</li><li>使用recurrent结构，从而达到迭代的目的</li><li><p>在每次迭代中都提供LR图像的输入（和上一轮的输出做一个concat）</p></li><li><p><img src="https://s21.ax1x.com/2024/10/21/pAaoiZR.md.png" alt="pAaoiZR.md.png"></p></li></ul></li></ul><h3 id="4-模型架构"><a href="#4-模型架构" class="headerlink" title="4.模型架构"></a>4.模型架构</h3><ul><li>每一次迭代由浅层特征提取层、反馈层、重建层以及一个将原始图像进行上采样的连接组成。经过t次迭代之后得到$ ( I _ { S R } ^ { 1 } , I _ { S R } ^ { 2 } , \ldots , I _ { S R } ^ { T } )$的高分辨率图片集合</li></ul><ul><li><p><img src="https://s21.ax1x.com/2024/10/21/pAaI0PK.png" alt="pAaI0PK.png"></p></li><li><p>浅层特征提取层 </p><ul><li>经过Conv(3, 4m) and Conv(1, m)</li><li>$ F _ { i n } ^ { t } = f _ { L R F B } ( I _ { L R } )$</li></ul></li><li>反馈层：$ F _ { o u t } ^ { t } = f _ { F B } ( F _ { o u t } ^ { t - 1 } , F _ { i n } ^ { t } )$<ul><li>t次迭代时，通过反馈连接接受$t-1$次的隐藏层信息，将其与本次迭代的输入信息在特征维度上进行拼接。</li><li>$F^t_{in}$ and $F^{t−1}_{out}$通过Conv(1, m)连接并压缩，减少输入特征的维度 <ul><li>$ L _ { 0 } ^ { t } = C _ { 0 } ( \left[ F _ { o u t } ^ { t - 1 } , F _ { i n } ^ { t } \right] ) ,$</li></ul></li><li>之后交替式地进行上采样和下采样，并通过稠密连接进行连接。（高尺度连接到高尺度、低尺度连接到低尺度）<ul><li>这样做的目的提取跨尺度的特征，提取图片内部特征的先验信息。</li><li>使用反卷积Deconv(k, m)进行上采样，$ H _ { g } ^ { t } = C _ { g } ^ { t } ( \left[ L _ { 0 } ^ { t } , L _ { 1 } ^ { t } , . . . , L _ { g - 1 } ^ { t } \right] ) ,$</li><li>使用Conv(k, m)进行下采样，$ L _ { g } ^ { t } = C _ { g } ^ { \downarrow } ( \left[ H _ { 1 } ^ { t } , H _ { 2 } ^ { t } , \ldots , H _ { g } ^ { t } \right] ) ,$</li><li>除了第一个组，在上采样层和下采样层之前使用Conv(1, m)，提高计算效率</li></ul></li><li><img src="https://s21.ax1x.com/2024/10/21/pAa7k8K.png" alt="pAa7k8K.png"></li></ul></li><li>重建层<ul><li>经过反卷积Deconv(k, m)放大，和Deconv(k, m)重建，并与上采样后的原始图像结合</li><li>$ I _ { R e s } ^ { t } = f _ { R B } ( F _ { o u t } ^ { t } ) $</li><li><script type="math/tex; mode=display">I _ { S R } ^ { t } = I _ { R e s } ^ { t } + f _ { U P } ( I _ { L R } ) ,</script></li></ul></li></ul><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><h3 id="1-基本结构"><a href="#1-基本结构" class="headerlink" title="1.基本结构"></a>1.基本结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SRFBN</span>(nn.Module):  <span class="comment">#num_steps:迭代次数、num_groups：反馈块中的上下采样层组的个数</span></span><br><span class="line">    <span class="comment"># 初始化方法，用于设置SRFBN模型的基本参数和构建模型结构，参数设置部分省略</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, num_features, num_steps, num_groups, upscale_factor, act_type = <span class="string">&#x27;prelu&#x27;</span>, norm_type = <span class="literal">None</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(SRFBN, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的初始化方法 </span></span><br><span class="line">        <span class="comment">#浅层特征提取块  </span></span><br><span class="line">        <span class="variable language_">self</span>.conv_in = ConvBlock(in_channels, <span class="number">4</span>*num_features, kernel_size=<span class="number">3</span>, act_type=act_type, norm_type=norm_type)   </span><br><span class="line">        <span class="variable language_">self</span>.feat_in = ConvBlock(<span class="number">4</span>*num_features, num_features, kernel_size=<span class="number">1</span>, act_type=act_type, norm_type=norm_type)  </span><br><span class="line">        <span class="comment"># 反馈块  </span></span><br><span class="line">        <span class="variable language_">self</span>.block = FeedbackBlock(num_features, num_groups, upscale_factor, act_type, norm_type) </span><br><span class="line">        <span class="comment"># 重建块  </span></span><br><span class="line">        <span class="variable language_">self</span>.out = DeconvBlock(num_features, num_features, kernel_size=kernel_size, stride=stride, padding=padding, act_type=<span class="string">&#x27;prelu&#x27;</span>, norm_type=norm_type)   </span><br><span class="line">        <span class="variable language_">self</span>.conv_out = ConvBlock(num_features, out_channels, kernel_size=<span class="number">3</span>, act_type=<span class="literal">None</span>, norm_type=norm_type)  </span><br><span class="line">       </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="variable language_">self</span>._reset_state()  <span class="comment">#重置状态</span></span><br><span class="line">        <span class="comment"># 对输入数据进行预处理，减去均值  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.sub_mean(x)  </span><br><span class="line">        <span class="comment"># 对输入数据进行上采样</span></span><br><span class="line">        inter_res = nn.functional.interpolate(x, scale_factor=<span class="variable language_">self</span>.upscale_factor, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)  </span><br><span class="line">        <span class="comment"># 通过低分辨率特征提取块  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv_in(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.feat_in(x)  </span><br><span class="line">        <span class="comment"># 存储每一步的输出  </span></span><br><span class="line">        outs = []  </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_steps):  <span class="comment">#开始迭代过程</span></span><br><span class="line">            <span class="comment"># 通过反馈块，得到当前隐藏层的状态</span></span><br><span class="line">            h = <span class="variable language_">self</span>.block(x)  </span><br><span class="line">            <span class="comment"># 通过重建块，并将当前结果与上采样得出的结果进行结合  </span></span><br><span class="line">            h = torch.add(inter_res, <span class="variable language_">self</span>.conv_out(<span class="variable language_">self</span>.out(h)))  </span><br><span class="line">            <span class="comment"># 对结果添加均值  </span></span><br><span class="line">            h = <span class="variable language_">self</span>.add_mean(h)  </span><br><span class="line">            <span class="comment"># 将结果添加到输出列表中  </span></span><br><span class="line">            outs.append(h)  </span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 返回每一步的输出结果  </span></span><br><span class="line">        <span class="keyword">return</span> outs       </span><br><span class="line">          </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_reset_state</span>(<span class="params">self</span>):  <span class="comment"># 重置状态的方法，通常用于FeedbackBlock中重置隐藏状态或计数器</span></span><br><span class="line">        <span class="variable language_">self</span>.block.reset_state()</span><br></pre></td></tr></table></figure><h3 id="2-反馈层结构"><a href="#2-反馈层结构" class="headerlink" title="2.反馈层结构"></a>2.反馈层结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeedbackBlock</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># 初始化函数，设置反馈块的各种参数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_groups, upscale_factor, act_type, norm_type</span>):  </span><br><span class="line">        <span class="built_in">super</span>(FeedbackBlock, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类的初始化函数  </span></span><br><span class="line">        <span class="comment"># 存储分组数量  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_groups = num_groups  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 定义压缩卷积块，用于减少输入特征的维度  </span></span><br><span class="line">        <span class="variable language_">self</span>.compress_in = ConvBlock(<span class="number">2</span>*num_features, num_features, kernel_size=<span class="number">1</span>, act_type=act_type, norm_type=norm_type)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 初始化存储上采样、下采样、上采样转换、下采样转换块的列表  </span></span><br><span class="line">        <span class="variable language_">self</span>.upBlocks = nn.ModuleList()  </span><br><span class="line">        <span class="variable language_">self</span>.downBlocks = nn.ModuleList()  </span><br><span class="line">        <span class="variable language_">self</span>.uptranBlocks = nn.ModuleList()  </span><br><span class="line">        <span class="variable language_">self</span>.downtranBlocks = nn.ModuleList()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 循环创建指定数量的上采样、下采样、上采样转换、下采样转换块  </span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_groups):  </span><br><span class="line">            <span class="variable language_">self</span>.upBlocks.append(DeconvBlock(num_features, num_features, kernel_size=kernel_size, stride=stride, padding=padding, act_type=act_type, norm_type=norm_type))  </span><br><span class="line">            <span class="variable language_">self</span>.downBlocks.append(ConvBlock(num_features, num_features, kernel_size=kernel_size, stride=stride, padding=padding, act_type=act_type, norm_type=norm_type, valid_padding=<span class="literal">False</span>))  </span><br><span class="line">            <span class="keyword">if</span> idx &gt; <span class="number">0</span>:  <span class="comment"># 如果不是第一个分组，则需要转换块  </span></span><br><span class="line">                <span class="variable language_">self</span>.uptranBlocks.append(ConvBlock(num_features*(idx+<span class="number">1</span>), num_features, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, act_type=act_type, norm_type=norm_type))  </span><br><span class="line">                <span class="variable language_">self</span>.downtranBlocks.append(ConvBlock(num_features*(idx+<span class="number">1</span>), num_features, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, act_type=act_type, norm_type=norm_type))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 输出压缩卷积块，用于将所有分组的输出合并并减少维度  </span></span><br><span class="line">        <span class="variable language_">self</span>.compress_out = ConvBlock(num_groups*num_features, num_features, kernel_size=<span class="number">1</span>, act_type=act_type, norm_type=norm_type)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 状态重置标志和上一次隐藏状态  </span></span><br><span class="line">        <span class="variable language_">self</span>.should_reset = <span class="literal">True</span>  </span><br><span class="line">        <span class="variable language_">self</span>.last_hidden = <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 如果是第一次运行，则重置隐藏状态并初始化为输入  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.should_reset:  </span><br><span class="line">            <span class="variable language_">self</span>.last_hidden = torch.zeros(x.size()).cuda()  </span><br><span class="line">            <span class="variable language_">self</span>.last_hidden.copy_(x)  </span><br><span class="line">            <span class="variable language_">self</span>.should_reset = <span class="literal">False</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 将当前输入和上一次隐藏状态在特征维度上拼接!</span></span><br><span class="line">        x = torch.cat((x, <span class="variable language_">self</span>.last_hidden), dim=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 通过输入压缩卷积块  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.compress_in(x)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 初始化低分辨率和高分辨率特征列表  </span></span><br><span class="line">        lr_features = []  </span><br><span class="line">        hr_features = []  </span><br><span class="line">        <span class="comment"># 将输入特征添加到低分辨率特征列表  </span></span><br><span class="line">        lr_features.append(x)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 循环处理每个分组  </span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_groups):  </span><br><span class="line">            <span class="comment"># 将当前低分辨率特征列表中的所有特征在特征维度上拼接  </span></span><br><span class="line">            LD_L = torch.cat(<span class="built_in">tuple</span>(lr_features), <span class="number">1</span>)  </span><br><span class="line">            <span class="comment"># 如果不是第一个分组，则通过上采样转换块  </span></span><br><span class="line">            <span class="keyword">if</span> idx &gt; <span class="number">0</span>:  </span><br><span class="line">                LD_L = <span class="variable language_">self</span>.uptranBlocks[idx-<span class="number">1</span>](LD_L)  </span><br><span class="line">            <span class="comment"># 通过上采样块  </span></span><br><span class="line">            LD_H = <span class="variable language_">self</span>.upBlocks[idx](LD_L)  </span><br><span class="line">            <span class="comment"># 将上采样后的特征添加到高分辨率特征列表  </span></span><br><span class="line">            hr_features.append(LD_H)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 将当前高分辨率特征列表中的所有特征在特征维度上拼接  </span></span><br><span class="line">            LD_H = torch.cat(<span class="built_in">tuple</span>(hr_features), <span class="number">1</span>)  </span><br><span class="line">            <span class="comment"># 如果不是第一个分组，则通过下采样转换块  </span></span><br><span class="line">            <span class="keyword">if</span> idx &gt; <span class="number">0</span>:  </span><br><span class="line">                LD_H = <span class="variable language_">self</span>.downtranBlocks[idx-<span class="number">1</span>](LD_H)  </span><br><span class="line">            <span class="comment"># 通过下采样块  </span></span><br><span class="line">            LD_L = <span class="variable language_">self</span>.downBlocks[idx](LD_H)  </span><br><span class="line">            <span class="comment"># 将下采样后的特征添加到低分辨率特征列表  </span></span><br><span class="line">            lr_features.append(LD_L)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 删除高分辨率特征列表以节省内存  </span></span><br><span class="line">        <span class="keyword">del</span> hr_features  </span><br><span class="line">        <span class="comment"># 将除输入外的所有低分辨率特征在特征维度上拼接，并通过输出压缩卷积块  </span></span><br><span class="line">        output = torch.cat(<span class="built_in">tuple</span>(lr_features[<span class="number">1</span>:]), <span class="number">1</span>)  </span><br><span class="line">        output = <span class="variable language_">self</span>.compress_out(output)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 更新隐藏状态  </span></span><br><span class="line">        <span class="variable language_">self</span>.last_hidden = output  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 返回输出  </span></span><br><span class="line">        <span class="keyword">return</span> output  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 重置状态函数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_state</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.should_reset = <span class="literal">True</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第七章-SRFBN&quot;&gt;&lt;a href=&quot;#超分辨率第七章-SRFBN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第七章-SRFBN&quot;&gt;&lt;/a&gt;超分辨率第七章-SRFBN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;SRFBN发表于2019年，引入了反馈网络机制，不会增加额外的参数，并且多次回传相当于加深了网络。&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1903.09814&quot;&gt;Feedback Network for Image Super-Resoluition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MRI论文：&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0933365719310073&quot;&gt;A trusted medical image super-resolution method based on feedback adaptive weighted dense network&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考博客：&lt;a href=&quot;https://blog.csdn.net/m0_37615398/article/details/89199251&quot;&gt;【CVPR2019】超分辨率文章，SRFBN: Feedback Network for Image Super-Resoluition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码位置：F:&#92;Github下载&#92;SRFBN_CVPR19-master&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第六章-RCAN</title>
    <link href="http://example.com/2024/09/26/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AD%E7%AB%A0-RCAN/"/>
    <id>http://example.com/2024/09/26/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%85%AD%E7%AB%A0-RCAN/</id>
    <published>2024-09-26T13:37:34.000Z</published>
    <updated>2024-10-28T04:33:40.803Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第六章-RCAN"><a href="#超分辨率第六章-RCAN" class="headerlink" title="超分辨率第六章-RCAN"></a>超分辨率第六章-RCAN</h1><blockquote><p>RCAN发表于2018年，引入了注意力机制：Channel Attention (CA)</p><p>论文地址：<a href="https://arxiv.org/abs/1807.02758">Image Super-Resolution Using Very Deep Residual Channel Attention Networks</a></p><p>参考博客</p><ul><li><a href="https://blog.csdn.net/weixin_46773169/article/details/105600346">RCAN论文笔记：Image Super-Resolution Using Very Deep Residual Channel Attention Networks</a></li><li><a href="https://blog.csdn.net/kuailezzf/article/details/135707786?spm=1001.2014.3001.5506">通道注意力机制(CA)</a></li></ul><p>代码位置：F:\Github下载\RCAN-pytorch-master</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><h3 id="1-模型特点"><a href="#1-模型特点" class="headerlink" title="1.模型特点"></a>1.模型特点</h3><h4 id="1-使用了RIR结构"><a href="#1-使用了RIR结构" class="headerlink" title="(1) 使用了RIR结构"></a>(1) 使用了RIR结构</h4><ul><li><p>仅仅通过叠加残差块来构建更深的网络很难获得更好的提升效果</p></li><li><p><strong>残差嵌套（residual in residual，RIR）结构构造非常深的可训练网络，RIR中的长跳连接和短跳连接有助于绕过大量的低频信息，使主网络学习到更有效的信息。</strong></p></li><li><strong>LSC和SSC可以直接将低层得到的低频的信息直接跨层和高层的特征信息融合，并迫使网络集中学习残差信息获取更丰富的高层特征信息</strong></li></ul><h4 id="2-引入了通道注意力机制（CA）"><a href="#2-引入了通道注意力机制（CA）" class="headerlink" title="2.引入了通道注意力机制（CA）"></a>2.引入了通道注意力机制（CA）</h4><ul><li><strong>低分辨率图像</strong>（LR）的输入和特征包含<strong>大量的低频信息</strong>，这些信息<strong>在通道间被平等对待</strong>，从而阻碍了模型的表征能力。</li><li>因此RCAN引入CA (通道注意力) 机制来解决此问题<ul><li><strong>不同的通道可能对不同的特征有不同的贡献，有些通道可能包含更多的关键信息，而其他通道则可能包含噪声或冗余信息。</strong></li><li><strong>一般来说，通道注意力机制通过对每层特征图全局信息的学习来为每个通道赋予不同的权重，达到加强有用的特征，抑制无用特征的效果</strong>。</li><li><strong>通过对不同通道施加不同的权重来提供不同重要程度的特征信息，因为不同通道的特征信息是有好有坏的，有的对图像的超分具有提升作用，而有的会损坏重建的质量，因此我们通过这个权重来让网络更加注重那些有用的特征信息，从而更好的提升表现力。</strong></li></ul></li></ul><h3 id="2-模型架构-G-10-B-20"><a href="#2-模型架构-G-10-B-20" class="headerlink" title="2.模型架构(G = 10 , B = 20 )"></a>2.模型架构(G = 10 , B = 20 )</h3><ul><li><p>分为四个部分：<strong>浅层特征提取、残差嵌套（RIR）深度特征提取、上采样模块、重建部分</strong></p></li><li><p>整个网络组成：Conv（浅层特征提取层） + RIR（深度特征提取层）+ 亚像素卷积层（上采样模块） + Conv（重建层）</p><ul><li>RIR（residual in residual，RIR）：G个RG（带长跳连接）</li></ul></li></ul><ul><li>每个RG（residual groups）：B个RCAB组成（带短跳连接）</li></ul><ul><li>每个RCAB（Residual Channel Attention Block）：Conv + ReLU + Conv + CA （带短跳连接）</li></ul><ul><li>CA（Channel Attention）：Global pooling（全局池化） + <Conv + relu>（下采样，特征转化） + <Conv+Sigmoid>（上采样，权重计算）（带元素相乘的门控）</Conv+Sigmoid></Conv></li></ul><ul><li><p>整体架构</p><ul><li><img src="https://s21.ax1x.com/2024/09/27/pAlfFd1.png" alt="pAlfFd1.png"></li></ul></li><li><p>RCAB架构</p><ul><li><img src="https://s21.ax1x.com/2024/09/27/pAlfQeA.png" alt="pAlfQeA.png"></li></ul></li><li><p>CA架构</p><ul><li><img src="https://s21.ax1x.com/2024/09/27/pAlfsYV.png" alt="pAlfsYV.png"></li><li><img src="https://s21.ax1x.com/2024/09/27/pAlhStP.md.png" alt="pAlhStP.md.png"></li></ul></li></ul><h3 id="3-CA（注意力机制）"><a href="#3-CA（注意力机制）" class="headerlink" title="3.CA（注意力机制）"></a>3.CA（注意力机制）</h3><ul><li>产生不同通道注意力需要一个反应不同通道重要程度的常数权重$w$，并将权重$w$和通道特征信息相结合的机制。<ul><li>全局池化<ul><li><strong>通过全局平均池化来产生产生该常数，即将不同通道的feature map映射成一个常数，如果这个特征图高频部分多，那个全局平均池化得来的值<br>$y_i$值就越大，不同大小的$y_i$与x相乘，就赋予了x不同的权重，即实现了对C个通道不同的注意（$y_i$值越大，注意力越高）</strong></li><li>设输入feature map为：<script type="math/tex">X = \left[ x _ { 1 } , \cdots , x _ { c } , \cdots , x _ { C } \right]</script>，其中<script type="math/tex">c \in \left\{ 0 , \cdots C - 1 \right\}</script>是第c个输入通道数，C为输入通道总数。池化的结果为<script type="math/tex">y \in R ^ { C }</script>，即一个一维张量，长度为C，数学表达式为：<ul><li><script type="math/tex; mode=display">y _ { c } = H _ { G P } \left( x _ { c } \right) = \frac { 1 } { H \times W } \sum _ { i = 1 } ^ { H } \sum _ { j = 1 } ^ { W } x _ { c } ( i , j ) .</script></li></ul></li></ul></li><li>特征转换与权重计算<ul><li><strong>为了限制模型复杂度和辅助泛化，通过在非线性周围形成两个卷积层的瓶颈来参数化门机制。然后经过sigmoid为每个通道学习特定采样的激活，控制每个通道的激励。</strong></li><li>$W_D$是将全局平均池化的结果进行通道降维，通过卷积的方式使得输出通道变为原来的$ \frac { 1 } { r }$，在通过ReLU激活函数保留非线性关系。</li><li>$W_U$是进行通道升维，通过卷积的方式将输出通道变为输入通道数的r倍，这里r不是SR缩放因子，实验中取r=16.</li><li><strong>经过sigmoid为每个通道学习特定采样的激活，控制每个通道的激励</strong>。<ul><li><script type="math/tex; mode=display">s = f ( W _ { U } \delta ( W _ { D } z ) ) .</script></li><li>δ（）、f（）分别表示ReLU激活函数和sigmoid门。</li></ul></li></ul></li><li>相乘<ul><li><strong>最后将激活后的非线性函数（c*1*1）按不同通道将权值和feature map进行相乘结合得到（c*h*w），输入特征与注意力权重相乘，得到重加权后的特征表示。这样，重要的通道会被放大，而不重要的通道则会减弱，从而更好地聚焦于重要的特征信息</strong></li><li><script type="math/tex; mode=display">\widehat { x } _ { c } = s _ { c } \cdot x _ { c } .</script></li></ul></li></ul></li><li>结构<ul><li><img src="https://s21.ax1x.com/2024/09/27/pAlf4T1.png" alt="pAlf4T1.png"></li></ul></li></ul><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><ul><li>使用DIV2K作为训练集，set5作为测试集</li></ul><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><ul><li>除了CA使用1×1卷积外，其余均使用3×3卷积核</li><li>除了CA使用<script type="math/tex">\frac { C } { r }</script>、r(r=16)的通道以外，其余均使用C=64。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChannelAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, reduction</span>):</span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.module = nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>), <span class="comment">#将输入特征图进行自适应平均池化到 C*1*1 大小，用于提取全局信息</span></span><br><span class="line">            nn.Conv2d(num_features, num_features // reduction, kernel_size=<span class="number">1</span>), <span class="comment">#减少通道数</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(num_features // reduction, num_features, kernel_size=<span class="number">1</span>), <span class="comment">#复原通道数</span></span><br><span class="line">            nn.Sigmoid() <span class="comment">#门控激活，得到注意力权重</span></span><br><span class="line">        ) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x * <span class="variable language_">self</span>.module(x) <span class="comment">#输入特征与注意力权重相乘，得到重加权后的特征表示。</span></span><br><span class="line">    <span class="comment">#这样，重要的通道会被放大，而不重要的通道则会减弱，从而更好地聚焦于重要的特征信息</span></span><br></pre></td></tr></table></figure><h3 id="2-RCAB-残差通道注意块"><a href="#2-RCAB-残差通道注意块" class="headerlink" title="2.RCAB (残差通道注意块)"></a>2.RCAB (残差通道注意块)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RCAB</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, reduction</span>):</span><br><span class="line">        <span class="built_in">super</span>(RCAB, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.module = nn.Sequential(</span><br><span class="line">            nn.Conv2d(num_features, num_features, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(num_features, num_features, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            ChannelAttention(num_features, reduction)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + <span class="variable language_">self</span>.module(x) <span class="comment">#通过短跳连接实现残差学习</span></span><br></pre></td></tr></table></figure><h3 id="3-RG-残差组"><a href="#3-RG-残差组" class="headerlink" title="3.RG (残差组)"></a>3.RG (残差组)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_rcab, reduction</span>):</span><br><span class="line">        <span class="built_in">super</span>(RG, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.module = [RCAB(num_features, reduction) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_rcab)] <span class="comment">#一个残差组中共有20个残差块</span></span><br><span class="line">        <span class="variable language_">self</span>.module.append(nn.Conv2d(num_features, num_features, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)) <span class="comment">#在最后追加一个卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.module = nn.Sequential(*<span class="variable language_">self</span>.module)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + <span class="variable language_">self</span>.module(x) <span class="comment">#通过短跳连接实现残差学习</span></span><br></pre></td></tr></table></figure><h3 id="4-RCAN主结构"><a href="#4-RCAN主结构" class="headerlink" title="4.RCAN主结构"></a>4.RCAN主结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RCAN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(RCAN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        scale = args.scale <span class="comment">#放大倍数</span></span><br><span class="line">        num_features = args.num_features <span class="comment">#卷积核大小为3</span></span><br><span class="line">        num_rg = args.num_rg <span class="comment">#残差组数量为10</span></span><br><span class="line">        num_rcab = args.num_rcab <span class="comment">#每个残差组所含残差块数量为20</span></span><br><span class="line">        reduction = args.reduction <span class="comment">#缩放维度倍数为16</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.sf = nn.Conv2d(<span class="number">3</span>, num_features, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment">#低层特征提取层</span></span><br><span class="line">        <span class="variable language_">self</span>.rgs = nn.Sequential(*[RG(num_features, num_rcab, reduction) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_rg)]) <span class="comment">#遍历10个残差组</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(num_features, num_features, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment">#追加一个卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.upscale = nn.Sequential( <span class="comment">#通过上采样和亚像素卷积层实现上采样</span></span><br><span class="line">            nn.Conv2d(num_features, num_features * (scale ** <span class="number">2</span>), kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.PixelShuffle(scale)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(num_features, <span class="number">3</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment">#重建层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.sf(x)</span><br><span class="line">        residual = x</span><br><span class="line">        x = <span class="variable language_">self</span>.rgs(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x += residual <span class="comment">#通过长跳连接实现残差学习</span></span><br><span class="line">        x = <span class="variable language_">self</span>.upscale(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="四-模型训练"><a href="#四-模型训练" class="headerlink" title="四.模型训练"></a>四.模型训练</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将RCAN模型实例化并移动到指定的设备（CPU或GPU）  </span></span><br><span class="line">model = RCAN(opt).to(device)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 定义损失函数为L1损失，常用于图像重建任务  </span></span><br><span class="line">criterion = nn.L1Loss()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用Adam优化器来优化模型参数，学习率通过opt.lr获取  </span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=opt.lr)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 加载数据集，参数从opt中获取  </span></span><br><span class="line">dataset = Dataset(opt.images_dir, opt.patch_size, opt.scale, opt.use_fast_loader)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用DataLoader来封装数据集，以便于批量处理和并行加载  </span></span><br><span class="line">dataloader = DataLoader(dataset=dataset,  </span><br><span class="line">                        batch_size=opt.batch_size,  </span><br><span class="line">                        shuffle=<span class="literal">True</span>,  <span class="comment"># 在每个epoch开始时打乱数据  </span></span><br><span class="line">                        num_workers=opt.threads,  <span class="comment"># 使用多个进程来加载数据  </span></span><br><span class="line">                        pin_memory=<span class="literal">True</span>,  <span class="comment"># 如果在GPU上，则锁定内存页，减少CPU到GPU的传输时间  </span></span><br><span class="line">                        drop_last=<span class="literal">True</span>)  <span class="comment"># 如果最后一个batch小于batch_size，则丢弃  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 遍历指定的训练轮次  </span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.num_epochs):  </span><br><span class="line">    epoch_losses = AverageMeter()  <span class="comment"># 使用AverageMeter来记录平均损失  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 使用tqdm来显示进度条  </span></span><br><span class="line">    <span class="keyword">with</span> tqdm(total=(<span class="built_in">len</span>(dataset) - <span class="built_in">len</span>(dataset) % opt.batch_size)) <span class="keyword">as</span> _tqdm:  </span><br><span class="line">        _tqdm.set_description(<span class="string">&#x27;epoch: &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, opt.num_epochs))  </span><br><span class="line">          </span><br><span class="line">        <span class="comment"># 遍历数据加载器中的每个batch  </span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:  </span><br><span class="line">            inputs, labels = data  <span class="comment"># 解包每个batch的数据和标签  </span></span><br><span class="line">            inputs = inputs.to(device)  <span class="comment"># 将数据和标签移动到指定设备  </span></span><br><span class="line">            labels = labels.to(device)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 前向传播  </span></span><br><span class="line">            preds = model(inputs)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 计算损失  </span></span><br><span class="line">            loss = criterion(preds, labels)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 更新损失的平均值  </span></span><br><span class="line">            epoch_losses.update(loss.item(), <span class="built_in">len</span>(inputs))  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 反向传播和优化  </span></span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 清除过往梯度  </span></span><br><span class="line">            loss.backward()  <span class="comment"># 反向传播，计算当前梯度  </span></span><br><span class="line">            optimizer.step()  <span class="comment"># 根据梯度更新网络参数  </span></span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 更新进度条上的信息  </span></span><br><span class="line">            _tqdm.set_postfix(loss=<span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch_losses.avg))  </span><br><span class="line">            _tqdm.update(<span class="built_in">len</span>(inputs))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 每个epoch结束后，保存模型参数  </span></span><br><span class="line">    torch.save(model.state_dict(), os.path.join(opt.outputs_dir, <span class="string">&#x27;&#123;&#125;_epoch_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(opt.arch, epoch)))</span><br></pre></td></tr></table></figure><h2 id="五-模型测试"><a href="#五-模型测试" class="headerlink" title="五.模型测试"></a>五.模型测试</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 加载预训练的RCAN模型  </span></span><br><span class="line">model = RCAN(opt)  <span class="comment"># 使用配置选项opt初始化RCAN模型  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2. 加载模型的权重  </span></span><br><span class="line">state_dict = model.state_dict()  <span class="comment"># 获取模型当前的权重字典  </span></span><br><span class="line"><span class="comment"># 加载预训练权重，并仅更新模型中存在的权重  </span></span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(opt.weights_path, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():  </span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():  </span><br><span class="line">        state_dict[n].copy_(p)  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        <span class="keyword">raise</span> KeyError(n)  <span class="comment"># 如果预训练权重中的某个键在模型权重字典中不存在，则抛出错误  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3. 将模型移动到指定的设备上（如CPU或GPU）  </span></span><br><span class="line">model = model.to(device)  </span><br><span class="line"><span class="comment"># 设置模型为评估模式  </span></span><br><span class="line">model.<span class="built_in">eval</span>()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4. 处理输入图像  </span></span><br><span class="line">filename = os.path.basename(opt.image_path).split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]  <span class="comment"># 从文件路径中提取文件名（不含扩展名）  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用PIL库打开并转换图像为RGB格式  </span></span><br><span class="line"><span class="built_in">input</span> = pil_image.<span class="built_in">open</span>(opt.image_path).convert(<span class="string">&#x27;RGB&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用双三次插值降采样图像，作为模型的低分辨率输入  </span></span><br><span class="line">lr = <span class="built_in">input</span>.resize((<span class="built_in">input</span>.width // opt.scale, <span class="built_in">input</span>.height // opt.scale), pil_image.BICUBIC)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用双三次插值将降采样后的图像上采样回原始尺寸，作为双三次插值的结果  </span></span><br><span class="line">bicubic = lr.resize((<span class="built_in">input</span>.width, <span class="built_in">input</span>.height), pil_image.BICUBIC)  </span><br><span class="line">bicubic.save(os.path.join(opt.outputs_dir, <span class="string">&#x27;&#123;&#125;_x&#123;&#125;_bicubic.png&#x27;</span>.<span class="built_in">format</span>(filename, opt.scale)))  <span class="comment"># 保存双三次插值结果  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5. 准备模型输入  </span></span><br><span class="line"><span class="comment"># 将低分辨率图像转换为Tensor，并添加批次维度，然后移动到指定设备上  </span></span><br><span class="line"><span class="built_in">input</span> = transforms.ToTensor()(lr).unsqueeze(<span class="number">0</span>).to(device)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 6. 使用模型进行超分辨率重建  </span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():  <span class="comment"># 不计算梯度，以节省内存和计算资源  </span></span><br><span class="line">    pred = model(<span class="built_in">input</span>)  <span class="comment"># 进行前向传播，得到超分辨率图像  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 7. 处理模型输出  </span></span><br><span class="line"><span class="comment"># 将输出Tensor转换为numpy数组，并进行必要的转换以匹配PIL图像的格式  </span></span><br><span class="line">output = pred.mul_(<span class="number">255.0</span>).clamp_(<span class="number">0.0</span>, <span class="number">255.0</span>).squeeze(<span class="number">0</span>).permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).byte().cpu().numpy()  </span><br><span class="line"><span class="comment"># 将numpy数组转换为PIL图像  </span></span><br><span class="line">output = pil_image.fromarray(output, mode=<span class="string">&#x27;RGB&#x27;</span>)  </span><br><span class="line"><span class="comment"># 保存超分辨率图像  </span></span><br><span class="line">output.save(os.path.join(opt.outputs_dir, <span class="string">&#x27;&#123;&#125;_x&#123;&#125;_&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(filename, opt.scale, opt.arch)))</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第六章-RCAN&quot;&gt;&lt;a href=&quot;#超分辨率第六章-RCAN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第六章-RCAN&quot;&gt;&lt;/a&gt;超分辨率第六章-RCAN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;RCAN发表于2018年，引入了注意力机制：Channel Attention (CA)&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1807.02758&quot;&gt;Image Super-Resolution Using Very Deep Residual Channel Attention Networks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考博客&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_46773169/article/details/105600346&quot;&gt;RCAN论文笔记：Image Super-Resolution Using Very Deep Residual Channel Attention Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/kuailezzf/article/details/135707786?spm=1001.2014.3001.5506&quot;&gt;通道注意力机制(CA)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码位置：F:&#92;Github下载&#92;RCAN-pytorch-master&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第五章-SRDenseNet</title>
    <link href="http://example.com/2024/09/23/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%BA%94%E7%AB%A0-SRDenseNet/"/>
    <id>http://example.com/2024/09/23/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%BA%94%E7%AB%A0-SRDenseNet/</id>
    <published>2024-09-23T13:21:04.000Z</published>
    <updated>2024-09-26T07:40:16.418Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第五章-SRDenseNet"><a href="#超分辨率第五章-SRDenseNet" class="headerlink" title="超分辨率第五章-SRDenseNet"></a>超分辨率第五章-SRDenseNet</h1><blockquote><p>SRDenseNet发表于2017年</p><p>论文：<a href="https://ieeexplore.ieee.org/document/8237776">Super-Resolution Using Dense Skip Connections</a> </p><p>参考博客：<a href="https://blog.csdn.net/MR_kdcon/article/details/123488533">超分之SRDenseNet</a></p><p>代码位置：F:\Github下载\SRDenseNet-pytorch-master</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><h3 id="1-模型特点"><a href="#1-模型特点" class="headerlink" title="1.模型特点"></a>1.模型特点</h3><ul><li>将稠密块作为SRDenseNet的基本结构。</li><li>Skip connection将各个level的特征直接与图像重建输入端相连，此外Dense skip connection可以缓解网络深度带来的梯度消失问题。</li></ul><h3 id="2-Dense块"><a href="#2-Dense块" class="headerlink" title="2.Dense块"></a>2.Dense块</h3><ul><li><p>Dense块各个层之间的skip connection是通过concat在一起的，而Resnet块是通过求和加在一起的。这样的好处在于可以缓解梯度消失的问题以及加强了信息在各个layer之间的流动</p></li><li><p>整个块分为8个layers，第 i 个layer产生16 × i 张feature map，最后一层产生128张特征图作为块的输出，一共有八个Dense块。</p><p><img src="https://s21.ax1x.com/2024/09/24/pAQ6AAS.png" alt="pAQ6AAS.png"></p><hr></li><li><p><img src="https://s21.ax1x.com/2024/09/24/pAQ6F78.png" alt="pAQ6F78.png"></p></li></ul><h3 id="3-模型架构"><a href="#3-模型架构" class="headerlink" title="3.模型架构"></a>3.模型架构</h3><ul><li>前向传播过程<ul><li>首先，输入的低分辨率图像经过第一层CNN提取低层的特征信息。</li><li>然后经过8个Dense块提取高层特征信息，通过skip connection的方式将各个level的特征信息相连，滤波器的大小统一设置成3×3。</li><li>再经过一层Bottleneck layer，降低前面特征图连接导致图像张数(通道数)太多而带来的高计算复杂度问题，通过1 × 1 卷积层进行缩减。</li><li>之后经过2个反卷积子网络，进行上采样。</li><li>最后使用3×3卷积核以及输出通道为1的卷积层进行重建。</li></ul></li><li>图示<ul><li><img src="https://s21.ax1x.com/2024/09/24/pAQrhHU.png" alt="pAQrhHU.png"></li></ul></li></ul><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><p>训练集使用coco2017，验证集使用set5</p><h2 id="三-模型架构"><a href="#三-模型架构" class="headerlink" title="三.模型架构"></a>三.模型架构</h2><h3 id="1-定义特征提取层"><a href="#1-定义特征提取层" class="headerlink" title="1.定义特征提取层"></a>1.定义特征提取层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLayer</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size</span>):  </span><br><span class="line">        <span class="built_in">super</span>(ConvLayer, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // <span class="number">2</span>)   </span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)   </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv(x))  <span class="comment">#卷积后应用ReLU激活</span></span><br></pre></td></tr></table></figure><h3 id="2-定义dense块结构"><a href="#2-定义dense块结构" class="headerlink" title="2.定义dense块结构"></a>2.定义dense块结构</h3><ul><li><strong>定义一个dense块中单独的层，每个层均为3<em>3\</em>16结构</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DenseLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(DenseLayer, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.cat([x, <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv(x))], <span class="number">1</span>) <span class="comment">#将输入x与卷积后的结果沿通道维拼接</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义dense块</strong></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DenseBlock</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, growth_rate, num_layers</span>):    </span><br><span class="line">        <span class="variable language_">self</span>.block = [ConvLayer(in_channels, growth_rate, kernel_size=<span class="number">3</span>)]   <span class="comment">#添加第一个DenseLayer层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">1</span>):  <span class="comment">#每一层的输入通道数是之前所有层输出通道数的累加</span></span><br><span class="line">            <span class="variable language_">self</span>.block.append(DenseLayer(growth_rate * (i + <span class="number">1</span>), growth_rate, kernel_size=<span class="number">3</span>))  <span class="comment"># 开始加入之后的dense块的层 </span></span><br><span class="line">        <span class="variable language_">self</span>.block = nn.Sequential(*<span class="variable language_">self</span>.block)  <span class="comment"># 将所有层封装成一个Sequential模块  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="keyword">return</span> torch.cat([x, <span class="variable language_">self</span>.block(x)], <span class="number">1</span>)  <span class="comment"># 将输入x与DenseBlock的输出沿通道维拼接</span></span><br></pre></td></tr></table></figure><h3 id="3-整体架构"><a href="#3-整体架构" class="headerlink" title="3.整体架构"></a>3.整体架构</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SRDenseNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels=<span class="number">1</span>, growth_rate=<span class="number">16</span>, num_blocks=<span class="number">8</span>, num_layers=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SRDenseNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始低维特征提取层，将维度变为16*8</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = ConvLayer(num_channels, growth_rate * num_layers, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 高维特征提取层：8个dense块结构</span></span><br><span class="line">        <span class="variable language_">self</span>.dense_blocks = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            <span class="variable language_">self</span>.dense_blocks.append(DenseBlock(growth_rate * num_layers * (i + <span class="number">1</span>), growth_rate, num_layers))</span><br><span class="line">        <span class="variable language_">self</span>.dense_blocks = nn.Sequential(*<span class="variable language_">self</span>.dense_blocks)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 瓶颈层降低通道数</span></span><br><span class="line">        <span class="variable language_">self</span>.bottleneck = nn.Sequential(</span><br><span class="line">            <span class="comment">#8*16:8个dense块结束后的连接，8*8*16:8个dense块中的8层卷积层的连接</span></span><br><span class="line">            nn.Conv2d(growth_rate * num_layers + growth_rate * num_layers * num_blocks, <span class="number">256</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.deconv = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span> // <span class="number">2</span>, output_padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span> // <span class="number">2</span>, output_padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重建层</span></span><br><span class="line">        <span class="variable language_">self</span>.reconstruction = nn.Conv2d(<span class="number">256</span>, num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">3</span> // <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>): <span class="comment">#使用Kaiming初始化方法初始化权重</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d) <span class="keyword">or</span> <span class="built_in">isinstance</span>(m, nn.ConvTranspose2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight.data, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.zeros_(m.bias.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dense_blocks(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.bottleneck(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.deconv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.reconstruction(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="四-训练模型"><a href="#四-训练模型" class="headerlink" title="四.训练模型"></a>四.训练模型</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">model = SRDenseNet(growth_rate=args.growth_rate, num_blocks=args.num_blocks, num_layers=args.num_layers).to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.weights_file <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">## 如果提供了权重文件，则加载预训练权重 </span></span><br><span class="line">    state_dict = model.state_dict()</span><br><span class="line">    <span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(args.weights_file, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():</span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():</span><br><span class="line">            state_dict[n].copy_(p)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(n)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=args.lr)</span><br><span class="line"></span><br><span class="line">train_dataset = TrainDataset(args.train_file, patch_size=args.patch_size, scale=args.scale)</span><br><span class="line">train_dataloader = DataLoader(dataset=train_dataset,</span><br><span class="line">                              batch_size=args.batch_size,</span><br><span class="line">                              shuffle=<span class="literal">True</span>,</span><br><span class="line">                              num_workers=args.num_workers,</span><br><span class="line">                              pin_memory=<span class="literal">True</span>)</span><br><span class="line">eval_dataset = EvalDataset(args.eval_file)</span><br><span class="line">eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">best_weights = copy.deepcopy(model.state_dict())</span><br><span class="line">best_epoch = <span class="number">0</span></span><br><span class="line">best_psnr = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.num_epochs):</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="built_in">int</span>(args.num_epochs * <span class="number">0.8</span>)))</span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line">    epoch_losses = AverageMeter()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tqdm(total=(<span class="built_in">len</span>(train_dataset) - <span class="built_in">len</span>(train_dataset) % args.batch_size), ncols=<span class="number">80</span>) <span class="keyword">as</span> t:</span><br><span class="line">        t.set_description(<span class="string">&#x27;epoch: &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, args.num_epochs - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">            inputs, labels = data</span><br><span class="line"></span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            preds = model(inputs)</span><br><span class="line"></span><br><span class="line">            loss = criterion(preds, labels)</span><br><span class="line"></span><br><span class="line">            epoch_losses.update(loss.item(), <span class="built_in">len</span>(inputs))</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            t.set_postfix(loss=<span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch_losses.avg))</span><br><span class="line">            t.update(<span class="built_in">len</span>(inputs))</span><br><span class="line"></span><br><span class="line">    torch.save(model.state_dict(), os.path.join(args.outputs_dir, <span class="string">&#x27;epoch_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(epoch)))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    epoch_psnr = AverageMeter()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            preds = model(inputs).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">        preds = preds[:, :, args.scale:-args.scale, args.scale:-args.scale]</span><br><span class="line">        labels = labels[:, :, args.scale:-args.scale, args.scale:-args.scale]</span><br><span class="line"></span><br><span class="line">        epoch_psnr.update(calc_psnr(preds, labels), <span class="built_in">len</span>(inputs))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;eval psnr: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch_psnr.avg))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch_psnr.avg &gt; best_psnr:</span><br><span class="line">        best_epoch = epoch</span><br><span class="line">        best_psnr = epoch_psnr.avg</span><br><span class="line">        best_weights = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best epoch: &#123;&#125;, psnr: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(best_epoch, best_psnr))</span><br><span class="line">torch.save(best_weights, os.path.join(args.outputs_dir, <span class="string">&#x27;best.pth&#x27;</span>))</span><br></pre></td></tr></table></figure><h2 id="五-测试模型"><a href="#五-测试模型" class="headerlink" title="五.测试模型"></a>五.测试模型</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model = SRDenseNet().to(device)</span><br><span class="line"></span><br><span class="line">state_dict = model.state_dict()</span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(args.weights_file, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():</span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():</span><br><span class="line">        state_dict[n].copy_(p)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> KeyError(n)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">image = pil_image.<span class="built_in">open</span>(args.image_file).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">image_width = (image.width // args.scale) * args.scale</span><br><span class="line">image_height = (image.height // args.scale) * args.scale</span><br><span class="line"></span><br><span class="line">hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)</span><br><span class="line">lr = hr.resize((hr.width // args.scale, hr.height // args.scale), resample=pil_image.BICUBIC)</span><br><span class="line">bicubic = lr.resize((lr.width * args.scale, lr.height * args.scale), resample=pil_image.BICUBIC)</span><br><span class="line">bicubic.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_bicubic_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br><span class="line"></span><br><span class="line">lr, _ = preprocess(lr, device)<span class="comment">#分出y空间</span></span><br><span class="line">hr, _ = preprocess(hr, device)</span><br><span class="line">_, ycbcr = preprocess(bicubic, device) </span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    preds = model(lr).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">psnr = calc_psnr(hr, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;PSNR: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(psnr))</span><br><span class="line"></span><br><span class="line">preds = preds.mul(<span class="number">255.0</span>).cpu().numpy().squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">output = np.array([preds, ycbcr[..., <span class="number">1</span>], ycbcr[..., <span class="number">2</span>]]).transpose([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">output = np.clip(convert_ycbcr_to_rgb(output), <span class="number">0.0</span>, <span class="number">255.0</span>).astype(np.uint8)</span><br><span class="line">output = pil_image.fromarray(output)</span><br><span class="line">output.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_srdensenet_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第五章-SRDenseNet&quot;&gt;&lt;a href=&quot;#超分辨率第五章-SRDenseNet&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第五章-SRDenseNet&quot;&gt;&lt;/a&gt;超分辨率第五章-SRDenseNet&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;SRDenseNet发表于2017年&lt;/p&gt;
&lt;p&gt;论文：&lt;a href=&quot;https://ieeexplore.ieee.org/document/8237776&quot;&gt;Super-Resolution Using Dense Skip Connections&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;参考博客：&lt;a href=&quot;https://blog.csdn.net/MR_kdcon/article/details/123488533&quot;&gt;超分之SRDenseNet&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码位置：F:&#92;Github下载&#92;SRDenseNet-pytorch-master&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第四章-VDSR&amp;EDSR</title>
    <link href="http://example.com/2024/09/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%9B%9B%E7%AB%A0-VDSR&amp;EDSR/"/>
    <id>http://example.com/2024/09/20/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E5%9B%9B%E7%AB%A0-VDSR&amp;EDSR/</id>
    <published>2024-09-20T11:21:03.000Z</published>
    <updated>2024-09-23T13:12:19.794Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第四章-VDSR-amp-EDSR"><a href="#超分辨率第四章-VDSR-amp-EDSR" class="headerlink" title="超分辨率第四章-VDSR&amp;EDSR"></a>超分辨率第四章-VDSR&amp;EDSR</h1><blockquote><p>VDSR是2016年提出的模型</p><ul><li>论文地址：<a href="https://arxiv.org/abs/1511.04587">Accurate Image Super-Resolution Using Very Deep Convolutional Networks</a></li><li>代码位置：F:\Github下载\pytorch-vdsr-recurrence-main</li></ul><p>EDSR是是SRResNet的增强版本,2017年提出</p></blockquote><span id="more"></span><h2 id="一-VDSR"><a href="#一-VDSR" class="headerlink" title="一.VDSR"></a>一.VDSR</h2><h3 id="1-模型介绍"><a href="#1-模型介绍" class="headerlink" title="1.模型介绍"></a>1.模型介绍</h3><ul><li>SRCNN的不足<ul><li>在增加深度之后训练效果较差。</li><li>模型只适用于单个放大因子，若需使用其他放大因子的尺度，需另外训练一个模型。</li></ul></li><li>改进措施<ul><li>基于VGG网络的方法，增强感受野，模型深度达到20层。</li><li>使用残差网络训练模型，避免退化问题。</li><li><strong>使用高学习率（0.1开始）加快收敛速度，并使用一个可调的梯度裁剪，以最大限度地提高速度，同时抑制爆炸梯度。</strong></li><li>SRCNN是针对单一尺度进行训练的，如果需要处理不同尺度的图像，则需要训练多个模型。而VDSR通过训练一个单一的网络来处理多尺度的超分辨率问题，显著降低了参数量并提高了实用性</li></ul></li><li>模型架构：作者使用20个网络层，除第一层和最后一层外，其余层具有相同的类型：64个大小为3x3x64的滤波器，也就是每一层滤波器的输入通道数为64，输出通道数也为64。其中一个滤波器在3*3的空间区域上操作。第一个网络层对输入图像进行操作，最后一个网络层用于图像重建。</li></ul><p><img src="https://s21.ax1x.com/2024/09/23/pAQCOc4.png" alt="pAQCOc4.png"></p><h3 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2.数据集"></a>2.数据集</h3><ul><li>训练集-91张图片（进行数据增强后得到训练集）</li><li>测试集-set5</li></ul><h3 id="3-模型结构"><a href="#3-模型结构" class="headerlink" title="3.模型结构"></a>3.模型结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置中间层结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conv_ReLU_Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Conv_ReLU_Block, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主要网络结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, <span class="variable language_">self</span>).__init__() </span><br><span class="line">        <span class="variable language_">self</span>.residual_layer = <span class="variable language_">self</span>.make_layer(Conv_ReLU_Block, <span class="number">18</span>) <span class="comment">#18个3*3*64的中间层结构</span></span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">input</span> = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>) <span class="comment">#输入层</span></span><br><span class="line">        <span class="variable language_">self</span>.output = nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>) <span class="comment">#输出层</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化Conv2d层中的权重，使用高斯分布，标准差根据输入特征数量动态计算  </span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, sqrt(<span class="number">2.</span> / n))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_layer</span>(<span class="params">self, block, num_of_layer</span>): <span class="comment">#创建中间层</span></span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_of_layer):</span><br><span class="line">            layers.append(block())</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = x <span class="comment">#原始输入作为残差</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.<span class="built_in">input</span>(x)) <span class="comment">#依次通过输入层、中间层、输出层 </span></span><br><span class="line">        out = <span class="variable language_">self</span>.residual_layer(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.output(out)</span><br><span class="line">        out = torch.add(out, residual) <span class="comment">#输出与残差相加，实现残差连接</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    modeltest = Net()</span><br><span class="line">    <span class="built_in">print</span>(modeltest)</span><br></pre></td></tr></table></figure><h3 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4.模型训练"></a>4.模型训练</h3><p>参数设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Namespace(batchSize=<span class="number">128</span>, nEpochs=<span class="number">50</span>, lr=<span class="number">0.1</span>, step=<span class="number">10</span>, cuda=<span class="literal">True</span>, resume=<span class="string">&#x27;&#x27;</span>, start_epoch=<span class="number">1</span>, clip=<span class="number">0.4</span>, threads=<span class="number">1</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>, pretrained=<span class="string">&#x27;none&#x27;</span>, gpus=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">train_set = DatasetFromHdf5(<span class="string">&quot;data/train.h5&quot;</span>)  </span><br><span class="line">training_data_loader = DataLoader(dataset=train_set, batch_size=opt.batchSize, shuffle=<span class="literal">True</span>) </span><br><span class="line">model = Net() </span><br><span class="line">criterion = nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>) </span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=opt.lr, momentum=opt.momentum, weight_decay=opt.weight_decay)  <span class="comment"># 设置优化器  </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.start_epoch, opt.nEpochs + <span class="number">1</span>):  </span><br><span class="line">    train(training_data_loader, optimizer, model, criterion, epoch)  <span class="comment"># 调用训练函数  </span></span><br><span class="line">    save_checkpoint(model, epoch)  <span class="comment"># 保存每轮训练后的权重</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">training_data_loader, optimizer, model, criterion, epoch</span>):  </span><br><span class="line">    <span class="comment">#每轮调整学习率</span></span><br><span class="line">    lr = adjust_learning_rate(optimizer, epoch-<span class="number">1</span>)  </span><br><span class="line">    <span class="comment">#遍历优化器的参数组，将每个组的学习率设置为新的学习率  </span></span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:  </span><br><span class="line">        param_group[<span class="string">&quot;lr&quot;</span>] = lr  </span><br><span class="line">    <span class="comment"># 打印当前epoch和对应的学习率  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch = &#123;&#125;, lr = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 设置模型为训练模式  </span></span><br><span class="line">    model.train()  </span><br><span class="line">    <span class="keyword">for</span> iteration, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(training_data_loader, <span class="number">1</span>):  </span><br><span class="line">        <span class="built_in">input</span>, target = Variable(batch[<span class="number">0</span>]), Variable(batch[<span class="number">1</span>], requires_grad=<span class="literal">False</span>)    </span><br><span class="line">        <span class="keyword">if</span> opt.cuda:  </span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">            target = target.cuda()  </span><br><span class="line">            </span><br><span class="line">        loss = criterion(model(<span class="built_in">input</span>), target)  </span><br><span class="line">        optimizer.zero_grad()   </span><br><span class="line">        loss.backward()  </span><br><span class="line">        nn.utils.clip_grad_norm_(model.parameters(), opt.clip)   <span class="comment">#梯度裁剪是一种技术，用于控制梯度的更新量，以避免在训练过程中出现梯度爆炸的问题，从而有助于模型训练的稳定性，当调用 nn.utils.clip_grad_norm_(model.parameters(), opt.clip) 时，PyTorch 会计算模型所有参数的梯度的L2范数。如果这个范数大于 opt.clip 指定的值，那么每个参数的梯度将会按比例缩放，使得最终的L2范数等于 opt.clip。</span></span><br><span class="line">        optimizer.step()  </span><br></pre></td></tr></table></figure><h2 id="二-EDSR"><a href="#二-EDSR" class="headerlink" title="二. EDSR"></a>二. EDSR</h2><ul><li>在SRResnet的基础上去除了BN层</li></ul><p><img src="https://s21.ax1x.com/2024/09/23/pAQm0Gn.png" alt="pAQm0Gn.png"></p><p>结构如下：</p><ul><li><img src="https://s21.ax1x.com/2024/09/23/pAQmDx0.png" alt="pAQmDx0.png"></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第四章-VDSR-amp-EDSR&quot;&gt;&lt;a href=&quot;#超分辨率第四章-VDSR-amp-EDSR&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第四章-VDSR&amp;amp;EDSR&quot;&gt;&lt;/a&gt;超分辨率第四章-VDSR&amp;amp;EDSR&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;VDSR是2016年提出的模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1511.04587&quot;&gt;Accurate Image Super-Resolution Using Very Deep Convolutional Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码位置：F:&#92;Github下载&#92;pytorch-vdsr-recurrence-main&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;EDSR是是SRResNet的增强版本,2017年提出&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第三章-SRGAN</title>
    <link href="http://example.com/2024/09/17/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%89%E7%AB%A0-SRGAN/"/>
    <id>http://example.com/2024/09/17/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%89%E7%AB%A0-SRGAN/</id>
    <published>2024-09-17T07:33:29.000Z</published>
    <updated>2024-09-19T13:56:30.064Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第三章-SRGAN"><a href="#超分辨率第三章-SRGAN" class="headerlink" title="超分辨率第三章-SRGAN"></a>超分辨率第三章-SRGAN</h1><blockquote><p>SRGNN是2017年提出的模型，首次使用GAN在超分辨领域。</p><p>参考文献：<a href="https://arxiv.org/abs/1609.04802">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</a></p><p>参考博客：<a href="https://blog.csdn.net/qq_47071847/article/details/130859675">基于pytorch的SRGAN实现(全网最细!!!)</a></p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><ul><li><p>先前超分辨率模型的局限性：虽然具有较高的峰值信噪比，但它们通常缺乏高频细节，并且在感知上不令人满意。</p></li><li><p>SRGAN中的生成网络就是SRResNet网络，其以ResNet块为基本结构，是一个具有深度的SR网络。生成网络使用感知损失进行训练，而不是传统的MSE方法，它使用预训练之后的VGG-16网络产生的feature map级进行计算，再加上本身生成网络带有的对抗损失。此外判别器也需要去训练，两个网络结合起来就是我们的SRGAN网络。</p></li><li><p>SRGNN提出了感知损失函数（Perceptual loss function），包括对抗损失与内容损失，在感知质量方面有了极大改进。MOS（平均意见得分）很高。</p></li></ul><h3 id="1-感知损失函数（Perceptual-loss-function）"><a href="#1-感知损失函数（Perceptual-loss-function）" class="headerlink" title="1.感知损失函数（Perceptual loss function）"></a>1.感知损失函数（Perceptual loss function）</h3><ul><li><script type="math/tex; mode=display">l ^ { S R } = l _ { X } ^ { S R } + 1 0 ^ { - 3 } l _ { G e n } ^ { S R }</script><ul><li>由基于VGG-16的内容损失函数和GAN的对抗损失函数组成</li></ul></li><li>内容损失函数<ul><li><script type="math/tex; mode=display">I _ { X } ^ { S R } = I _ { V G G / ( i , j ) } ^ { S R } = \frac { 1 } { W _ { i , j } H _ { i , j } } \sum _ { x = 1 } ^ { W _ { i , j } } ( \phi _ { i , j } ( G _ { 0 , i } ( I ^ { L R } ) ) _ { x , y } - \phi _ { i , j } ( I ^ { H R } ) _ { x , y } ) ^ { 2 } .</script></li><li>采用预训练好的VGG-16网络的特征向量，使得生成网络的结果<script type="math/tex">G( I ^ { L R })</script>通过VGG某一层之后产生的feature map和原始高分辨率图像<script type="math/tex">I ^ { H R }</script>通过VGG-16网络产生的feature map做loss，作者指出这种loss更能反应图片之间的感知相似度。</li></ul></li><li>对抗损失函数<ul><li><script type="math/tex; mode=display">I _ { G e n } ^ { S R } = \sum _ { n = 1 } ^ { N } - \log D _ { \theta _ { D } } ( G _ { \theta _ { G } } ( I ^ { L R } ) ) .</script></li></ul></li></ul><h3 id="2-论文贡献"><a href="#2-论文贡献" class="headerlink" title="2.论文贡献"></a>2.论文贡献</h3><ul><li>深度RESNet（SRRESNet）针对MSE进行了优化，通过PSNR和结构相似度(SSIM)来测量图像SR的高放大因子</li><li>SRGAN，是一种基于GAN的网络，针对一种新的感知损失进行了优化。用在VGG网络的特征映射上计算的损失来代替基于MSE的内容损失，该特征映射对像素空间的变化更加不变，这样相较于原来像素损失超分的图像更具有纹理等高频细节.</li><li>对来自三个公共基准数据集的图像进行广泛的平均意见得分(MOS)测试，证实SRGAN在很大程度上是高放大因子(4×)的照片真实感SR图像估计的最新技术, 即超分后的图像更加接近自然图像.</li></ul><h3 id="3-模型结构"><a href="#3-模型结构" class="headerlink" title="3.模型结构"></a>3.模型结构</h3><p><img src="https://s21.ax1x.com/2024/09/19/pAKsjR1.png" alt="pAKsjR1.png"></p><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><ul><li>训练集使用：VOC2012（训练数据集包含16700张图片，验证数据集包含425张图片）</li><li>测试集使用：Set5 Set14 BSD100 Urban100 SunHays80</li></ul><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><h3 id="1-生成器结构"><a href="#1-生成器结构" class="headerlink" title="1.生成器结构"></a>1.生成器结构</h3><ul><li>输入一张低分辨率图片，生成高分辨率图片</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, scale_factor</span>):</span><br><span class="line">        upsample_block_num = <span class="built_in">int</span>(math.log(scale_factor, <span class="number">2</span>)) <span class="comment">#计算上采样块的数量，输入放大因子为4，则有两个上采样块</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(Generator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.block1 = nn.Sequential( <span class="comment">#首先放大维度，特征提取</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">9</span>, padding=<span class="number">4</span>),</span><br><span class="line">            nn.PReLU()</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.block2 = ResidualBlock(<span class="number">64</span>) <span class="comment">#5个残差网络块，特征提取</span></span><br><span class="line">        <span class="variable language_">self</span>.block3 = ResidualBlock(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.block4 = ResidualBlock(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.block5 = ResidualBlock(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.block6 = ResidualBlock(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.block7 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        )</span><br><span class="line">        block8 = [UpsampleBLock(<span class="number">64</span>, <span class="number">2</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(upsample_block_num)] <span class="comment">#定义了一个列表，进行上采样两次提高分辨率，每次提高2倍，共提升4倍</span></span><br><span class="line">        block8.append(nn.Conv2d(<span class="number">64</span>, <span class="number">3</span>, kernel_size=<span class="number">9</span>, padding=<span class="number">4</span>))<span class="comment">#向该列表添加一个卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.block8 = nn.Sequential(*block8)<span class="comment">#将这些层组合成一个顺序模型</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        block1 = <span class="variable language_">self</span>.block1(x)</span><br><span class="line">        block2 = <span class="variable language_">self</span>.block2(block1)</span><br><span class="line">        block3 = <span class="variable language_">self</span>.block3(block2)</span><br><span class="line">        block4 = <span class="variable language_">self</span>.block4(block3)</span><br><span class="line">        block5 = <span class="variable language_">self</span>.block5(block4)</span><br><span class="line">        block6 = <span class="variable language_">self</span>.block6(block5)</span><br><span class="line">        block7 = <span class="variable language_">self</span>.block7(block6)</span><br><span class="line">        block8 = <span class="variable language_">self</span>.block8(block1 + block7) <span class="comment">#特征融合相加</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (torch.tanh(block8) + <span class="number">1</span>) / <span class="number">2</span> <span class="comment">#使用torch.tanh函数将输出值映射到[-1, 1]区间，并通过(torch.tanh(block8) + 1) / 2将其缩放到[0, 1]区间，这是图像数据常见的归一化范围。</span></span><br></pre></td></tr></table></figure><h3 id="2-判别器结构"><a href="#2-判别器结构" class="headerlink" title="2.判别器结构"></a>2.判别器结构</h3><ul><li>输入图片，判断真假</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.net = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>), <span class="comment">#一个自适应平均池化层，它该层都会将其空间维度（高度和宽度）压缩到1x1，而保持通道数不变</span></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">1024</span>, <span class="number">1</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(<span class="variable language_">self</span>.net(x).view(batch_size)) <span class="comment">#显示输入图片为真实的概率，将最终的输出（原本是一个形状为(batch_size, 1, 1, 1)的四维张量）展平成一个一维张量，其长度为批次大小，其元素对应于批次中每个样本的判别结果</span></span><br></pre></td></tr></table></figure><h3 id="3-resnet结构"><a href="#3-resnet结构" class="headerlink" title="3.resnet结构"></a>3.resnet结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResidualBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(channels, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(channels)</span><br><span class="line">        <span class="variable language_">self</span>.prelu = nn.PReLU()</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(channels, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        residual = <span class="variable language_">self</span>.bn1(residual)</span><br><span class="line">        residual = <span class="variable language_">self</span>.prelu(residual)</span><br><span class="line">        residual = <span class="variable language_">self</span>.conv2(residual)</span><br><span class="line">        residual = <span class="variable language_">self</span>.bn2(residual)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x + residual</span><br></pre></td></tr></table></figure><h3 id="4-上采样结构"><a href="#4-上采样结构" class="headerlink" title="4.上采样结构"></a>4.上采样结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UpsampleBLock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, up_scale</span>):</span><br><span class="line">        <span class="built_in">super</span>(UpsampleBLock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, in_channels * up_scale ** <span class="number">2</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)<span class="comment">#up_scale ** 2是因为之后的像素重排（pixel shuffle）操作会将通道数重排成空间维度，以达到上采样的效果，此时增加维度可以保持整体维度不变。</span></span><br><span class="line">        <span class="variable language_">self</span>.pixel_shuffle = nn.PixelShuffle(up_scale) <span class="comment">#这个层将输入特征图的通道数重新排列成空间维度，以实现上采样（新的通道数将是原始通道数除以up_scale^2，而高度和宽度将会乘以up_scale）</span></span><br><span class="line">        <span class="variable language_">self</span>.prelu = nn.PReLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pixel_shuffle(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.prelu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="四-损失函数"><a href="#四-损失函数" class="headerlink" title="四.损失函数"></a>四.损失函数</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models.vgg <span class="keyword">import</span> vgg16</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GeneratorLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(GeneratorLoss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment">#使用预训练的 VGG16 模型来构建特征提取网络</span></span><br><span class="line">        vgg = vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#选择 VGG16 模型的前 31 层作为损失网络，并将其设置为评估模式（不进行梯度更新）</span></span><br><span class="line">        loss_network = nn.Sequential(*<span class="built_in">list</span>(vgg.features)[:<span class="number">31</span>]).<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment">#冻结其参数，不进行梯度更新</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> loss_network.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line">        <span class="comment">#定义VGG16网络</span></span><br><span class="line">        <span class="variable language_">self</span>.loss_network = loss_network</span><br><span class="line">        <span class="comment">#定义均方误差损失函数，计算生成器生成图像与目标图像之间的均方误差损失</span></span><br><span class="line">        <span class="variable language_">self</span>.mse_loss = nn.MSELoss()</span><br><span class="line">        <span class="comment">#定义总变差损失函数，计算生成器生成图像的总变差损失，用于平滑生成的图像</span></span><br><span class="line">        <span class="variable language_">self</span>.tv_loss = TVLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, out_labels, out_images, target_images</span>): <span class="comment">#分别传入判别器判定概率，伪高分辨率图像，真图像</span></span><br><span class="line">        <span class="comment"># Adversarial Loss（对抗损失）：使生成的图像更接近真实图像，目标是最小化生成器对图像的判别结果的平均值与 1(真实值)的差距</span></span><br><span class="line">        adversarial_loss = torch.mean(<span class="number">1</span> - out_labels)</span><br><span class="line">        <span class="comment"># Perception Loss（感知损失）：计算生成图像和目标图像在vgg-16网络中提取的特征之间的均方误差损失</span></span><br><span class="line">        perception_loss = <span class="variable language_">self</span>.mse_loss(<span class="variable language_">self</span>.loss_network(out_images), <span class="variable language_">self</span>.loss_network(target_images))</span><br><span class="line">        <span class="comment"># Image Loss（图像损失）：计算生成图像和目标图像之间的均方误差损失</span></span><br><span class="line">        image_loss = <span class="variable language_">self</span>.mse_loss(out_images, target_images)</span><br><span class="line">        <span class="comment"># TV Loss（总变差损失）：计算生成图像的总变差损失，用于平滑生成的图像</span></span><br><span class="line">        tv_loss = <span class="variable language_">self</span>.tv_loss(out_images)</span><br><span class="line">        <span class="comment"># 返回生成器的总损失，四个损失项加权求和</span></span><br><span class="line">        <span class="keyword">return</span> image_loss + <span class="number">0.001</span> * adversarial_loss + <span class="number">0.006</span> * perception_loss + <span class="number">2e-8</span> * tv_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 总变差损失衡量的是图像中相邻像素之间的差异程度</span></span><br><span class="line"><span class="comment"># 在模型训练过程中，将总变差损失作为损失函数的一部分，可以引导模型在优化过程中考虑图像的空间连续性，从而生成更加符合人类直觉的图像。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TVLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tv_loss_weight=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TVLoss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tv_loss_weight = tv_loss_weight</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batch_size = x.size()[<span class="number">0</span>]</span><br><span class="line">        h_x = x.size()[<span class="number">2</span>]</span><br><span class="line">        w_x = x.size()[<span class="number">3</span>]</span><br><span class="line">        count_h = <span class="variable language_">self</span>.tensor_size(x[:, :, <span class="number">1</span>:, :])</span><br><span class="line">        count_w = <span class="variable language_">self</span>.tensor_size(x[:, :, :, <span class="number">1</span>:])</span><br><span class="line">        <span class="comment"># 计算水平方向上的总变差损失</span></span><br><span class="line">        h_tv = torch.<span class="built_in">pow</span>((x[:, :, <span class="number">1</span>:, :] - x[:, :, :h_x - <span class="number">1</span>, :]), <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">        <span class="comment"># 计算垂直方向上的总变差损失</span></span><br><span class="line">        w_tv = torch.<span class="built_in">pow</span>((x[:, :, :, <span class="number">1</span>:] - x[:, :, :, :w_x - <span class="number">1</span>]), <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">        <span class="comment"># 返回总变差损失</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.tv_loss_weight * <span class="number">2</span> * (h_tv / count_h + w_tv / count_w) / batch_size</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tensor_size</span>(<span class="params">t</span>):</span><br><span class="line">        <span class="comment"># 返回张量的尺寸大小，即通道数乘以高度乘以宽度</span></span><br><span class="line">        <span class="keyword">return</span> t.size()[<span class="number">1</span>] * t.size()[<span class="number">2</span>] * t.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    g_loss = GeneratorLoss()</span><br><span class="line">    <span class="built_in">print</span>(g_loss)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="五-模型训练"><a href="#五-模型训练" class="headerlink" title="五.模型训练"></a>五.模型训练</h2><h3 id="1-载入数据集与初始化网络"><a href="#1-载入数据集与初始化网络" class="headerlink" title="1.载入数据集与初始化网络"></a>1.载入数据集与初始化网络</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">opt = parser.parse_args()<span class="comment">#用户可以在命令行中指定一些参数（如裁剪大小、放大因子、训练轮数等），这些参数将被存储在opt对象中</span></span><br><span class="line"></span><br><span class="line">CROP_SIZE = opt.crop_size</span><br><span class="line">UPSCALE_FACTOR = opt.upscale_factor</span><br><span class="line">NUM_EPOCHS = opt.num_epochs</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建训练和验证数据集</span></span><br><span class="line">train_set = TrainDatasetFromFolder(<span class="string">&#x27;data/VOC2012/train&#x27;</span>, crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)</span><br><span class="line">val_set = ValDatasetFromFolder(<span class="string">&#x27;data/VOC2012/val&#x27;</span>, upscale_factor=UPSCALE_FACTOR)</span><br><span class="line"><span class="comment">#创建数据加载器</span></span><br><span class="line">train_loader = DataLoader(dataset=train_set, num_workers=<span class="number">4</span>, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">val_loader = DataLoader(dataset=val_set, num_workers=<span class="number">4</span>, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化生成器（netG）和判别器（netD）网络，并打印生成器和判别器的参数数量</span></span><br><span class="line">netG = Generator(UPSCALE_FACTOR)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# generator parameters:&#x27;</span>, <span class="built_in">sum</span>(param.numel() <span class="keyword">for</span> param <span class="keyword">in</span> netG.parameters()))</span><br><span class="line">netD = Discriminator()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# discriminator parameters:&#x27;</span>, <span class="built_in">sum</span>(param.numel() <span class="keyword">for</span> param <span class="keyword">in</span> netD.parameters()))</span><br><span class="line"></span><br><span class="line">generator_criterion = GeneratorLoss()<span class="comment">#定义生成器的内容损失函数，此处会引入VGG16网络进行计算</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    netG.cuda()</span><br><span class="line">    netD.cuda()</span><br><span class="line">    generator_criterion.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化优化器</span></span><br><span class="line">optimizerG = optim.Adam(netG.parameters())</span><br><span class="line">optimizerD = optim.Adam(netD.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化一个字典results，用于存储训练过程中的各种指标（如判别器和生成器的损失、评分、PSNR、SSIM等）。这些指标将用于评估训练过程中的模型性能。</span></span><br><span class="line">results = &#123;<span class="string">&#x27;d_loss&#x27;</span>: [], <span class="string">&#x27;g_loss&#x27;</span>: [], <span class="string">&#x27;d_score&#x27;</span>: [], <span class="string">&#x27;g_score&#x27;</span>: [], <span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;</span><br></pre></td></tr></table></figure><h3 id="2-训练阶段"><a href="#2-训练阶段" class="headerlink" title="2.训练阶段"></a>2.训练阶段</h3><ul><li>生成器（Generator）和判别器（Discriminator）交替训练</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, NUM_EPOCHS + <span class="number">1</span>):</span><br><span class="line">    train_bar = tqdm(train_loader)</span><br><span class="line">    running_results = &#123;<span class="string">&#x27;batch_sizes&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;d_loss&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;g_loss&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;d_score&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;g_score&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">    netG.train()</span><br><span class="line">    netD.train()</span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> train_bar:</span><br><span class="line">        g_update_first = <span class="literal">True</span></span><br><span class="line">        batch_size = data.size(<span class="number">0</span>)</span><br><span class="line">        running_results[<span class="string">&#x27;batch_sizes&#x27;</span>] += batch_size</span><br><span class="line"></span><br><span class="line">        <span class="comment">#先训练判别器，输入就是真图片、假图片和它们对应的标签。</span></span><br><span class="line">        <span class="comment"># (1) Update D network: maximize D(x)-1-D(G(z))</span></span><br><span class="line">        real_img = target <span class="comment">#真实图片</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            real_img = real_img.<span class="built_in">float</span>().cuda()</span><br><span class="line">        z = data <span class="comment">#低分辨率图片</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            z = z.<span class="built_in">float</span>().cuda()</span><br><span class="line"></span><br><span class="line">        fake_img = netG(z) <span class="comment">#通过生成器生成高分辨率伪图片</span></span><br><span class="line">        optimizerD.zero_grad() <span class="comment">#清除判别器的梯度</span></span><br><span class="line">        real_out = netD(real_img).mean() <span class="comment">#通过判别器对真实图像进行前向传播，并计算其输出的平均值</span></span><br><span class="line">        fake_out = netD(fake_img).mean() <span class="comment">#通过判别器对伪图像进行前向传播，并计算其输出的平均值</span></span><br><span class="line">        d_loss = <span class="number">1</span> - real_out + fake_out <span class="comment">#计算判别器的损失</span></span><br><span class="line">        d_loss.backward(retain_graph=<span class="literal">True</span>) <span class="comment">#反向传播，计算判别器的梯度，并保留计算图以进行后续优化步骤</span></span><br><span class="line">        optimizerD.step() <span class="comment">#对判别器网络梯度进行更新</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#再训练生成器，在训练生成器的时候我们希望生成器可以生成极为真实的假图片。因此我们在训练生成器需要知道判别器认为什么图片是真图片</span></span><br><span class="line">        <span class="comment"># (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss</span></span><br><span class="line">        optimizerG.zero_grad() <span class="comment">#清除生成器的梯度</span></span><br><span class="line">        fake_img = netG(z) <span class="comment">#通过生成器生成高分辨率伪图片</span></span><br><span class="line">        fake_out = netD(fake_img).mean() <span class="comment">#通过判别器对伪图像进行前向传播，并计算其输出的平均值</span></span><br><span class="line">        g_loss = generator_criterion(fake_out, fake_img, real_img)<span class="comment"># 计算生成器的损失，包括对抗损失、感知损失、图像损失和TV损失</span></span><br><span class="line">        g_loss.backward() <span class="comment">#反向传播，计算生成器的梯度</span></span><br><span class="line">        optimizerG.step() <span class="comment">#对生成器网络梯度进行更新</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># loss for current batch before optimization</span></span><br><span class="line">        <span class="comment">#累加当前批次生成器的损失值乘以批次大小，用于计算平均损失</span></span><br><span class="line">        running_results[<span class="string">&#x27;g_loss&#x27;</span>] += g_loss.item() * batch_size</span><br><span class="line">        <span class="comment">#累加当前批次判别器的损失值乘以批次大小，用于计算平均损失</span></span><br><span class="line">        running_results[<span class="string">&#x27;d_loss&#x27;</span>] += d_loss.item() * batch_size</span><br><span class="line">        <span class="comment">#累加当前批次真实图像在判别器的输出得分乘以批次大小，用于计算平均得分</span></span><br><span class="line">        running_results[<span class="string">&#x27;d_score&#x27;</span>] += real_out.item() * batch_size</span><br><span class="line">        <span class="comment">#累加当前批次伪图像在判别器的输出得分乘以批次大小，用于计算平均得分</span></span><br><span class="line">        running_results[<span class="string">&#x27;g_score&#x27;</span>] += fake_out.item() * batch_size</span><br><span class="line"></span><br><span class="line">        <span class="comment">#更新训练进度条的描述信息</span></span><br><span class="line">        train_bar.set_description(desc=<span class="string">&#x27;[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f&#x27;</span> % (</span><br><span class="line">            epoch, NUM_EPOCHS, running_results[<span class="string">&#x27;d_loss&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>],</span><br><span class="line">            running_results[<span class="string">&#x27;g_loss&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>],</span><br><span class="line">            running_results[<span class="string">&#x27;d_score&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>],</span><br><span class="line">            running_results[<span class="string">&#x27;g_score&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>]))</span><br></pre></td></tr></table></figure><h3 id="3-验证阶段"><a href="#3-验证阶段" class="headerlink" title="3.验证阶段"></a>3.验证阶段</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">netG.<span class="built_in">eval</span>() <span class="comment">#生成器验证模式</span></span><br><span class="line">out_path = <span class="string">&#x27;training_results/SRF_&#x27;</span> + <span class="built_in">str</span>(UPSCALE_FACTOR) + <span class="string">&#x27;/&#x27;</span> <span class="comment">#创建用于保存训练结果的目录</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">    os.makedirs(out_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    val_bar = tqdm(val_loader) <span class="comment">#验证集进度条</span></span><br><span class="line">    valing_results = &#123;<span class="string">&#x27;mse&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;ssims&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;psnr&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;ssim&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;batch_sizes&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line">    val_images = []</span><br><span class="line">    <span class="keyword">for</span> val_lr, val_hr_restore, val_hr <span class="keyword">in</span> val_bar: <span class="comment">#遍历验证数据集(低分辨率图 恢复的高分辨率图 高分辨率图）</span></span><br><span class="line">        batch_size = val_lr.size(<span class="number">0</span>)</span><br><span class="line">        valing_results[<span class="string">&#x27;batch_sizes&#x27;</span>] += batch_size</span><br><span class="line">        lr = val_lr</span><br><span class="line">        hr = val_hr</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            lr = lr.<span class="built_in">float</span>().cuda()</span><br><span class="line">            hr = hr.<span class="built_in">float</span>().cuda()</span><br><span class="line">        sr = netG(lr) <span class="comment">#生成超分辨率图像</span></span><br><span class="line"></span><br><span class="line">        batch_mse = ((sr - hr) ** <span class="number">2</span>).data.mean() <span class="comment">#计算批量图像的均方误差，这里应该使用.mean()而不是.data.mean()，后者在PyTorch新版本中已不推荐</span></span><br><span class="line">        valing_results[<span class="string">&#x27;mse&#x27;</span>] += batch_mse * batch_size <span class="comment">#累加均方误差</span></span><br><span class="line">        batch_ssim = pytorch_ssim.ssim(sr, hr).item() <span class="comment">#计算批量图像的结构相似度指数</span></span><br><span class="line">        valing_results[<span class="string">&#x27;ssims&#x27;</span>] += batch_ssim * batch_size <span class="comment">#累加结构相似度指数</span></span><br><span class="line">        <span class="comment">#计算平均峰值信噪比</span></span><br><span class="line">        valing_results[<span class="string">&#x27;psnr&#x27;</span>] = <span class="number">10</span> * log10((hr.<span class="built_in">max</span>()**<span class="number">2</span>) / (valing_results[<span class="string">&#x27;mse&#x27;</span>] / valing_results[<span class="string">&#x27;batch_sizes&#x27;</span>]))</span><br><span class="line">        <span class="comment">#计算平均结构相似度指数</span></span><br><span class="line">        valing_results[<span class="string">&#x27;ssim&#x27;</span>] = valing_results[<span class="string">&#x27;ssims&#x27;</span>] / valing_results[<span class="string">&#x27;batch_sizes&#x27;</span>]</span><br><span class="line">        <span class="comment">#更新训练进度条的描述信息</span></span><br><span class="line">        val_bar.set_description(</span><br><span class="line">            desc=<span class="string">&#x27;[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f&#x27;</span> % (</span><br><span class="line">                valing_results[<span class="string">&#x27;psnr&#x27;</span>], valing_results[<span class="string">&#x27;ssim&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#将验证图像添加到列表中，用于后续保存</span></span><br><span class="line">        val_images.extend(</span><br><span class="line">            [display_transform()(val_hr_restore.squeeze(<span class="number">0</span>)), display_transform()(hr.data.cpu().squeeze(<span class="number">0</span>)),</span><br><span class="line">             display_transform()(sr.data.cpu().squeeze(<span class="number">0</span>))])</span><br><span class="line">    val_images = torch.stack(val_images)  <span class="comment">#将验证图像列表堆叠为张量</span></span><br><span class="line">    val_images = torch.chunk(val_images, val_images.size(<span class="number">0</span>) // <span class="number">15</span>) <span class="comment">#将堆叠后的张量分割为多个小块，每个小块包含15张图像</span></span><br><span class="line">    val_save_bar = tqdm(val_images, desc=<span class="string">&#x27;[saving training results]&#x27;</span>) <span class="comment">#创建保存图像进度条，并设置描述为“[saving training results]”</span></span><br><span class="line">    index = <span class="number">1</span></span><br><span class="line">    <span class="comment">#遍历图像批次并保存</span></span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> val_save_bar:</span><br><span class="line">        image = utils.make_grid(image, nrow=<span class="number">3</span>, padding=<span class="number">5</span>) <span class="comment">#将小块中的图像创建为一个网格，每行显示3张图像，图像之间有5个像素的间隔</span></span><br><span class="line">        utils.save_image(image, out_path + <span class="string">&#x27;epoch_%d_index_%d.png&#x27;</span> % (epoch, index), padding=<span class="number">5</span>)</span><br><span class="line">        index += <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="4-保存文件"><a href="#4-保存文件" class="headerlink" title="4.保存文件"></a>4.保存文件</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将判别器和生成器的参数保存到指定文件</span></span><br><span class="line">torch.save(netG.state_dict(), <span class="string">&#x27;epochs/netG_epoch_%d_%d.pth&#x27;</span> % (UPSCALE_FACTOR, epoch))</span><br><span class="line">torch.save(netD.state_dict(), <span class="string">&#x27;epochs/netD_epoch_%d_%d.pth&#x27;</span> % (UPSCALE_FACTOR, epoch))</span><br><span class="line"><span class="comment"># save loss\scores\psnr\ssim</span></span><br><span class="line">results[<span class="string">&#x27;d_loss&#x27;</span>].append(running_results[<span class="string">&#x27;d_loss&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>])</span><br><span class="line">results[<span class="string">&#x27;g_loss&#x27;</span>].append(running_results[<span class="string">&#x27;g_loss&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>])</span><br><span class="line">results[<span class="string">&#x27;d_score&#x27;</span>].append(running_results[<span class="string">&#x27;d_score&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>])</span><br><span class="line">results[<span class="string">&#x27;g_score&#x27;</span>].append(running_results[<span class="string">&#x27;g_score&#x27;</span>] / running_results[<span class="string">&#x27;batch_sizes&#x27;</span>])</span><br><span class="line">results[<span class="string">&#x27;psnr&#x27;</span>].append(valing_results[<span class="string">&#x27;psnr&#x27;</span>])</span><br><span class="line">results[<span class="string">&#x27;ssim&#x27;</span>].append(valing_results[<span class="string">&#x27;ssim&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span> <span class="keyword">and</span> epoch != <span class="number">0</span>:</span><br><span class="line">    out_path = <span class="string">&#x27;statistics/&#x27;</span></span><br><span class="line">    <span class="comment"># 创建一个DataFrame对象，用于存储训练结果数据</span></span><br><span class="line">    data_frame = pd.DataFrame(</span><br><span class="line">        data=&#123;<span class="string">&#x27;Loss_D&#x27;</span>: results[<span class="string">&#x27;d_loss&#x27;</span>], <span class="string">&#x27;Loss_G&#x27;</span>: results[<span class="string">&#x27;g_loss&#x27;</span>], <span class="string">&#x27;Score_D&#x27;</span>: results[<span class="string">&#x27;d_score&#x27;</span>],</span><br><span class="line">              <span class="string">&#x27;Score_G&#x27;</span>: results[<span class="string">&#x27;g_score&#x27;</span>], <span class="string">&#x27;PSNR&#x27;</span>: results[<span class="string">&#x27;psnr&#x27;</span>], <span class="string">&#x27;SSIM&#x27;</span>: results[<span class="string">&#x27;ssim&#x27;</span>]&#125;,</span><br><span class="line">        index=<span class="built_in">range</span>(<span class="number">1</span>, epoch + <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将DataFrame对象保存为CSV文件</span></span><br><span class="line">    data_frame.to_csv(out_path + <span class="string">&#x27;srf_&#x27;</span> + <span class="built_in">str</span>(UPSCALE_FACTOR) + <span class="string">&#x27;_train_results.csv&#x27;</span>, index_label=<span class="string">&#x27;Epoch&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="五-模型测试"><a href="#五-模型测试" class="headerlink" title="五.模型测试"></a>五.模型测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log10</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.utils <span class="keyword">as</span> utils</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pytorch_ssim</span><br><span class="line"><span class="keyword">from</span> data_utils <span class="keyword">import</span> TestDatasetFromFolder, display_transform</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Generator</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Test Benchmark Datasets&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--upscale_factor&#x27;</span>, default=<span class="number">4</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;super resolution upscale factor&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--model_name&#x27;</span>, default=<span class="string">&#x27;netG_epoch_4_150.pth&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;generator model epoch name&#x27;</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">UPSCALE_FACTOR = opt.upscale_factor</span><br><span class="line">MODEL_NAME = opt.model_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存每个测试数据集的结果</span></span><br><span class="line">results = &#123;<span class="string">&#x27;Set5&#x27;</span>: &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;, <span class="string">&#x27;Set14&#x27;</span>: &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;, <span class="string">&#x27;BSD100&#x27;</span>: &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;,</span><br><span class="line">           <span class="string">&#x27;Urban100&#x27;</span>: &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;, <span class="string">&#x27;SunHays80&#x27;</span>: &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 Generator 对象</span></span><br><span class="line">model = Generator(UPSCALE_FACTOR).<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model = model.cuda()</span><br><span class="line"><span class="comment"># 加载训练好的模型参数</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;epochs/&#x27;</span> + MODEL_NAME))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载测试数据集</span></span><br><span class="line">test_set = TestDatasetFromFolder(<span class="string">&#x27;data/test&#x27;</span>, upscale_factor=UPSCALE_FACTOR)</span><br><span class="line">test_loader = DataLoader(dataset=test_set, num_workers=<span class="number">4</span>, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 创建一个用于 test_loader 的 tqdm 进度条</span></span><br><span class="line">test_bar = tqdm(test_loader, desc=<span class="string">&#x27;[testing benchmark datasets]&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试结果输出路径</span></span><br><span class="line">out_path = <span class="string">&#x27;benchmark_results/SRF_&#x27;</span> + <span class="built_in">str</span>(UPSCALE_FACTOR) + <span class="string">&#x27;/&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">    os.makedirs(out_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_name, lr_image, hr_restore_img, hr_image <span class="keyword">in</span> test_bar:</span><br><span class="line">    <span class="comment"># 由于 image_name 是一个包含单个元素的列表，所以将其取出</span></span><br><span class="line">    image_name = image_name[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 将 lr_image 转换为 Variable 对象，并设置 volatile=True</span></span><br><span class="line">    <span class="comment"># volatile=True 表示不会计算梯度，这在推理阶段通常是需要的</span></span><br><span class="line">    lr_image = Variable(lr_image, volatile=<span class="literal">True</span>)</span><br><span class="line">    hr_image = Variable(hr_image, volatile=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        lr_image = lr_image.cuda()</span><br><span class="line">        hr_image = hr_image.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成超分变率图像</span></span><br><span class="line">    sr_image = model(lr_image)</span><br><span class="line"></span><br><span class="line">    mse = ((hr_image - sr_image) ** <span class="number">2</span>).data.mean()</span><br><span class="line">    <span class="comment"># 计算峰值信噪比（Peak Signal-to-Noise Ratio）</span></span><br><span class="line">    psnr = <span class="number">10</span> * log10(<span class="number">255</span> ** <span class="number">2</span> / mse)</span><br><span class="line">    <span class="comment"># 计算结构相似性指数（Structural Similarity Index）</span></span><br><span class="line">    <span class="comment"># 使用 pytorch_ssim 库中的 ssim 函数计算 SSIM</span></span><br><span class="line">    ssim = pytorch_ssim.ssim(sr_image, hr_image).data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个包含三张图像的张量，分别是原始恢复的高分辨率图像、原始高分辨率图像和生成的超分辨率图像</span></span><br><span class="line">    <span class="comment"># 将每张图像应用 display_transform() 转换，并通过 squeeze(0) 去除批次维度</span></span><br><span class="line">    test_images = torch.stack(</span><br><span class="line">        [display_transform()(hr_restore_img.squeeze(<span class="number">0</span>)), display_transform()(hr_image.data.cpu().squeeze(<span class="number">0</span>)),</span><br><span class="line">         display_transform()(sr_image.data.cpu().squeeze(<span class="number">0</span>))])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 make_grid 函数将三张图像拼接成一张大图像</span></span><br><span class="line">    <span class="comment"># nrow=3 表示每行显示 3 张图像，padding=5 表示图像之间的间距为 5</span></span><br><span class="line">    image = utils.make_grid(test_images, nrow=<span class="number">3</span>, padding=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 save_image 函数将合成的图像保存到指定路径</span></span><br><span class="line">    utils.save_image(image, out_path + image_name.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;_psnr_%.4f_ssim_%.4f.&#x27;</span> % (psnr, ssim) +</span><br><span class="line">                     image_name.split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>], padding=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将对应数据集的PSNR和SSIM保存到对应的字典当中</span></span><br><span class="line">    results[image_name.split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]][<span class="string">&#x27;psnr&#x27;</span>].append(psnr)</span><br><span class="line">    results[image_name.split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]][<span class="string">&#x27;ssim&#x27;</span>].append(ssim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结果保存路径</span></span><br><span class="line">out_path = <span class="string">&#x27;statistics/&#x27;</span></span><br><span class="line">saved_results = &#123;<span class="string">&#x27;psnr&#x27;</span>: [], <span class="string">&#x27;ssim&#x27;</span>: []&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 results 字典中的每个值</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> results.values():</span><br><span class="line">    <span class="comment"># 获取 PSNR 和 SSIM 的列表</span></span><br><span class="line">    psnr = np.array(item[<span class="string">&#x27;psnr&#x27;</span>])</span><br><span class="line">    ssim = np.array(item[<span class="string">&#x27;ssim&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果列表为空，将 PSNR 和 SSIM 设置为 &#x27;No data&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(psnr) == <span class="number">0</span>) <span class="keyword">or</span> (<span class="built_in">len</span>(ssim) == <span class="number">0</span>):</span><br><span class="line">        psnr = <span class="string">&#x27;No data&#x27;</span></span><br><span class="line">        ssim = <span class="string">&#x27;No data&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果列表不为空，计算 PSNR 和 SSIM 的均值</span></span><br><span class="line">        psnr = psnr.mean()</span><br><span class="line">        ssim = ssim.mean()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将计算得到的 PSNR 和 SSIM 添加到 saved_results 字典的相应列表中</span></span><br><span class="line">    saved_results[<span class="string">&#x27;psnr&#x27;</span>].append(psnr)</span><br><span class="line">    saved_results[<span class="string">&#x27;ssim&#x27;</span>].append(ssim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 DataFrame 对象，使用 saved_results 字典作为数据，以 results.keys() 作为列标签</span></span><br><span class="line">data_frame = pd.DataFrame(saved_results, results.keys())</span><br><span class="line"><span class="comment"># 将 DataFrame 对象保存为 CSV 文件</span></span><br><span class="line"><span class="comment"># 文件路径由 out_path、&#x27;srf_&#x27;、UPSCALE_FACTOR 值和 &#x27;_test_results.csv&#x27; 组成</span></span><br><span class="line"><span class="comment"># index_label=&#x27;DataSet&#x27; 表示使用 &#x27;DataSet&#x27; 作为索引标签</span></span><br><span class="line">data_frame.to_csv(out_path + <span class="string">&#x27;srf_&#x27;</span> + <span class="built_in">str</span>(UPSCALE_FACTOR) + <span class="string">&#x27;_test_results.csv&#x27;</span>, index_label=<span class="string">&#x27;DataSet&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第三章-SRGAN&quot;&gt;&lt;a href=&quot;#超分辨率第三章-SRGAN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第三章-SRGAN&quot;&gt;&lt;/a&gt;超分辨率第三章-SRGAN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;SRGNN是2017年提出的模型，首次使用GAN在超分辨领域。&lt;/p&gt;
&lt;p&gt;参考文献：&lt;a href=&quot;https://arxiv.org/abs/1609.04802&quot;&gt;Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考博客：&lt;a href=&quot;https://blog.csdn.net/qq_47071847/article/details/130859675&quot;&gt;基于pytorch的SRGAN实现(全网最细!!!)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第二章-FSRCNN</title>
    <link href="http://example.com/2024/09/13/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%BA%8C%E7%AB%A0-FSRCNN/"/>
    <id>http://example.com/2024/09/13/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%BA%8C%E7%AB%A0-FSRCNN/</id>
    <published>2024-09-13T08:00:41.000Z</published>
    <updated>2024-09-14T09:50:15.351Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第二章-FSRCNN"><a href="#超分辨率第二章-FSRCNN" class="headerlink" title="超分辨率第二章-FSRCNN"></a>超分辨率第二章-FSRCNN</h1><blockquote><p>FSRCNN是2016年提出的超分辨率模型，使用后端上采样（转置卷积的方法），在一定程度上解决了SRCNN的问题。</p><p><a href="https://blog.csdn.net/zzy_pphz/article/details/108408933">参考博客</a></p><p><a href="https://arxiv.org/abs/1608.00367">论文地址</a></p><p>模型位置：F:\Github下载\FSRCNN-pytorch-master</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><ul><li><p>FSRCNN改进了SRCNN在速度上存在的缺陷</p><ul><li><p>SRCNN在将低分辨率图像送进网络之前，<strong>会先使用双三次插值法进行插值上采样操作</strong>，产生与groundtruth大小一致的低分辨率图像，这样会增加了计算复杂度，<strong>因为插值后的图像相比原始的低分辨率图像更大，于是在输入网络后各个卷积层的计算代价会增大，从而限制了网络的整体速度</strong>。</p></li><li><p><strong>SRCNN非线性映射层的计算代价太高，参数过多(高维度下的映射)。</strong></p></li></ul></li><li><p>FSRCNN在SRCNN基础上做了如下改变：</p><ul><li><p><strong>FSRCNN直接采用低分辨的图像作为输入，不同于SRCNN需要先对低分辨率的图像进行双三次插值然后作为输入，FSRCNN在网络的最后采用反卷积层实现上采样，小尺寸的图像在映射学习阶段可以有效地提升运算速度</strong></p></li><li><p><strong>FSRCNN中没有非线性映射，相应地出现了收缩层、映射（多个卷积核为3*3的层）和扩展层，在低维空间中进行映射学习可以有效地提升运算速度</strong></p></li><li><p><strong>FSRCNN选择更小尺寸的滤波器和更深的网络结构。</strong></p></li><li><p><strong>所有卷积层（反卷积层除外）都可以由不同放大因子的网络共享，能够在保持恢复质量（即图像超分辨率重建后的质量）不降低的前提下，通过迁移（或共享）其卷积层来快速地对不同放大因子（upscaling factors）的图像进行训练和测试。</strong></p><p>具体来说，我们可以从以下几个方面来理解这句话：</p><ol><li><strong>卷积层的迁移</strong>：在深度学习中，迁移学习是一种常见的技术，它允许将一个已经训练好的模型的部分（如网络层）用于另一个相关的任务中，以减少训练时间和提高模型性能。<strong>FSRCNN利用这一思想，将网络中用于特征提取的卷积层设计为与放大因子无关。这意味着，无论是将图像放大2倍、3倍还是4倍，这些卷积层都可以保持不变，而不需要为每个放大因子重新训练。</strong></li><li><strong>快速训练和测试</strong>：由于卷积层可以跨不同的放大因子进行迁移，因此FSRCNN在训练和测试时可以节省大量时间。对于一个新的放大因子，我们只需要重新训练或调整网络的反卷积层，该层直接负责根据给定的放大因子来重建图像。这种方式大大减少了训练成本，并加快了测试速度。</li><li><strong>无损失的恢复质量</strong>：尽管FSRCNN通过迁移卷积层来简化训练和测试过程，但它并没有牺牲图像超分辨率重建的质量。这得益于其网络架构的精心设计，特别是反卷积层能够根据目标放大因子有效地重建图像细节。因此，无论是在哪个放大因子下，FSRCNN都能提供高质量的图像恢复结果。</li></ol></li></ul></li><li><p>对比</p><ul><li><p>SRCNN结构（飞镖型维度变化：小-大-小，前端上采样）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SRCNN</span>(nn.Module): <span class="comment">#输入的图像是经过双三次插值后上采样放大尺寸的低分辨率图像</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SRCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(num_channels, <span class="number">64</span>, kernel_size=<span class="number">9</span>, padding=<span class="number">9</span> // <span class="number">2</span>) <span class="comment">#特征提取层</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span> // <span class="number">2</span>) <span class="comment">#映射层</span></span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(<span class="number">32</span>, num_channels, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span> // <span class="number">2</span>) <span class="comment">#重建层</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></li><li><p>FSRCNN结构（沙漏型维度变化：大-小-大，后端上采样）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, scale_factor, num_channels=<span class="number">1</span>, d=<span class="number">56</span>, s=<span class="number">12</span>, m=<span class="number">4</span></span>):</span><br><span class="line">       <span class="built_in">super</span>(FSRCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">       <span class="variable language_">self</span>.first_part = nn.Sequential(</span><br><span class="line">           nn.Conv2d(num_channels, d, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span>//<span class="number">2</span>),</span><br><span class="line">           nn.PReLU(d)</span><br><span class="line">       )</span><br><span class="line">       <span class="variable language_">self</span>.mid_part = [nn.Conv2d(d, s, kernel_size=<span class="number">1</span>), nn.PReLU(s)]</span><br><span class="line">       <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">           <span class="variable language_">self</span>.mid_part.extend([nn.Conv2d(s, s, kernel_size=<span class="number">3</span>, padding=<span class="number">3</span>//<span class="number">2</span>), nn.PReLU(s)])<span class="comment">#进行m次s个通道到s个通道的映射</span></span><br><span class="line">       <span class="variable language_">self</span>.mid_part.extend([nn.Conv2d(s, d, kernel_size=<span class="number">1</span>), nn.PReLU(d)])</span><br><span class="line">       <span class="variable language_">self</span>.mid_part = nn.Sequential(*<span class="variable language_">self</span>.mid_part)<span class="comment">#把中间层的卷积都封装起来</span></span><br><span class="line">       <span class="variable language_">self</span>.last_part = nn.ConvTranspose2d(d, num_channels, kernel_size=<span class="number">9</span>, stride=scale_factor, padding=<span class="number">9</span>//<span class="number">2</span>,</span><br><span class="line">                                           output_padding=scale_factor-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">       <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line">    </span><br></pre></td></tr></table></figure></li><li><p>图片:conv(卷积核大小，输出维度，输入维度)</p><ul><li><img src="https://s21.ax1x.com/2024/09/06/pAZz6IA.png" alt="pAZz6IA.png"></li></ul></li></ul></li></ul><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><p><strong>以img-91作为训练集，Set5作为测试集。</strong></p><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FSRCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, scale_factor, num_channels=<span class="number">1</span>, d=<span class="number">56</span>, s=<span class="number">12</span>, m=<span class="number">4</span></span>): <span class="comment">#缩放因子，输入维度，模型各个部分的超参数</span></span><br><span class="line">        <span class="built_in">super</span>(FSRCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment">#模型的第一部分：特征提取层</span></span><br><span class="line">        <span class="variable language_">self</span>.first_part = nn.Sequential(</span><br><span class="line">            nn.Conv2d(num_channels, d, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span>//<span class="number">2</span>),</span><br><span class="line">            nn.PReLU(d)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#模型的第二部分：</span></span><br><span class="line">        <span class="variable language_">self</span>.mid_part = [nn.Conv2d(d, s, kernel_size=<span class="number">1</span>), nn.PReLU(s)] <span class="comment">#收缩层，缩小维度</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m):<span class="comment">#执行4次，卷积核大小为3*3的非线性映射层</span></span><br><span class="line">            <span class="variable language_">self</span>.mid_part.extend([nn.Conv2d(s, s, kernel_size=<span class="number">3</span>, padding=<span class="number">3</span>//<span class="number">2</span>), nn.PReLU(s)])</span><br><span class="line">        <span class="variable language_">self</span>.mid_part.extend([nn.Conv2d(s, d, kernel_size=<span class="number">1</span>), nn.PReLU(d)]) <span class="comment">#扩充层，恢复到原来的维度</span></span><br><span class="line">        <span class="variable language_">self</span>.mid_part = nn.Sequential(*<span class="variable language_">self</span>.mid_part) <span class="comment">#通过nn.Sequential(*self.mid_part)转换为一个Sequential模块</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#模型的第三部分：转置卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.last_part = nn.ConvTranspose2d(d, num_channels, kernel_size=<span class="number">9</span>, stride=scale_factor, padding=<span class="number">9</span>//<span class="number">2</span>,</span><br><span class="line">                                            output_padding=scale_factor-<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#在输出特征图的边缘额外添加的零填充的层数。这个参数在转置卷积中非常重要，因为它允许我们更精确地控制输出特征图的大小。</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>): <span class="comment">#权重初始化</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.first_part:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, mean=<span class="number">0.0</span>, std=math.sqrt(<span class="number">2</span>/(m.out_channels*m.weight.data[<span class="number">0</span>][<span class="number">0</span>].numel())))</span><br><span class="line">                nn.init.zeros_(m.bias.data)</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.mid_part:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, mean=<span class="number">0.0</span>, std=math.sqrt(<span class="number">2</span>/(m.out_channels*m.weight.data[<span class="number">0</span>][<span class="number">0</span>].numel())))</span><br><span class="line">                nn.init.zeros_(m.bias.data)</span><br><span class="line">        nn.init.normal_(<span class="variable language_">self</span>.last_part.weight.data, mean=<span class="number">0.0</span>, std=<span class="number">0.001</span>)</span><br><span class="line">        nn.init.zeros_(<span class="variable language_">self</span>.last_part.bias.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.first_part(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.mid_part(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.last_part(x)</span><br><span class="line">        <span class="keyword">return</span> x*</span><br></pre></td></tr></table></figure><h2 id="四-模型训练"><a href="#四-模型训练" class="headerlink" title="四.模型训练"></a>四.模型训练</h2><ul><li><p>代码与上一章内容相同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --train-file=data_set/train_set/<span class="number">91</span>-image_x3.h5 --<span class="built_in">eval</span>-file=data_set/eval_set/Set5_x3.h5 --outputs-<span class="built_in">dir</span>=outputs <span class="comment">#运行命令</span></span><br></pre></td></tr></table></figure></li></ul><p>结果：<img src="https://s21.ax1x.com/2024/09/14/pAuVdT1.png" alt="pAuVdT1.png"></p><h2 id="五-模型测试"><a href="#五-模型测试" class="headerlink" title="五.模型测试"></a>五.模型测试</h2><blockquote><p>这里将低分辨率进行超分处理后的预测Y通道与双三次插值后图像的 Cb、Cr通道的结合的意义：</p><p>YCbCr色彩空间中的Y代表亮度信息，而Cb和Cr代表色度信息（蓝色和红色的色度差）。RGB色彩空间则直接由红（R）、绿（G）、蓝（B）三个颜色通道组成。</p><p>在图像处理中，由于人眼对亮度的敏感度高于对色度的敏感度，因此很多图像处理算法会选择在YCbCr色彩空间中进行处理，尤其是在超分辨率等任务中，可以独立地对亮度（Y通道）和色度（Cb、Cr通道）进行处理，以达到更好的视觉效果和计算效率。</p><p>在超分辨率任务中，由于亮度信息（Y通道）包含了图像的主要结构信息，因此通常会通过深度学习等算法对低分辨率图像的Y通道进行预测，以获得高分辨率的Y通道。而色度信息（Cb、Cr通道）则相对简单，可以通过传统的插值方法（如双三次插值）从低分辨率图像中直接获得高分辨率的版本。</p><p>将预测的Y通道与bicubic插值得到的Cb、Cr通道结合，实际上是在保持色度信息不变的同时，仅对亮度信息进行增强或修正。这样做的好处是可以在保持图像颜色自然性的同时，显著提高图像的清晰度和细节表现。</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model = FSRCNN(scale_factor=args.scale).to(device)</span><br><span class="line"></span><br><span class="line">state_dict = model.state_dict()</span><br><span class="line"><span class="comment">#加载模型权重文件</span></span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(args.weights_file, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():</span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():</span><br><span class="line">        state_dict[n].copy_(p)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> KeyError(n)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># 计算调整后的图像尺寸，确保它是缩放因子的整数倍</span></span><br><span class="line">image = pil_image.<span class="built_in">open</span>(args.image_file).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">image_width = (image.width // args.scale) * args.scale</span><br><span class="line">image_height = (image.height // args.scale) * args.scale</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成高分辨率（HR）、低分辨率（LR）和双三次插值放大后的图像（bicubic）  </span></span><br><span class="line">hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)</span><br><span class="line">lr = hr.resize((hr.width // args.scale, hr.height // args.scale), resample=pil_image.BICUBIC) <span class="comment">#下采样降低分辨率</span></span><br><span class="line">bicubic = lr.resize((lr.width * args.scale, lr.height * args.scale), resample=pil_image.BICUBIC) <span class="comment">#双三次插值增大分辨率</span></span><br><span class="line">bicubic.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_bicubic_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#将RGB图像转换为YCbCr色彩空间，并返回处理后的Y通道和原始的YCbCr图像，高分辨率和低分辨率图像接受Y通道，而双三次插值图像接受色度通道（（Cb、Cr通道）</span></span><br><span class="line">lr, _ = preprocess(lr, device)</span><br><span class="line">hr, _ = preprocess(hr, device)</span><br><span class="line">_, ycbcr = preprocess(bicubic, device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    preds = model(lr).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>) <span class="comment">#此处只需输入原始低分辨率图像，不需要输入双三次插值后的图像，此时进行将超分处理。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算峰值信噪比</span></span><br><span class="line">psnr = calc_psnr(hr, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;PSNR: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(psnr))</span><br><span class="line"></span><br><span class="line">preds = preds.mul(<span class="number">255.0</span>).cpu().numpy().squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)<span class="comment">#将模型预测结果缩放到0-255范围，并转换为NumPy数组，去除不必要的维度。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将预测的Y通道与bicubic图像的Cb和Cr通道结合，之后转换为RGB格式，裁剪到0-255范围，转换为PIL图像，并保存。</span></span><br><span class="line">output = np.array([preds, ycbcr[..., <span class="number">1</span>], ycbcr[..., <span class="number">2</span>]]).transpose([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">output = np.clip(convert_ycbcr_to_rgb(output), <span class="number">0.0</span>, <span class="number">255.0</span>).astype(np.uint8)</span><br><span class="line">output = pil_image.fromarray(output)</span><br><span class="line">output.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_fsrcnn_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#python test.py --weights-file=outputs/x3/best.pth --image-file=data/car.bmp</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第二章-FSRCNN&quot;&gt;&lt;a href=&quot;#超分辨率第二章-FSRCNN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第二章-FSRCNN&quot;&gt;&lt;/a&gt;超分辨率第二章-FSRCNN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;FSRCNN是2016年提出的超分辨率模型，使用后端上采样（转置卷积的方法），在一定程度上解决了SRCNN的问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/zzy_pphz/article/details/108408933&quot;&gt;参考博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1608.00367&quot;&gt;论文地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;模型位置：F:&#92;Github下载&#92;FSRCNN-pytorch-master&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>基于参考图像的超分辨率-综述</title>
    <link href="http://example.com/2024/09/09/%E5%9F%BA%E4%BA%8E%E5%8F%82%E8%80%83%E5%9B%BE%E5%83%8F%E7%9A%84%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E7%BB%BC%E8%BF%B0/"/>
    <id>http://example.com/2024/09/09/%E5%9F%BA%E4%BA%8E%E5%8F%82%E8%80%83%E5%9B%BE%E5%83%8F%E7%9A%84%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E7%BB%BC%E8%BF%B0/</id>
    <published>2024-09-09T08:05:20.000Z</published>
    <updated>2024-09-09T13:22:21.184Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于参考图像的超分辨率-综述"><a href="#基于参考图像的超分辨率-综述" class="headerlink" title="基于参考图像的超分辨率-综述"></a>基于参考图像的超分辨率-综述</h1><blockquote><p>参考文献：<a href="https://kns.cnki.net/kcms2/article/abstract?v=-4s28oSk478lMupsZHFTRSDE7aArCjQPFtapPdcSezJKaonTlxOG4MtmhRxxWeFwj3rVlAtCBbYqf-RpkIRuaI4yEOkQLZVycoNwfeD0FW1fE8xfDpyBhZyfF1CqRgwDJ0BcE_ZKE9JZw7tiLkd2LRrG5V93dZAhGDzOTeIfu9sLZLlxk2cQW3fgHfb83_NtXHT9F7iUTpH7FAhPxZowhKalw5i1BSKcAGX5dXZTpjBFE2-AYcZvxBqb_q-t7-uXP2mxU5s4TJvdkWCzxBTTPt2ziqoXmFwMWiRiNA9bTsmm9P2Mma7B5Gd50JmDLFPaPuSmU7uRDH0=&amp;uniplatform=NZKPT&amp;language=CHS">基于参考图像的超分辨率重建算法综述</a></p></blockquote><span id="more"></span><h2 id="一-RefSR介绍"><a href="#一-RefSR介绍" class="headerlink" title="一.RefSR介绍"></a>一.RefSR介绍</h2><ul><li><p>将已有的高分辨率图像作为参考， 利用<strong>参考图</strong>中丰富的纹理来补偿低分辨率图像缺失的细节信息， 从而缓解单帧图像超分辨重建的不适定性</p></li><li><p>基于参考图的超分辨率重建， 与普通的单帧重建不同， 除输入低分辨率图像外， <strong>还需额外输入一张或多张与低分辨率图像内容或纹理相似的高分辨率参考图像</strong></p></li></ul><h2 id="二-RefSR的主要方法"><a href="#二-RefSR的主要方法" class="headerlink" title="二.RefSR的主要方法"></a>二.RefSR的主要方法</h2><ul><li><p>依据Ref图像与LR图像的对应方式， 可以将RefSR分为两大类： 基于图像对齐的方法和基于图像块匹配的方法</p></li><li><p>基于图像对齐的RefSR方法是利用光流、 可变形卷积等模型将输入的LR图像与Ref图像进行全局配准， 再将对齐后的Ref图像的纹理用于LR图像重建， 其代表模型有SSEN、Cross-Net</p></li><li>而基于图像块匹配的RfSR方法则是将输入图像分割为若干个块，对每个块进行相似度匹配，再利用匹配后的LR/Rf图像进行重建。该方法代表模型有SRNTT、TTSR、MASA等。</li><li><img src="https://s21.ax1x.com/2024/09/09/pAmETsA.png" alt="pAmETsA.png"></li></ul><h3 id="1-基于图像对齐的方法"><a href="#1-基于图像对齐的方法" class="headerlink" title="1.基于图像对齐的方法"></a>1.基于图像对齐的方法</h3><ul><li><img src="https://s21.ax1x.com/2024/09/09/pAmAfjs.png" alt="pAmAfjs.png"></li></ul><h4 id="①CrossNet（跨尺度端到端的网络）"><a href="#①CrossNet（跨尺度端到端的网络）" class="headerlink" title="①CrossNet（跨尺度端到端的网络）"></a>①CrossNet（跨尺度端到端的网络）</h4><ul><li><p>其中图像对齐使用了<strong>光流法</strong>。</p><ul><li>光流：光流的概念是指在连续的两帧图像中由于图像中的物体移动或者摄像头的移动导致的图像中目标像素的移动</li></ul></li><li><p>该网络利用SISR方法对LR图像进行上采样，得到与Ref图像相同大小的上采样图，再分别提取出上采样图和Rf图像的多尺度特征。</p></li><li><p><strong>然后，利用改进的FlowNetS模型学习不同尺度LR/Ref图像特征的光流信息来更新Ref图像，从而实现图像对齐操作</strong>。</p><ul><li><blockquote><ul><li>数据预处理<ul><li>准备LR（低分辨率）图像和Ref（参考或高分辨率）图像对。这些图像对可能是从不同来源或在不同条件下获取的，因此它们之间可能存在位移、旋转、缩放等差异。</li><li>可能需要将图像对缩放到不同的尺度，以便在多个尺度上分析光流信息。这有助于捕捉不同尺度的运动模式，从而提高光流估计的准确性。</li></ul></li><li>改进的FlowNetS模型<ul><li>FlowNetS是一个基于卷积神经网络（CNN）的光流估计模型，<strong>它接受一对图像作为输入，并输出一个与输入图像相同大小的光流场。光流场中的每个像素值表示该像素在另一张图像中的对应位置偏移。</strong></li><li>为了适应特定的任务需求，FlowNetS模型可能经过了改进，比如增加了更多的卷积层、使用了更高效的特征提取器、或者修改了损失函数等。</li></ul></li><li>光流信息学习<ul><li>将LR和Ref图像对输入到改进的FlowNetS模型中。</li><li>模型会分析图像对之间的特征差异，并学习如何将这些差异转化为光流信息。在多个尺度上进行这个操作可以捕获更丰富的运动模式。</li></ul></li><li>Ref图像更新<ul><li><strong>利用学习到的光流信息，可以对Ref图像进行变换，以使其与LR图像在视觉上对齐。这通常涉及到对Ref图像中的每个像素位置进行偏移，偏移量由光流场中的相应像素值给出。</strong></li><li>由于光流信息可能包含噪声或估计误差，因此在执行更新之前，可能需要对光流场进行平滑处理或滤波操作。</li></ul></li><li>图像对齐操作<ul><li>经过Ref图像的更新后，LR和Ref图像在视觉上变得更加对齐。这种对齐可以用于多种应用场景，比如图像超分辨率、视频帧插值、图像融合等。</li><li>需要注意的是，由于光流估计的局限性（如遮挡、大位移、快速运动等），在某些情况下，图像对齐可能无法达到完美的效果。</li></ul></li></ul></blockquote></li></ul></li><li><p>最后，通过融合操作重建出HR图像。该方法假设两幅图像具有较强的相似性，所以当LR/Rf图像相关性不强时，效果会有下降。</p></li></ul><h4 id="②SSEN"><a href="#②SSEN" class="headerlink" title="②SSEN"></a>②SSEN</h4><ul><li><strong>SSEN利用可变形卷积来寻找LR/Rf图像的对应关系，且用动态偏移估计器对可变形卷积的偏移量进行估计。</strong><ul><li>首先，通过特征提取网络（如卷积神经网络）从LR和Ref图像中提取特征图。</li><li>然后，将特征图输入到动态偏移估计器中，计算得到每个卷积核采样点的偏移量。</li><li>最后，使用这些偏移量来指导可变形卷积操作，从而生成新的特征图或超分辨率图像</li></ul></li><li>同时，为了捕获特征内部和特征之间的全局相关性，在动态偏移估计器中加入了非局部块。该方法能够处理非刚性变换的图像，计算量较小，但是无法解决长距离对应问题。</li></ul><h3 id="2-基于图像块匹配的方法"><a href="#2-基于图像块匹配的方法" class="headerlink" title="2.基于图像块匹配的方法"></a>2.基于图像块匹配的方法</h3><p><img src="https://s21.ax1x.com/2024/09/09/pAmENV0.png" alt="pAmENV0.png"></p><ul><li>图像块匹配：Rf图像下采样后，计算其一阶、二阶梯度，利用欧式距离在梯度特征图中寻找与LR图像最相邻的9个块，然后加权平均得到融合结果。</li></ul><h4 id="①CC-Net-SS-Net"><a href="#①CC-Net-SS-Net" class="headerlink" title="①CC-Net+SS-Net"></a>①CC-Net+SS-Net</h4><ul><li>使用CC-Net(cross-scale correspondence network)模块，通过卷积神经网络提取LR/Rf图像特征，利用内积计算相似度，选择相似度最高的图像块作为匹配<br>对</li><li>然后，将匹配好的图像块送入到SS-Net(super-resolution synthesis network)模块进行多尺度融合，最后得到SR图像。</li></ul><h4 id="②SRNTT（super-resolution-by-neural-texture-transfer）"><a href="#②SRNTT（super-resolution-by-neural-texture-transfer）" class="headerlink" title="②SRNTT（super-resolution by neural texture transfer）"></a>②SRNTT（super-resolution by neural texture transfer）</h4><ul><li>首先， 对提取的图像特征进行密集块匹配， 然后将匹配后的Ref图像进行纹理迁移， 从而使得重建的SR图像拥有丰富的纹理信息。 </li></ul><h4 id="③TTSR（texture-transformer-network-for-image-su-per-resolution）"><a href="#③TTSR（texture-transformer-network-for-image-su-per-resolution）" class="headerlink" title="③TTSR（texture transformer network for image su-per-resolution）"></a>③TTSR（texture transformer network for image su-per-resolution）</h4><ul><li>该网络通过使用注意力机制挖掘深层次的特征对应关系，再将匹配好的特征送入跨尺度融合模块，最后得到SR图像。</li></ul><h4 id="④MASA"><a href="#④MASA" class="headerlink" title="④MASA"></a>④MASA</h4><ul><li>首先对LR/Rf图像进行一个大尺度的图像块匹配，再利用图像的局部相似性，对大尺度图形块分块进行小尺度匹配。</li></ul><h4 id="⑤AMSA"><a href="#⑤AMSA" class="headerlink" title="⑤AMSA"></a>⑤AMSA</h4><ul><li>针对小规模的不对齐问题，提出了动态融合模块；针对大尺度不对齐问题，提出了多规模融合模块。这两个融合模块相互配合，产生了很好的融合效果。</li></ul><h4 id="⑥-C-2-Matching"><a href="#⑥-C-2-Matching" class="headerlink" title="⑥$C^2$-Matching"></a>⑥$C^2$-Matching</h4><ul><li>cross transformation and cross resolution matching技术，用于跨变换和跨分辨率的关系匹配。</li><li>对于变换差距，利用对比网络拉近匹配对之间的距离，疏远不匹配对之间的距离</li><li>对于分辨率差距，提出教师学生关系蒸馏网络，与传统的知识蒸馏网络不同，此网络用HR-HR匹配来指导相对困难的LR-HR匹配。然后，通过设计的动态融合模块来解决潜在的错位问题。</li><li>该技术在目前常用的数据集中，都显现出了极强的泛化能力，以及对大尺度和旋转变换的鲁棒性。</li></ul><h2 id="三-损失函数"><a href="#三-损失函数" class="headerlink" title="三.损失函数"></a>三.损失函数</h2><h3 id="1-重建损失"><a href="#1-重建损失" class="headerlink" title="1.重建损失"></a>1.重建损失</h3><ul><li>可分为L1,L2损失</li><li><script type="math/tex; mode=display">L _ { r e c - l 1 } ( I ^ { S R } , I ) = \frac { 1 } { h w c } \sum _ { i , j , k } | I _ { i , j , k } ^ { s R } - I _ { i , j , k } | ,</script></li><li><script type="math/tex; mode=display">L _ { r e c - l2 } ( I ^ { S R } , I ) = \frac { 1 } { h w c } \sum _ { i , j , k } ( I _ { i , j , k } ^ { s R } - I _ { i , j , k } ) ^ { 2 } 。</script></li><li>h，w和c分别表示图像的长、宽和通道数；ISR表示生成的HR图像；I表示真实图像。</li></ul><h3 id="2-感知损失"><a href="#2-感知损失" class="headerlink" title="2.感知损失"></a>2.感知损失</h3><ul><li><script type="math/tex; mode=display">L _ { p e r } = | | \varphi _ { i } ( I ^ { S R } ) - \varphi _ { i } ( I ) | | _ { 2 } 。</script></li></ul><h3 id="3-对抗损失"><a href="#3-对抗损失" class="headerlink" title="3.对抗损失"></a>3.对抗损失</h3><ul><li><script type="math/tex; mode=display">L _ { g a n - c e - g } = - \lg D ( I ^ { S R } ) ,</script></li></ul><h3 id="4-纹理损失"><a href="#4-纹理损失" class="headerlink" title="4.纹理损失"></a>4.纹理损失</h3><ul><li><script type="math/tex; mode=display">L _ { t e x } = \sum _ { l } \lambda _ { l } | | G _ { r } ( \varphi _ { l } ( I ^ { S R } ) \odot S _ { l } ^ { * } ) - G _ { r } ( \varphi _ { l } ( I ^ { R e f } ) \odot S _ { l } ^ { * } ) | _ { F } 。</script></li></ul><h2 id="四-总结"><a href="#四-总结" class="headerlink" title="四.总结"></a>四.总结</h2><ul><li><img src="https://s21.ax1x.com/2024/09/09/pAmn5DJ.png" alt="pAmn5DJ.png"></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;基于参考图像的超分辨率-综述&quot;&gt;&lt;a href=&quot;#基于参考图像的超分辨率-综述&quot; class=&quot;headerlink&quot; title=&quot;基于参考图像的超分辨率-综述&quot;&gt;&lt;/a&gt;基于参考图像的超分辨率-综述&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考文献：&lt;a href=&quot;https://kns.cnki.net/kcms2/article/abstract?v=-4s28oSk478lMupsZHFTRSDE7aArCjQPFtapPdcSezJKaonTlxOG4MtmhRxxWeFwj3rVlAtCBbYqf-RpkIRuaI4yEOkQLZVycoNwfeD0FW1fE8xfDpyBhZyfF1CqRgwDJ0BcE_ZKE9JZw7tiLkd2LRrG5V93dZAhGDzOTeIfu9sLZLlxk2cQW3fgHfb83_NtXHT9F7iUTpH7FAhPxZowhKalw5i1BSKcAGX5dXZTpjBFE2-AYcZvxBqb_q-t7-uXP2mxU5s4TJvdkWCzxBTTPt2ziqoXmFwMWiRiNA9bTsmm9P2Mma7B5Gd50JmDLFPaPuSmU7uRDH0=&amp;amp;uniplatform=NZKPT&amp;amp;language=CHS&quot;&gt;基于参考图像的超分辨率重建算法综述&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="学术论文总结" scheme="http://example.com/categories/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率第一章-SRCNN</title>
    <link href="http://example.com/2024/09/08/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%80%E7%AB%A0-SRCNN/"/>
    <id>http://example.com/2024/09/08/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%AC%AC%E4%B8%80%E7%AB%A0-SRCNN/</id>
    <published>2024-09-08T08:58:27.000Z</published>
    <updated>2024-09-20T13:04:53.071Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率第一章-SRCNN"><a href="#超分辨率第一章-SRCNN" class="headerlink" title="超分辨率第一章-SRCNN"></a>超分辨率第一章-SRCNN</h1><blockquote><p>第一个超分辨率模型-SRCNN （SISR），2014年提出</p><p>参考网址：<a href="https://blog.csdn.net/zhanjuex/article/details/124344864?spm=1001.2014.3001.5506">【超分辨率】【深度学习】SRCNN pytorch代码（附详细注释和数据集）_srcnn代码-CSDN博客</a></p><p><a href="https://blog.csdn.net/weixin_52261094/article/details/128389448">SRCNN超分辨率Pytorch实现，代码逐行讲解，附源码</a></p><p>模型位置：F:\Github下载\SRCNN_Pytorch_1.0-master</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运行程序</span></span><br><span class="line">python train.py --train-file=data_set/train_set/<span class="number">91</span>-image_x3.h5 --<span class="built_in">eval</span>-file=data_set/eval_set/Set5_x3.h5 --outputs-<span class="built_in">dir</span>=outputs</span><br></pre></td></tr></table></figure><p><strong>SRCNN（2014年Dong等人提出，前端上采样框架 ）</strong></p><ul><li>先将图片下采样预处理得到低分辨率图像 </li><li>再利用双三次插值法将图片放大到目标分辨率（基于插值的上采样方法）</li><li>再用卷积核大小分别为 9×9、1×1、5×5的三个卷积层，分别进行特征提取，拟合 LR-HR 图像对之间的非线性映射以及将网络模型的输出结果进行重建，得到最后的高分辨率图像</li><li>图示：<img src="https://s21.ax1x.com/2024/09/06/pAZzAbQ.png" alt="pAZzAbQ.png"></li></ul><h2 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h2><p><strong>以img-91作为训练集，Set5作为测试集。</strong></p><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SRCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SRCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(num_channels, <span class="number">64</span>, kernel_size=<span class="number">9</span>, padding=<span class="number">9</span> // <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span> // <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(<span class="number">32</span>, num_channels, kernel_size=<span class="number">5</span>, padding=<span class="number">5</span> // <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="四-模型训练"><a href="#四-模型训练" class="headerlink" title="四.模型训练"></a>四.模型训练</h2><h3 id="1-调用库"><a href="#1-调用库" class="headerlink" title="1.调用库"></a>1.调用库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse <span class="comment">#argparse用于编写用户友好的命令行接口。程序通过定义它期望从命令行接收的参数，然后 argparse 会自动从 sys.argv 解析出那些参数。这允许你的程序更加灵活和可配置</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment">#cudnn 是 NVIDIA 提供的深度神经网络加速库（cuDNN）的 PyTorch 接口。它可以提高深度学习模型的计算速度和效率，特别是在使用 NVIDIA GPU 时。</span></span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataloader <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="comment">#进度条</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> SRCNN</span><br><span class="line"><span class="comment">#从 datasets 模块中导入了 TrainDataset 和 EvalDataset 两个类。这两个类很可能分别用于加载训练数据集和评估数据集。</span></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> TrainDataset, EvalDataset</span><br><span class="line"><span class="comment"># utils 模块中导入了 AverageMeter 和 calc_psnr 两个工具或函数。AverageMeter 可能是一个用于计算平均值的工具类，而 calc_psnr 函数则用于计算峰值信噪比（Peak Signal-to-Noise Ratio），这是一种常用的图像质量评估指标。</span></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> AverageMeter, calc_psnr</span><br></pre></td></tr></table></figure><h3 id="2-命令行参数设定"><a href="#2-命令行参数设定" class="headerlink" title="2.命令行参数设定"></a>2.命令行参数设定</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始参数设定，argparse是Python标准库中的一个模块，用于编写用户友好的命令行接口。程序定义了它期望从命令行接收的参数，然后argparse会自动从sys.argv解析出那些参数。</span></span><br><span class="line">parser = argparse.ArgumentParser() <span class="comment">#parser = argparse.ArgumentParser() 创建了一个ArgumentParser对象。这个对象将包含将命令行解析成Python数据类型所需的全部信息。</span></span><br><span class="line"><span class="comment">#通过调用parser.add_argument()方法，可以向解析器添加命令行参数。每个add_argument()调用都指定了一个命令行选项（如--train-file），并可能包含一些额外的参数（如type=str，required=True等），这些参数定义了命令行选项应该如何被解析。</span></span><br><span class="line"><span class="comment">#--train-file, --eval-file, --outputs-dir：这些参数被标记为required=True，意味着它们在命令行中必须被提供。其他参数有默认值。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--eval-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--outputs-dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">3</span>) <span class="comment">#图片上采样放大尺寸倍数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-4</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num-workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num-epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">123</span>)</span><br><span class="line">args = parser.parse_args() <span class="comment">#解析命令行参数，并将结果存储在名为args的命名空间中。之后，你可以通过args.参数名的方式来访问这些参数的值。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存输出到相应目录下</span></span><br><span class="line">args.outputs_dir = os.path.join(args.outputs_dir, <span class="string">&#x27;x&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.scale))</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.outputs_dir):</span><br><span class="line">    os.makedirs(args.outputs_dir)</span><br></pre></td></tr></table></figure><h3 id="3-加载数据集并进行预处理"><a href="#3-加载数据集并进行预处理" class="headerlink" title="3.加载数据集并进行预处理"></a>3.加载数据集并进行预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#预处理训练集</span></span><br><span class="line">train_dataset = TrainDataset(args.train_file)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">            dataset=train_dataset,</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            shuffle=<span class="literal">True</span>,</span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">            pin_memory=<span class="literal">True</span>,</span><br><span class="line">            drop_last=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#预处理验证集</span></span><br><span class="line">eval_dataset = EvalDataset(args.eval_file)</span><br><span class="line">eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="4-设置训练参数"><a href="#4-设置训练参数" class="headerlink" title="4.设置训练参数"></a>4.设置训练参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cudnn.benchmark = <span class="literal">True</span> <span class="comment">#开启cudnn的benchmark模式，用于加速计算。但请注意，这可能会导致每次运行程序时，前馈计算的结果有细微差异，因为cudnn会寻找最优的卷积算法。</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">torch.manual_seed(args.seed) <span class="comment">#随机数种子</span></span><br><span class="line">model = SRCNN().to(device)</span><br><span class="line">criterion = nn.MSELoss() <span class="comment">#代价函数MSE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义优化器为Adam，并为模型的不同部分设置不同的学习率。这里，conv3层的学习率是conv1和conv2层学习率的十分之一。</span></span><br><span class="line">optimizer = optim.Adam([</span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>: model.conv1.parameters()&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>: model.conv2.parameters()&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>: model.conv3.parameters(), <span class="string">&#x27;lr&#x27;</span>: args.lr*<span class="number">0.1</span>&#125;</span><br><span class="line">], lr=args.lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练开始前，复制当前模型的最佳权重（这里初始化为当前模型的权重）。这些权重将在验证过程中根据性能进行更新。  </span></span><br><span class="line">best_weights = copy.deepcopy(model.state_dict())</span><br><span class="line">best_epoch = <span class="number">0</span></span><br><span class="line">best_psnr = <span class="number">0.0</span></span><br></pre></td></tr></table></figure><h3 id="5-模型训练与验证"><a href="#5-模型训练与验证" class="headerlink" title="5.模型训练与验证"></a>5.模型训练与验证</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.num_epochs):</span><br><span class="line">    <span class="comment">#训练模式</span></span><br><span class="line">    model.train()</span><br><span class="line">    epoch_losses = AverageMeter() <span class="comment">#初始化一个AverageMeter对象来跟踪当前epoch的损失平均值</span></span><br><span class="line">    <span class="comment">#创建一个进度条，并设置进度条描述（当前轮/总批次）</span></span><br><span class="line">    <span class="keyword">with</span> tqdm(total=(<span class="built_in">len</span>(train_dataset) - <span class="built_in">len</span>(train_dataset) % args.batch_size)) <span class="keyword">as</span> t:</span><br><span class="line">        t.set_description(<span class="string">&#x27;epoch:&#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, args.num_epochs))</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">            inputs, labels = data</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            preds = model(inputs)</span><br><span class="line">            loss = criterion(preds, labels)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            epoch_losses.update(loss.item(), <span class="built_in">len</span>(inputs)) <span class="comment">#更新当前的平均损失，并在进度条上显示</span></span><br><span class="line">            t.set_postfix(loss=<span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch_losses.avg))</span><br><span class="line">            t.update(<span class="built_in">len</span>(inputs))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#验证模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    epoch_psnr = AverageMeter() <span class="comment">#初始化一个AverageMeter对象来跟踪当前epoch的psnr平均值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            preds = model(inputs).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>) <span class="comment">#对预测值进行裁剪</span></span><br><span class="line">        epoch_psnr.update(calc_psnr(preds, labels), <span class="built_in">len</span>(inputs)) <span class="comment">#计算PSNR值并更新当前epoch的PSNR平均值。calc_psnr函数用于计算预测值和真实值之间的PSNR。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;eval psnr: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch_psnr.avg))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存最优epoch的权重文件</span></span><br><span class="line">    <span class="keyword">if</span> epoch_psnr.avg &gt; best_psnr:</span><br><span class="line">        best_epoch = epoch</span><br><span class="line">        best_psnr = epoch_psnr.avg</span><br><span class="line">        best_weights = copy.deepcopy(model.state_dict())</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best epoch: &#123;&#125;, psnr: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(best_epoch, best_psnr))</span><br><span class="line">torch.save(best_weights, os.path.join(args.outputs_dir, <span class="string">&#x27;best.pth&#x27;</span>))</span><br></pre></td></tr></table></figure><h2 id="五-模型测试"><a href="#五-模型测试" class="headerlink" title="五.模型测试"></a>五.模型测试</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运行程序</span></span><br><span class="line">python test.py --weights-file=outputs/x3/best.pth --image-file=data/car.bmp</span><br></pre></td></tr></table></figure><h3 id="1-命令行参数设定"><a href="#1-命令行参数设定" class="headerlink" title="1.命令行参数设定"></a>1.命令行参数设定</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--weights-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--image-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">3</span>) </span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure><h3 id="2-加载预训练权重"><a href="#2-加载预训练权重" class="headerlink" title="2.加载预训练权重"></a>2.加载预训练权重</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model = SRCNN().to(device)</span><br><span class="line"></span><br><span class="line">state_dict = model.state_dict() <span class="comment">#加载模型的参数状态  </span></span><br><span class="line"><span class="comment">#加载预训练权重，并映射到GPU</span></span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(args.weights_file, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():</span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():<span class="comment"># 如果预训练权重中的键在模型的参数状态中存在 </span></span><br><span class="line">        state_dict[n].copy_(p)<span class="comment"># 则用预训练权重替换模型参数</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> KeyError(n)</span><br></pre></td></tr></table></figure><h3 id="3-双三次插值（BICUBIC）调整图片尺寸"><a href="#3-双三次插值（BICUBIC）调整图片尺寸" class="headerlink" title="3.双三次插值（BICUBIC）调整图片尺寸"></a>3.双三次插值（BICUBIC）调整图片尺寸</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">image = pil_image.<span class="built_in">open</span>(args.image_file).convert(<span class="string">&#x27;RGB&#x27;</span>)<span class="comment"># 加载图像，并转换为RGB格式</span></span><br><span class="line"><span class="comment"># 根据args.scale调整图像尺寸，使其为scale的整数倍 </span></span><br><span class="line">image_width = (image.width // args.scale) * args.scale</span><br><span class="line">image_height = (image.height // args.scale) * args.scale</span><br><span class="line"><span class="comment"># 调整至scale的倍数</span></span><br><span class="line">image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)</span><br><span class="line"><span class="comment"># 将原始图片进行下采样，缩小到原始尺寸的1/scale，得到低分辨率图片</span></span><br><span class="line">image = image.resize((image.width // args.scale, image.height // args.scale), resample=pil_image.BICUBIC)</span><br><span class="line"><span class="comment"># 将低分辨率图片进行上采样，放大到规定的尺寸</span></span><br><span class="line">image = image.resize((image.width * args.scale, image.height * args.scale), resample=pil_image.BICUBIC)</span><br><span class="line"><span class="comment"># 保存处理后的图像</span></span><br><span class="line">image.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_bicubic_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br></pre></td></tr></table></figure><h3 id="4-调整色彩空间并进行超分辨率重建"><a href="#4-调整色彩空间并进行超分辨率重建" class="headerlink" title="4.调整色彩空间并进行超分辨率重建"></a>4.调整色彩空间并进行超分辨率重建</h3><ul><li><strong>将调整后的图像从RGB色彩空间转换到YCbCr色彩空间，并仅对Y分量进行超分辨率重建（SRCNN等模型通常只处理亮度分量）</strong>。</li><li><strong>YCbCr是一种色彩空间，其中Y代表亮度分量（Luminance），Cb和Cr代表蓝色和红色的色度分量（Chrominance）。YCbCr色彩空间是YUV色彩空间的一种变种，广泛应用于视频压缩和图像处理中。</strong></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image = np.array(image).astype(np.float32)<span class="comment"># 将图像转换为numpy数组，并转换为float32类型 </span></span><br><span class="line">ycbcr = convert_rgb_to_ycbcr(image)<span class="comment"># 将RGB图像转换为YCbCr色彩空间</span></span><br><span class="line"></span><br><span class="line">y = ycbcr[..., <span class="number">0</span>] <span class="comment">#提取Y分量</span></span><br><span class="line">y /= <span class="number">255.</span> <span class="comment">#归一化Y分量到[0, 1] </span></span><br><span class="line">y = torch.from_numpy(y).to(device) <span class="comment">#将numpy数组转换为torch张量，并移动到指定设备（如GPU）</span></span><br><span class="line">y = y.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>) <span class="comment">#增加一个批次维度和一个通道维度</span></span><br></pre></td></tr></table></figure><h3 id="5-使用模型进行重建"><a href="#5-使用模型进行重建" class="headerlink" title="5.使用模型进行重建"></a>5.使用模型进行重建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():<span class="comment"># 关闭梯度计算，进行前向传播</span></span><br><span class="line">    preds = model(y).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>) <span class="comment">#使用模型进行预测，并限制输出值在[0, 1]之间</span></span><br><span class="line"></span><br><span class="line">psnr = calc_psnr(y, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;PSNR: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(psnr))</span><br><span class="line"></span><br><span class="line">preds = preds.mul(<span class="number">255.0</span>).cpu().numpy().squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)<span class="comment">#将预测结果转换回uint8类型，并去除批次和通道维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将预测的Y分量与原始的Cb、Cr分量合并，然后转换回RGB色彩空间  </span></span><br><span class="line">output = np.array([preds, ycbcr[..., <span class="number">1</span>], ycbcr[..., <span class="number">2</span>]]).transpose([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">output = np.clip(convert_ycbcr_to_rgb(output), <span class="number">0.0</span>, <span class="number">255.0</span>).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">output = pil_image.fromarray(output) <span class="comment">#将numpy数组转换回PIL图像 </span></span><br><span class="line">output.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_srcnn_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale))) <span class="comment">#保存最终的图像 </span></span><br></pre></td></tr></table></figure><h3 id="6-结果"><a href="#6-结果" class="headerlink" title="6.结果"></a>6.结果</h3><p><img src="https://s21.ax1x.com/2024/09/13/pAn4tSJ.png" alt="pAn4tSJ.png"></p><h2 id="六-以单幅低分辨率图像实现超分辨率"><a href="#六-以单幅低分辨率图像实现超分辨率" class="headerlink" title="六.以单幅低分辨率图像实现超分辨率"></a>六.以单幅低分辨率图像实现超分辨率</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将单幅低分辨率图像以原尺寸规模进行超分辨率处理</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> pil_image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> SRCNN</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> convert_rgb_to_ycbcr, convert_ycbcr_to_rgb, calc_psnr</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--image-file&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">3</span>) </span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    model = SRCNN().to(device)</span><br><span class="line"></span><br><span class="line">    state_dict = model.state_dict()</span><br><span class="line">    <span class="keyword">for</span> n, p <span class="keyword">in</span> torch.load(args.weights_file, map_location=<span class="keyword">lambda</span> storage, loc: storage).items():</span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">in</span> state_dict.keys():</span><br><span class="line">            state_dict[n].copy_(p)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(n)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    image = pil_image.<span class="built_in">open</span>(args.image_file).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">    image_width = (image.width // args.scale) * args.scale</span><br><span class="line">    image_height = (image.height // args.scale) * args.scale</span><br><span class="line">    image = image.resize((image_width, image_height), resample=pil_image.BICUBIC) </span><br><span class="line">    <span class="comment">#不进行下采样得到低分辨率图像的操作，从而也不需要上采样恢复尺寸</span></span><br><span class="line">    <span class="comment"># image = image.resize((image.width // args.scale, image.height // args.scale), resample=pil_image.BICUBIC)</span></span><br><span class="line">    <span class="comment"># image = image.resize((image.width * args.scale, image.height * args.scale), resample=pil_image.BICUBIC)</span></span><br><span class="line">    image.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_bicubic_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br><span class="line"></span><br><span class="line">    image = np.array(image).astype(np.float32)</span><br><span class="line">    ycbcr = convert_rgb_to_ycbcr(image)</span><br><span class="line"></span><br><span class="line">    y = ycbcr[..., <span class="number">0</span>]</span><br><span class="line">    y /= <span class="number">255.</span></span><br><span class="line">    y = torch.from_numpy(y).to(device)</span><br><span class="line">    y = y.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        preds = model(y).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># psnr = calc_psnr(y, preds)</span></span><br><span class="line">    <span class="comment"># print(&#x27;PSNR: &#123;:.2f&#125;&#x27;.format(psnr))</span></span><br><span class="line"></span><br><span class="line">    preds = preds.mul(<span class="number">255.0</span>).cpu().numpy().squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    output = np.array([preds, ycbcr[..., <span class="number">1</span>], ycbcr[..., <span class="number">2</span>]]).transpose([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">    output = np.clip(convert_ycbcr_to_rgb(output), <span class="number">0.0</span>, <span class="number">255.0</span>).astype(np.uint8)</span><br><span class="line">    output = pil_image.fromarray(output)</span><br><span class="line">    output.save(args.image_file.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;_srcnn_x&#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(args.scale)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#python make.py --weights-file=outputs/x3/best.pth --image-file=data/test.bmp</span></span><br></pre></td></tr></table></figure><ul><li>个人评价：该模型实现效果很差。若不提供原始高分辨率图像，几乎不能将低分辨率图像变为高分辨率图像。</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率第一章-SRCNN&quot;&gt;&lt;a href=&quot;#超分辨率第一章-SRCNN&quot; class=&quot;headerlink&quot; title=&quot;超分辨率第一章-SRCNN&quot;&gt;&lt;/a&gt;超分辨率第一章-SRCNN&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;第一个超分辨率模型-SRCNN （SISR），2014年提出&lt;/p&gt;
&lt;p&gt;参考网址：&lt;a href=&quot;https://blog.csdn.net/zhanjuex/article/details/124344864?spm=1001.2014.3001.5506&quot;&gt;【超分辨率】【深度学习】SRCNN pytorch代码（附详细注释和数据集）_srcnn代码-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_52261094/article/details/128389448&quot;&gt;SRCNN超分辨率Pytorch实现，代码逐行讲解，附源码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;模型位置：F:&#92;Github下载&#92;SRCNN_Pytorch_1.0-master&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>超分辨率-综述</title>
    <link href="http://example.com/2024/09/06/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E7%BB%BC%E8%BF%B0/"/>
    <id>http://example.com/2024/09/06/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E7%BB%BC%E8%BF%B0/</id>
    <published>2024-09-06T08:55:56.000Z</published>
    <updated>2024-09-09T12:50:05.829Z</updated>
    
    <content type="html"><![CDATA[<h1 id="超分辨率-综述"><a href="#超分辨率-综述" class="headerlink" title="超分辨率-综述"></a>超分辨率-综述</h1><blockquote><p>参考文献：<a href="http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2202063">深度学习的图像超分辨率重建技术综述</a></p></blockquote><span id="more"></span><h2 id="关于分辨率（resolution）"><a href="#关于分辨率（resolution）" class="headerlink" title="关于分辨率（resolution）"></a>关于分辨率（resolution）</h2><h3 id="1-分辨率的概念"><a href="#1-分辨率的概念" class="headerlink" title="1.分辨率的概念"></a>1.分辨率的概念</h3><ul><li>分辨率描述了图像或视频中像素的数量和密度，以及显示设备能够呈现的细节水平</li><li>具体可以细分为<a href="https://baike.baidu.com/item/显示分辨率/3431933?fromModule=lemma_inlink">显示分辨率</a>、<a href="https://baike.baidu.com/item/图像分辨率/872374?fromModule=lemma_inlink">图像分辨率</a><ul><li>显示分辨率<ul><li>在显示器领域，分辨率通常指屏幕水平和垂直方向有多少像素点。分辨率大小使用乘积表示，如1920×1080。当屏幕分辨率高时，屏幕上显示的像素多，单个像素尺寸比较小。2k:1920<em>1080；2.5k:2560\</em>1440；4k:3840 x 2160</li></ul></li><li>图像分辨率<ul><li>图像分辨率指的是图像中存储的信息量，通常为单位英寸中包含的像素点数。随着图像技术的发展，理论上图像分辨率会越来越大。</li><li>Pixels Per Inch(PPI)也叫像素密度单位，所表示的是每英寸所拥有的像素数量。因此PPI数值越高，即代表显示屏能够以越高的密度显示图像。当然，显示的密度越高，拟真度就越高</li></ul></li></ul></li></ul><h3 id="2-疑问解答"><a href="#2-疑问解答" class="headerlink" title="2.疑问解答"></a>2.疑问解答</h3><ul><li><strong>问题一：在基于深度学习的超分辨率重建图像方法中，分为两个模块，上采样和非线性映射学习模块；上采样是将图片进行放大，这个过程提升了图像的分辨率吗？（按我个人的理解是上采样是将图片的尺寸进行放大，但是并没有将先前模糊的图片变清晰，而非线性学习映射才是将低分辨率图片变为高分辨率图片的过程）</strong></li></ul><blockquote><p>答：在基于深度学习的超分辨率重建图像方法中，确实包含上采样和非线性映射学习两个关键模块。针对您提出的问题，我们可以从以下几个方面进行详细分析：</p><p><strong>1.上采样模块的作用</strong></p><p><strong>上采样</strong>模块的主要作用是将图像的尺寸进行放大，这个过程确实提升了图像的分辨率。分辨率是指图像中像素点的数量，通过上采样，图像的像素点数量增加，从而在物理尺寸上实现了图像的放大。然而，<strong>仅仅通过上采样并不能直接改善图像的质量，特别是当原始图像是低分辨率或模糊的时。这是因为上采样本身并不增加图像中的新信息，只是通过插值等方法在现有像素之间生成新的像素值。</strong></p><p><strong>2.非线性映射学习模块的作用</strong></p><p><strong>非线性映射学习</strong>模块则是超分辨率重建中的核心部分。它负责学习低分辨率（LR）图像到高分辨率（HR）图像之间的映射关系。在训练过程中，该模块通过大量的LR-HR图像对进行学习，使得模型能够掌握从LR图像中提取有效特征并重建出HR图像的能力。这个过程中，<strong>模型会学习到如何填补LR图像中缺失的细节信息，从而生成更加清晰、高分辨率的图像。</strong></p><p><strong>3.两者结合的作用</strong></p><p>在超分辨率重建中，上采样模块和非线性映射学习模块是相辅相成的。上采样模块为非线性映射学习模块提供了必要的图像尺寸放大功能，使得模型能够在更大的图像尺寸上进行特征提取和重建。而非线性映射学习模块则通过其强大的学习能力，弥补了上采样过程中可能产生的模糊和失真问题，最终生成出高质量的高分辨率图像。</p><p><strong>4.对问题的回答</strong></p><ul><li><strong>上采样是否提升了图像的分辨率？</strong> 是的，上采样通过增加图像的像素点数量，实现了图像尺寸的放大和分辨率的提升。</li><li><strong>上采样是否将先前模糊的图片变清晰？</strong> 单独来看，上采样并不能直接使模糊的图片变清晰。它只是改变了图像的物理尺寸和分辨率，而没有增加图像中的新信息或改善图像的质量。要使模糊的图片变清晰，需要依赖非线性映射学习模块等后续处理步骤。</li><li><strong>非线性学习映射是否将低分辨率图片变为高分辨率图片？</strong> 是的，非线性学习映射模块通过其强大的学习能力，能够从低分辨率图像中提取有效特征并重建出高分辨率图像。这个过程中，模型会填补低分辨率图像中缺失的细节信息，从而生成出更加清晰、高分辨率的图像。</li></ul><p>综上所述，在基于深度学习的超分辨率重建图像方法中，上采样模块和非线性映射学习模块各自承担着重要的角色，并通过协同工作实现了从低分辨率图像到高分辨率图像的转换</p></blockquote><ul><li><strong>问题二：上采样提升了分辨率，不是将图片的分辨率提高了吗，为什么图片还是模糊的呢，不是说分辨率越高的图片越清晰吗？</strong></li></ul><blockquote><p>您提出的问题非常深入，涉及到了图像处理中分辨率、清晰度以及上采样过程之间的复杂关系。首先，我们来澄清几个概念，并解释为什么上采样虽然提升了图像的分辨率，但并不一定能使图片变得清晰。</p><p><strong>1.分辨率与清晰度的关系</strong></p><p>分辨率确实是衡量图像质量的一个重要指标，它指的是图像中像素的数量。在数字图像中，分辨率越高，意味着图像包含的像素点越多，从而在物理尺寸上能够展现更多的细节。然而，<strong>清晰度（sharpness）则更多地与图像的细节表现力、边缘的锐利程度以及图像的噪声水平等因素有关。</strong></p><p><strong>2.上采样的作用与限制</strong></p><p>上采样是一个将图像尺寸放大的过程，它通过插值算法在原有像素之间生成新的像素值，从而增加图像的像素数量，提升分辨率。但是，这个过程并不会增加图像中的实际信息内容。换句话说，上采样无法创造出原本不存在的图像细节。</p><p><strong>3.为什么上采样后的图片可能仍然模糊？</strong></p><ol><li><strong>信息缺失</strong>：如果原始图像本身就是低分辨率或模糊的，那么它包含的细节信息就有限。上采样虽然能在物理尺寸上放大图像，但无法填补这些缺失的细节。</li><li><strong>插值算法的影响</strong>：上采样过程中使用的插值算法会影响新生成像素的质量。一些简单的插值算法（如最近邻插值）可能会产生明显的锯齿效应或模糊效果。而更复杂的算法（如双线性插值、双三次插值等）虽然能在一定程度上改善这个问题，但仍然无法完全恢复原始图像中不存在的细节。</li><li><strong>噪声放大</strong>：在上采样过程中，图像中的噪声也可能会被放大。如果原始图像就包含较多的噪声，那么上采样后的图像可能会显得更加模糊或颗粒感更强。</li></ol><p><strong>结论</strong></p><p>因此，虽然上采样能够提升图像的分辨率，但并不一定能使图片变得清晰。<strong>要获得清晰的图像，还需要从源头上保证图像的质量，并在后续处理过程中采用合适的算法和技术来尽可能地保留和恢复图像的细节信息。</strong>在某些情况下，可能需要结合超分辨率重建等高级技术来进一步提升图像的质量。</p></blockquote><h2 id="一-单图像超分辨率重建方法-SISR"><a href="#一-单图像超分辨率重建方法-SISR" class="headerlink" title="一.单图像超分辨率重建方法(SISR)"></a>一.单图像超分辨率重建方法(SISR)</h2><h3 id="1-发展情况"><a href="#1-发展情况" class="headerlink" title="1.发展情况"></a>1.发展情况</h3><ul><li>SISR 方法输入一张低分辨率图像，利用深度神经网络学习 LR-HR 图像对之间的映射关系，最终将 LR 图像重建为一张高分辨率图像。</li><li>2014提出<strong>SRCNN</strong>模型：提出<strong>峰值信噪比</strong>（peak signal-tonoise ratio，<strong>PSNR</strong>）和<strong>结构相似度</strong>（structure similarity index measure，<strong>SSIM</strong>）指标。这个阶段的 SISR 方法的改进方向主要以增加神经网络的深度，从而提高PSNR和SSIM指标为导向。</li><li>2017年提出<strong>SRGNN</strong>模型：首次提出要提高图像的感官质量，引入了<strong>感知损失函数</strong>。随后提出的模型开始以<strong>优化重建图像纹理细节</strong>为目标。</li><li>发展历程<ul><li><img src="https://s21.ax1x.com/2024/09/06/pAZqM01.png" alt="pAZqM01.png"></li></ul></li></ul><h3 id="2-超分框架（按照上采样模块位置区分）"><a href="#2-超分框架（按照上采样模块位置区分）" class="headerlink" title="2.超分框架（按照上采样模块位置区分）"></a>2.超分框架（按照上采样模块位置区分）</h3><ul><li><strong>非线性映射学习模块</strong><ul><li><strong>负责完成低分辨率图像到高分辨率图像的映射，这个过程中利用损失函数来进行引导和监督学习的进程</strong></li></ul></li><li><strong>上采样模块</strong><ul><li><strong>实现图片的放大</strong></li></ul></li></ul><h4 id="①前端上采样超分框架"><a href="#①前端上采样超分框架" class="headerlink" title="①前端上采样超分框架"></a>①前端上采样超分框架</h4><ul><li><p><strong>先将图片放大，再进行低分辨率到高分辨率的映射。</strong></p></li><li><p>前端上采样可以<strong>避免在低维空间上进行低维到高维的映射学习</strong>，降低了学习难度，是一 种简单易行的方法。</p></li><li><strong>但是同时噪声和模糊等也被增强，并且在高维空间进行卷积运算将会增加模型计算量，消耗更多的计算资源</strong></li><li><img src="https://s21.ax1x.com/2024/09/06/pAZqBAP.md.png" alt="pAZqBAP.md.png"></li></ul><h4 id="②后端上采样超分框架"><a href="#②后端上采样超分框架" class="headerlink" title="②后端上采样超分框架"></a>②后端上采样超分框架</h4><ul><li><p><strong>先进行低分辨率到高分辨率的映射，再将图片放大。</strong></p></li><li><p>该框架下的大部分卷积计算在低维空间进行，最后再利用端到端可学习的上采样层，<strong>如转置卷积和亚像素卷积</strong> ，进行上采样放大。</p></li><li>进一步释放了卷积的计算能力， 降低模型复杂度。</li><li><img src="https://s21.ax1x.com/2024/09/06/pAZq5NV.md.png" alt="pAZq5NV.md.png"></li></ul><h4 id="③渐进式上采样超分框架"><a href="#③渐进式上采样超分框架" class="headerlink" title="③渐进式上采样超分框架"></a>③渐进式上采样超分框架</h4><ul><li>先进行低分辨率到高分辨的映射，之后逐级进行图片放大，中途生成的图像继续输入后续模块（低分辨率到高分辨率的映射），直到达到目标分辨率。</li><li><p>常用方法是采用卷积级联或者 Laplace 金字塔的方式，再结合多级监督等学习策略</p></li><li><p><img src="https://s21.ax1x.com/2024/09/06/pAZqXH1.png" alt="pAZqXH1.png"></p></li></ul><h4 id="④升降采样迭代式超分框架"><a href="#④升降采样迭代式超分框架" class="headerlink" title="④升降采样迭代式超分框架"></a>④升降采样迭代式超分框架</h4><ul><li>交替使用上、下采样，结合得到的所有特征图来完成低分辨率图像的重建</li><li><img src="https://s21.ax1x.com/2024/09/06/pAZqz4K.md.png" alt="pAZqz4K.md.png"></li></ul><h3 id="3-上采样方法"><a href="#3-上采样方法" class="headerlink" title="3.上采样方法"></a>3.上采样方法</h3><h4 id="①基于插值法的上采样方法"><a href="#①基于插值法的上采样方法" class="headerlink" title="①基于插值法的上采样方法"></a>①基于插值法的上采样方法</h4><ul><li>利用一定的数学策略，从相关点中计算出待扩展点的像素值</li><li><strong>但是由于插值函数本身的连续性，导致了重建图像较为<u>平滑而模糊。</u>但图像纹理处常常是<u>各种突变</u>，这与插值函数的连续性互为矛盾</strong></li></ul><h4 id="②端到端可学习的上采样方法"><a href="#②端到端可学习的上采样方法" class="headerlink" title="②端到端可学习的上采样方法"></a>②端到端可学习的上采样方法</h4><h5 id="1-转置卷积"><a href="#1-转置卷积" class="headerlink" title="(1)转置卷积"></a>(1)转置卷积</h5><ul><li><p>设卷积核大小为k*k，输入为方形矩阵（将转置卷积过程转变为普通卷积过程）</p><ol><li>对输入进行四边补零，单边补零的数量为k-1</li><li>将卷积核旋转180°，在新的输入上进行直接卷积</li></ol></li><li><p>图示：</p><ul><li><img src="https://s21.ax1x.com/2024/09/06/pAZvnds.png" alt="pAZvnds.png"></li></ul></li></ul><h5 id="2-亚像素卷积"><a href="#2-亚像素卷积" class="headerlink" title="(2)亚像素卷积"></a>(2)亚像素卷积</h5><ul><li>亚像素的概念：在相机成像的过程中，获得的图像数据是将图像进行了离散化的处理，由于感光元件本身的能力限制，到成像面上每个像素只代表附近的颜色。例如两个感官原件上的像素之间有4.5um的间距，宏观上它们是连在一起的，微观上它们之间还有无数微小的东西存在，这些存在于两个实际物理像素之间的像素，就被称为“亚像素”。</li><li>利用卷积计算对图像进行特征提取，再对不同通道间的特征图进行重组，从而得到更高分辨率的特征图</li><li>图示：<img src="https://s21.ax1x.com/2024/09/06/pAZx5NR.png" alt="pAZx5NR.png"></li></ul><h3 id="4-非线性映射学习模块"><a href="#4-非线性映射学习模块" class="headerlink" title="4.非线性映射学习模块"></a>4.非线性映射学习模块</h3><ul><li>非线性映射学习模块在训练过程中利用 “<strong>LR-HR 图像对</strong>“进行学习，使模型获得从低分辨率图像到高分辨率图像的映射能力</li><li>一共分为四种模型<ul><li><img src="https://s21.ax1x.com/2024/09/06/pAZzRRP.png" alt="pAZzRRP.png"></li></ul></li></ul><h4 id="①基于CNN的超分模型"><a href="#①基于CNN的超分模型" class="headerlink" title="①基于CNN的超分模型"></a>①基于CNN的超分模型</h4><h5 id="1-SRCNN（2014年Dong等人提出，前端上采样框架-）"><a href="#1-SRCNN（2014年Dong等人提出，前端上采样框架-）" class="headerlink" title="(1)SRCNN（2014年Dong等人提出，前端上采样框架 ）"></a>(1)SRCNN（2014年Dong等人提出，前端上采样框架 ）</h5><ul><li>先将图片下采样预处理得到低分辨率图像</li><li>再利用双三次插值法将图片放大到目标分辨率（基于插值的上采样方法）</li><li>再用卷积核大小分别为 9×9、1×1、5×5的三个卷积层，分别进行特征提取，拟合 LR-HR 图像对之间的非线性映射以及将网络模型的输出结果进行重建，得到最后的高分辨率图像</li><li>图示：<img src="https://s21.ax1x.com/2024/09/06/pAZzAbQ.png" alt="pAZzAbQ.png"></li></ul><h5 id="2-FSRCNN-2016年由Dong改进，后端上采样框架"><a href="#2-FSRCNN-2016年由Dong改进，后端上采样框架" class="headerlink" title="(2)FSRCNN (2016年由Dong改进，后端上采样框架)"></a>(2)FSRCNN (2016年由Dong改进，后端上采样框架)</h5><ul><li>改进点：<ul><li>直接用LR图像作为输入，降低特征维度</li><li>使用比SRCNN 更小的滤波器，网络结构加深</li><li>采用后端上采样超分框架，在网络最后加入反卷积层来将图像放大至目标分辨率。</li><li>FSRCNN采用更小的卷积核、更深的网络层数，训练速度提高，重建的HR图像质量效果进一步得到提高</li></ul></li><li>图示：<img src="https://s21.ax1x.com/2024/09/06/pAZz6IA.png" alt="pAZz6IA.png"></li></ul><h4 id="②基于GNN的超分模型"><a href="#②基于GNN的超分模型" class="headerlink" title="②基于GNN的超分模型"></a>②基于GNN的超分模型</h4><ul><li>解决问题：基于CNN的超分辨率模型，尽管重建出来的高分辨率图像的 PSNR/SSIM 指标越来越高，但是生成的图像过于平滑，高频纹理信息丢失，重建图像缺乏人眼感官上的照片真实感， 并且在工业界的实际使用效果依然很差</li></ul><h5 id="1-SRGNN-2017Ledig等人提出"><a href="#1-SRGNN-2017Ledig等人提出" class="headerlink" title="(1) SRGNN (2017Ledig等人提出)"></a>(1) SRGNN (2017Ledig等人提出)</h5><ul><li>最早开始将超分研究的注意力从 PSNR/SSIM 指标上转移到图像感知质量上。</li><li>利用 VGG 网络提取出来的特征计算损失函数作为内容损失，内容损失加上对抗网络本身的对抗损失，共同构成了感知损失函数</li></ul><h4 id="③基于深度强化学习的超分模型"><a href="#③基于深度强化学习的超分模型" class="headerlink" title="③基于深度强化学习的超分模型"></a>③基于深度强化学习的超分模型</h4><ul><li>强化学习概念：<ul><li>强化学习在现有数据的基础上，循环利用学习得到的新的数据，不断提高模型的学习能力。 该方法已经被证明在不监督每一步的情况下对序列模型进行全局优化的有效性</li></ul></li></ul><h4 id="④基于Transformer的超分模型"><a href="#④基于Transformer的超分模型" class="headerlink" title="④基于Transformer的超分模型"></a>④基于Transformer的超分模型</h4><ul><li>2020 年 Yang 等人最早将 Transformer 引入图像超分领域，提出了基于 Transformer 网络结构的 TTSR 超分算法。</li><li>为了充分利用参考图像的纹理信息，Yang 等人在TTSR中提出了特征融合机制，利用上采样方式实现不同层级间的特征互相融合。</li></ul><h3 id="5-损失函数"><a href="#5-损失函数" class="headerlink" title="5.损失函数"></a>5.损失函数</h3><ul><li>损失函数在非线性映射学习模块的学习过程中，指导着超分模型向着预期的方向学习和前进，通过损失函数的变化可以知道当前模型的训练与预期之间的差距，同时调控模型学习方向。</li></ul><h4 id="①像素损失函数"><a href="#①像素损失函数" class="headerlink" title="①像素损失函数"></a>①像素损失函数</h4><ul><li>表示重建图像与目标图像之间的像素损失</li></ul><h5 id="1-MSE损失（均方误差）函数"><a href="#1-MSE损失（均方误差）函数" class="headerlink" title="(1)MSE损失（均方误差）函数"></a>(1)MSE损失（均方误差）函数</h5><ul><li><script type="math/tex; mode=display">M S E = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( y _ { i } - y _ { i } ^ { * } ) ^ { 2 }</script></li><li>其中，n 表示像素点个数，yi 表示预测值，<script type="math/tex">y _ { i } ^ { * }</script>表示目标值。</li><li>缺点（基于平方项的影响）<ul><li>MSE 损失函数（L2 loss）中，在误差已经很小的情况下，MSE损失函数仍然会促使模型继续优化这些误差，即使这样做带来的收益可能微乎其微。</li><li>当误差大于1时，MSE会将误差进一步放大，因此它对数据中的异常值（即那些与大多数数据点显著不同的点）非常敏感。模型可能会为了适应这些异常值而做出较大的调整，这可能导致模型在整体数据上的泛化能力下降。这就使得最终重建图像更为平滑、模糊，缺乏高频的纹理细节。</li><li>在图像处理或重建任务中，如果使用MSE作为损失函数，模型可能会为了最小化MSE而倾向于生成平滑、模糊的图像。这是因为高频纹理细节（如边缘、锐角等）在像素级别上通常与周围像素有较大的差异，这些差异在MSE损失函数下会被视为大误差。为了减小这些误差，模型可能会倾向于将这些高频细节平滑化，从而导致重建图像缺乏细节和锐度。</li></ul></li></ul><h5 id="2-L1损失函数（平均绝对误差）"><a href="#2-L1损失函数（平均绝对误差）" class="headerlink" title="(2)L1损失函数（平均绝对误差）"></a>(2)L1损失函数（平均绝对误差）</h5><ul><li><script type="math/tex; mode=display">L _ { 1 } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } | y _ { i } - y _ { i } ^ { * } |</script></li><li>在实践中，L1 损失函数的实际效果要比 MSE更好，更能提高模型性能，得到更高的指标</li></ul><h4 id="②内容损失"><a href="#②内容损失" class="headerlink" title="②内容损失"></a>②内容损失</h4><ul><li><p>相对像素损失来说，内容损失不再要求像素层面上的精确，而是追求人眼感官层面的相似。为了提升感知质量，利用神经网络中生成的图像特征与真实图像特征之间的距离来进行计算</p></li><li><script type="math/tex; mode=display">L _ { e o n t e n t } = \frac { 1 } { n _ { l } } \sqrt { \sum _ { i , j } ( \phi _ { i , j } ^ { ( 0 ) } ( I ) - \phi _ { i , j } ^ { ( 0 ) } ( \widehat { I } ) ) ^ { 2 } }</script></li><li><script type="math/tex">n _ { l }</script> 表示第 L 层特征图对应的像素点个数，<script type="math/tex">\phi _ { i , j } ^ { ( l ) } ( I )</script>和<script type="math/tex">\phi _ { i , j } ^ { ( l ) } ( \widehat { I } )</script>分别表示重建图像和原始高分辨率图像在第 I 层中第 i 个最大池化层之前经过第 j 次卷积得到的特征图。</li></ul><h4 id="③对抗损失"><a href="#③对抗损失" class="headerlink" title="③对抗损失"></a>③对抗损失</h4><ul><li><script type="math/tex; mode=display">L _ { G } ( I _ { S R } ) = - D ( I _ { S R } )</script></li><li><script type="math/tex; mode=display">L _ { D } ( I _ { S R } , I _ { H R } ) = D ( I _ { S R } ) - D ( I _ { H R } ) + \lambda ( | V _ { I _ { S R } } D ( I _ { S R } ) _ { 2 } - 1 | | ) ^ { 2 }</script></li></ul><h4 id="④感知损失"><a href="#④感知损失" class="headerlink" title="④感知损失"></a>④感知损失</h4><ul><li>内容损失和对抗损失的加权和<ul><li><script type="math/tex; mode=display">L ^ { S R } = L _ { c o n t e n t } + 1 0 ^ { - 3 } L _ { G } ( I _ { S R } )</script></li></ul></li></ul><h2 id="二-基于参考的图像超分辨率重建（略读）"><a href="#二-基于参考的图像超分辨率重建（略读）" class="headerlink" title="二.基于参考的图像超分辨率重建（略读）"></a>二.基于参考的图像超分辨率重建（略读）</h2><ul><li>定义<ul><li><strong>RefSR 方法借助引入的参考图像，将相似度最高的参考图像中的信息转移到低分辨率图像中并进行两者的信息融合，从而重建出纹理细节更清晰的高分辨率图像。</strong></li></ul></li><li>步骤：<ul><li>第一步将参考图像中有用的信息与输入图像中的信息进行匹配，能准确对应两者的信息是重建令人满意的细节纹理的关键。</li><li>第二步将匹配到的信息进行提取，并与输入图像进行融合，进而重建出满意的图像。</li></ul></li><li>决定性因素就是 LR 图像与高分辨率参考图像之间的匹配和融合的准确性</li><li><img src="https://s21.ax1x.com/2024/09/08/pAeRGgx.png" alt="pAeRGgx.png"></li></ul><h3 id="1-像素对齐"><a href="#1-像素对齐" class="headerlink" title="1.像素对齐"></a>1.像素对齐</h3><ul><li>先从 LR 图像中检测稀疏的特征，再在参考图像中进行特征匹配， 最后基于这些匹配特征将原LR图像映射到另一个图像中，从而实现图像对齐</li><li><p><strong>Landmark</strong> 通过全局配准来将参考图像与上采样后的LR图像进行对齐，从而识别出这些图像中各自对应的区域， 减少失配或错配的情况</p><ul><li><img src="https://s21.ax1x.com/2024/09/08/pAeRF4s.png" alt="pAeRF4s.png"></li></ul></li><li><p>2018年的<strong>CrossNet</strong>模型是一种端到端的完全卷积的深度神经网络，通过预测光流量来进行跨尺度变换</p><ul><li><img src="https://s21.ax1x.com/2024/09/08/pAeR2qS.png" alt="pAeR2qS.png"></li></ul></li><li>2018年Zhao等人提出了<strong>高频补偿超分辨率（highfrequency compensation super-resolution，HCSR）模型</strong>，需要计算从参考图像到所有LR光场图像的多个视图差，然后利用混合策略对精化的视差图进行融合，最后得到高质量的超分图像</li><li>2020年Shim 等人在堆叠的可变性卷积的基础上提出了可实现<strong>端到端的新颖高效的参考图像特征提取模块——相似性搜索与提取网络（similairity search and extraction network，SSEN</strong>），可以从参考图像中提取对齐的相关特征，并且可以插入到任何现有的超分辨率网络中。</li></ul><h3 id="2-Patch匹配"><a href="#2-Patch匹配" class="headerlink" title="2.Patch匹配"></a>2.Patch匹配</h3><ul><li>2017 年 Zheng 等人利用 Patch 匹配的方法，提出了 <strong>SS-Net 模型</strong>。具体来说，SS-Net 首先设计了一个跨尺度对应网络来表示参考图像和低分辨率图像之间的跨尺度 Patch匹配。在多个尺度上对低分辨率图像的Patch与参考图像的Patch进行融合，最终合成HR图像并输出。</li><li><p>2019 年 Zheng 等人提出了<strong>端到端可学习的 SRNTT（superresolution by neural texture transfer）网络模型</strong>，SRNTT预先训练的 VGG 中提取的参考特征与 LR 特征在自然空间中进行多级匹配，促进了多尺度神经传输。</p><ul><li><img src="https://s21.ax1x.com/2024/09/08/pAeRzGR.png" alt="pAeRzGR.png"></li></ul></li><li><p>2020年Yang等人[16] 进一步将Transformer架构引入RefSR任务，提出了<strong>TTSR 模型</strong></p><ul><li><img src="https://s21.ax1x.com/2024/09/08/pAeWnzt.png" alt="pAeWnzt.png"></li></ul></li><li><p>2021年Zhou等人从解决实际多尺度相机系统中的 RefSR问题出发，受到多平面图像（multiplane image，MPI）表示的启发，提出了一个 端到端可学习的 RefSR 网络模型——Cross-MPI 模型</p></li><li>2021年Lu等人[56] 提出了 MASA （matching acceleration and spatial adaptation）模型</li><li>2021年Jiang 等人[57] 提出了 C2 -Matching 模型</li></ul><h2 id="三-超分数据集和图像质量评估"><a href="#三-超分数据集和图像质量评估" class="headerlink" title="三.超分数据集和图像质量评估"></a>三.超分数据集和图像质量评估</h2><h3 id="1-常用数据集"><a href="#1-常用数据集" class="headerlink" title="1.常用数据集"></a>1.常用数据集</h3><ul><li><img src="https://s21.ax1x.com/2024/09/08/pAeWNzq.png" alt="pAeWNzq.png"></li></ul><h3 id="2-图像质量评估"><a href="#2-图像质量评估" class="headerlink" title="2.图像质量评估"></a>2.图像质量评估</h3><h4 id="①峰值信噪比（PSNR）"><a href="#①峰值信噪比（PSNR）" class="headerlink" title="①峰值信噪比（PSNR）"></a>①峰值信噪比（PSNR）</h4><ul><li><script type="math/tex; mode=display">P S N R = 1 0 \lg \frac { M A X _ { 1 } ^ { 2 } } { M S E }</script></li><li><p>其中，MSE 为均方误差，MAX指表示图像点颜色的最大数值，图像的最大像素值由二进制位数决定，如8位二进制表示的图像的最大像素值就是 255。</p></li></ul><h4 id="②结构相似度（SSIM）"><a href="#②结构相似度（SSIM）" class="headerlink" title="②结构相似度（SSIM）"></a>②结构相似度（SSIM）</h4><ul><li>SSIM 从人类视觉系统中 获得灵感，将图像的组成分为亮度、对比度以及结构三部分，并用均值作为亮度的估计，标准差作为对比度估计，协方差作为结构相似程度估计</li><li><script type="math/tex; mode=display">S S I M ( x , y ) = \frac { ( 2 \mu _ { x } \mu _ { y } + c _ { 1 } ) ( \sigma _ { x y } + c _ { 2 } ) } { ( \mu _ { x } ^ { 2 } + \mu _ { y } ^ { 2 } + c _ { 1 } ) ( \sigma _ { x } ^ { 2 } + \sigma _ { y } ^ { 2 } + c _ { 2 } ) }</script></li></ul><h4 id="③平均意见评分（mean-opinion-score，MOS）"><a href="#③平均意见评分（mean-opinion-score，MOS）" class="headerlink" title="③平均意见评分（mean opinion score，MOS）"></a>③平均意见评分（mean opinion score，MOS）</h4><ul><li>一种常用的主观图像质量评估的方法，通过邀请接受过训练的普通人以及未接受过训练的普通人来对重建的图像进行评分，并且两者人数大致均衡，通过给重建图像打分，再对最后的得分进行平均</li></ul><h2 id="四-模型分析"><a href="#四-模型分析" class="headerlink" title="四.模型分析"></a>四.模型分析</h2><h3 id="1-SOTA模型统计"><a href="#1-SOTA模型统计" class="headerlink" title="1. SOTA模型统计"></a>1. SOTA模型统计</h3><h4 id="①SISR模型统计"><a href="#①SISR模型统计" class="headerlink" title="①SISR模型统计"></a>①SISR模型统计</h4><p><img src="https://s21.ax1x.com/2024/09/08/pAeW6Y9.png" alt="pAeW6Y9.png"></p><h4 id="②RefSR模型统计"><a href="#②RefSR模型统计" class="headerlink" title="②RefSR模型统计"></a>②RefSR模型统计</h4><p><img src="https://s21.ax1x.com/2024/09/08/pAeWcWR.png" alt="pAeWcWR.png"></p><h3 id="2-两种方式对比"><a href="#2-两种方式对比" class="headerlink" title="2.两种方式对比"></a>2.两种方式对比</h3><p><img src="https://s21.ax1x.com/2024/09/08/pAeWRQx.png" alt="pAeWRQx.png"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;超分辨率-综述&quot;&gt;&lt;a href=&quot;#超分辨率-综述&quot; class=&quot;headerlink&quot; title=&quot;超分辨率-综述&quot;&gt;&lt;/a&gt;超分辨率-综述&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考文献：&lt;a href=&quot;http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2202063&quot;&gt;深度学习的图像超分辨率重建技术综述&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="学术论文总结" scheme="http://example.com/categories/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="超分辨率" scheme="http://example.com/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>深度学习第五章-ResNet网络</title>
    <link href="http://example.com/2024/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%94%E7%AB%A0-ResNet%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2024/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%94%E7%AB%A0-ResNet%E7%BD%91%E7%BB%9C/</id>
    <published>2024-09-04T08:10:38.000Z</published>
    <updated>2024-09-19T09:00:41.477Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习第五章-ResNet网络"><a href="#深度学习第五章-ResNet网络" class="headerlink" title="深度学习第五章-ResNet网络"></a>深度学习第五章-ResNet网络</h1><blockquote><p>本模型位于：E:\python文件\deep-learning-for-image-processing-master\pytorch_classification\Test5_resnet</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><blockquote><p>特点：</p><ul><li>超深的网络结构(突破1000层)</li><li>提出residual模块</li><li>使用Batch Normalization加速训练(丢弃dropout)</li></ul></blockquote><h3 id="1-残差模块"><a href="#1-残差模块" class="headerlink" title="1.残差模块"></a>1.残差模块</h3><p>（左边是18层、34层的残差块结构；右边是50层、101层、152层的残差块结构）</p><ul><li><img src="https://s21.ax1x.com/2024/09/04/pAZFLVO.png" alt="pAZFLVO.png"></li></ul><h3 id="2-实线残差结构与虚线残差结构"><a href="#2-实线残差结构与虚线残差结构" class="headerlink" title="2.实线残差结构与虚线残差结构"></a>2.实线残差结构与虚线残差结构</h3><p>从conv3层开始需使用虚线所示的残差网络结构（初始层有下采样）</p><h3 id="3-BN处理方法"><a href="#3-BN处理方法" class="headerlink" title="3.BN处理方法"></a>3.BN处理方法</h3><ul><li><p>通常在卷积层或全连接层之后添加</p></li><li><p>Batch Normalization的目的是使我们的一批(Batch) 特征层满足均值为0，方差为1的分布规律</p></li></ul><h3 id="4-模型参数"><a href="#4-模型参数" class="headerlink" title="4.模型参数"></a>4.模型参数</h3><ul><li><img src="https://s21.ax1x.com/2024/09/04/pAZVWO1.png" alt="pAZVWO1.png"></li></ul><h2 id="二-数据集-花分类集"><a href="#二-数据集-花分类集" class="headerlink" title="二.数据集-花分类集"></a>二.数据集-花分类集</h2><ul><li>如同前两章</li></ul><h2 id="三-模型搭建"><a href="#三-模型搭建" class="headerlink" title="三.模型搭建"></a>三.模型搭建</h2><h3 id="1-定义18层、24层网络残差块结构"><a href="#1-定义18层、24层网络残差块结构" class="headerlink" title="1.定义18层、24层网络残差块结构"></a>1.定义18层、24层网络残差块结构</h3><ul><li><p>图示，左边结构：conv2_x层、右边结构：conv3_x层及之后</p><ul><li><img src="https://s21.ax1x.com/2024/09/05/pAZ0SEV.png" alt="pAZ0SEV.png"></li></ul></li><li><p>代码</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module): <span class="comment">#定义残差块（18层、34层网络使用）</span></span><br><span class="line">    expansion = <span class="number">1</span> <span class="comment">#表示残差块中前后维度的倍数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(out_channel) <span class="comment">#bath normalizition层</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="variable language_">self</span>.downsample = downsample <span class="comment">#定义下采样方法</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x <span class="comment">#输入数据作为原数据记录</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#判断是否为虚线分支结构，若是则将原输入进行下采样</span></span><br><span class="line">            identity = <span class="variable language_">self</span>.downsample(x) </span><br><span class="line"></span><br><span class="line">        out = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line"></span><br><span class="line">        out = <span class="variable language_">self</span>.conv2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn2(out)</span><br><span class="line"></span><br><span class="line">        out += identity <span class="comment">#最终输出由主分支加原输入组成</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="2-定义50层、101层、152层残差块网络结构"><a href="#2-定义50层、101层、152层残差块网络结构" class="headerlink" title="2.定义50层、101层、152层残差块网络结构"></a>2.定义50层、101层、152层残差块网络结构</h3><ul><li>图示：左边结构：conv2_x层、右边结构：conv3_x层及之后<ul><li><img src="https://s21.ax1x.com/2024/09/04/pAZEI2j.png" alt="pAZEI2j.png" style="zoom:67%;"></li></ul></li><li>代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module): <span class="comment">#定义残差块 （50层、101层、152层网络使用）</span></span><br><span class="line">    expansion = <span class="number">4</span> <span class="comment">#表示残差块中前后维度的倍数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)  <span class="comment"># squeeze channels</span></span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="comment"># -----------------------------------------</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=stride, bias=<span class="literal">False</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="comment"># -----------------------------------------</span></span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*<span class="variable language_">self</span>.expansion,</span><br><span class="line">                               kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)  <span class="comment"># unsqueeze channels</span></span><br><span class="line">        <span class="variable language_">self</span>.bn3 = nn.BatchNorm2d(out_channel*<span class="variable language_">self</span>.expansion)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#判断是否为虚线分支结构,若是则将原输入进行下采样</span></span><br><span class="line">            identity = <span class="variable language_">self</span>.downsample(x)</span><br><span class="line"></span><br><span class="line">        out = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line"></span><br><span class="line">        out = <span class="variable language_">self</span>.conv2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line"></span><br><span class="line">        out = <span class="variable language_">self</span>.conv3(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn3(out)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="3-构建网络模型"><a href="#3-构建网络模型" class="headerlink" title="3.构建网络模型"></a>3.构建网络模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module): <span class="comment">#定义网络模型结构</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,block,blocks_num,num_classes=<span class="number">1000</span>,include_top=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.include_top = include_top</span><br><span class="line">        <span class="variable language_">self</span>.in_channel = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="variable language_">self</span>.in_channel,kernel_size=<span class="number">7</span>,stride=<span class="number">2</span>,padding=<span class="number">3</span>,bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(<span class="variable language_">self</span>.in_channel)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.layer1 = <span class="variable language_">self</span>._make_layer(block, <span class="number">64</span>, blocks_num[<span class="number">0</span>]) <span class="comment">#blocks_num为重复的残差块数量，一般这一层还不需要在初始位置进行下采样。</span></span><br><span class="line">        <span class="variable language_">self</span>.layer2 = <span class="variable language_">self</span>._make_layer(block, <span class="number">128</span>, blocks_num[<span class="number">1</span>], stride=<span class="number">2</span>)<span class="comment">#这一层开始需要进行下采样</span></span><br><span class="line">        <span class="variable language_">self</span>.layer3 = <span class="variable language_">self</span>._make_layer(block, <span class="number">256</span>, blocks_num[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.layer4 = <span class="variable language_">self</span>._make_layer(block, <span class="number">512</span>, blocks_num[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.include_top:</span><br><span class="line">            <span class="variable language_">self</span>.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))  <span class="comment">#添加了一个自适应平均池化层（Adaptive Average Pooling Layer），其输出尺寸为(1, 1)，高和宽变为1.</span></span><br><span class="line">            <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules(): <span class="comment">#对卷积层进行初始化操作</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, channel, block_num, stride=<span class="number">1</span></span>): <span class="comment">#生成各层残差块</span></span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> <span class="variable language_">self</span>.in_channel != channel * block.expansion: <span class="comment">#判断残差块初始输入时是否需要进行下采样</span></span><br><span class="line">       <span class="comment">#如果需要下采样，downsample 被初始化为一个顺序模型（nn.Sequential），其中包含一个1x1的卷积层（用于调整通道数和（或）进行下采样），以及一个批量归一化层（nn.BatchNorm2d）。这个顺序模型用于调整输入数据，使其能够与残差块的输出进行相加（残差网络的关键操作之一）。</span></span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(<span class="variable language_">self</span>.in_channel, channel * block.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(channel * block.expansion))</span><br><span class="line"></span><br><span class="line">        layers = [] <span class="comment">#方法创建一个空列表 layers，用于存储要构建的残差块</span></span><br><span class="line">        <span class="comment">#首先，将第一个残差块添加到 layers 列表中。这个残差块可能带有下采样层（如果 downsample 不为 None），且其输入通道数为 self.in_channel，输出通道数为 channel。</span></span><br><span class="line">        layers.append(block(<span class="variable language_">self</span>.in_channel,channel,downsample=downsample,stride=stride))</span><br><span class="line">        <span class="variable language_">self</span>.in_channel = channel * block.expansion <span class="comment">#更新通道数的变化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num): <span class="comment">#将剩余残差块的层进行添加</span></span><br><span class="line">            layers.append(block(<span class="variable language_">self</span>.in_channel,channel))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.bn1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.layer1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer4(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.include_top:</span><br><span class="line">            x = <span class="variable language_">self</span>.avgpool(x)</span><br><span class="line">            x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">            x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="4-定义各版本的Resnet网络"><a href="#4-定义各版本的Resnet网络" class="headerlink" title="4.定义各版本的Resnet网络"></a>4.定义各版本的Resnet网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>): <span class="comment">#本次训练选择的模型</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br></pre></td></tr></table></figure><h2 id="四-模型训练"><a href="#四-模型训练" class="headerlink" title="四.模型训练"></a>四.模型训练</h2><h3 id="1-使用迁移训练的方法，下载预训练权重"><a href="#1-使用迁移训练的方法，下载预训练权重" class="headerlink" title="1.使用迁移训练的方法，下载预训练权重"></a>1.使用迁移训练的方法，下载预训练权重</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net = resnet34()</span><br><span class="line"><span class="comment"># download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth</span></span><br><span class="line">model_weight_path = <span class="string">&quot;./resnet34-pre.pth&quot;</span> <span class="comment">#预训练的权重文件</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(model_weight_path), <span class="string">&quot;file &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(model_weight_path)</span><br><span class="line">net.load_state_dict(torch.load(model_weight_path, map_location=<span class="string">&#x27;cpu&#x27;</span>)) <span class="comment">#加载权重并将权重加载到模型中</span></span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line">in_channel = net.fc.in_features <span class="comment">#获取原始全连接层的输入特征维度（即最后一个卷积层输出的特征图数量）</span></span><br><span class="line">net.fc = nn.Linear(in_channel, <span class="number">5</span>).to(device) <span class="comment">#然后，创建一个新的全连接层nn.Linear(in_channel, 5)，其输入维度与原始全连接层相同，但输出维度为5，以匹配新的分类任务。最后，将这个新的全连接层赋值给net.fc，从而完成了模型的修改。</span></span><br></pre></td></tr></table></figure><h3 id="2-训练模型"><a href="#2-训练模型" class="headerlink" title="2.训练模型"></a>2.训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#通过列表推导式，从模型的参数中筛选出需要梯度的参数（即那些被训练的参数）。这通常排除了那些不参与训练的参数，如批量归一化层（BatchNorm）中的运行均值和方差。</span></span><br><span class="line">params = [p <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">optimizer = optim.Adam(params, lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">save_path = <span class="string">&#x27;resnet34-pre-again.pth&#x27;</span></span><br><span class="line">train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    train_bar = tqdm(train_loader, file=sys.stdout) <span class="comment">#创建进度条</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        logits = net(images.to(device))</span><br><span class="line">        loss = loss_function(logits, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                 epochs,</span><br><span class="line">                                                                 loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>() <span class="comment">#验证模式下的BN层将不起作用</span></span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))</span><br><span class="line">            <span class="comment"># loss = loss_function(outputs, test_labels)</span></span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">            val_bar.desc = <span class="string">&quot;valid epoch[&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                       epochs)</span><br><span class="line"></span><br><span class="line">    val_accurate = acc / val_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">          (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">        best_acc = val_accurate</span><br><span class="line">        torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="五-测试结果"><a href="#五-测试结果" class="headerlink" title="五.测试结果"></a>五.测试结果</h2><ul><li>如同前一章结果</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;深度学习第五章-ResNet网络&quot;&gt;&lt;a href=&quot;#深度学习第五章-ResNet网络&quot; class=&quot;headerlink&quot; title=&quot;深度学习第五章-ResNet网络&quot;&gt;&lt;/a&gt;深度学习第五章-ResNet网络&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本模型位于：E:&#92;python文件&#92;deep-learning-for-image-processing-master&#92;pytorch_classification&#92;Test5_resnet&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="深度学习基础" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习第四章-GoogleNet</title>
    <link href="http://example.com/2024/09/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%9B%9B%E7%AB%A0-GoogleNet/"/>
    <id>http://example.com/2024/09/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%9B%9B%E7%AB%A0-GoogleNet/</id>
    <published>2024-09-02T09:32:32.000Z</published>
    <updated>2024-09-13T08:09:59.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习第四章-GoogleNet"><a href="#深度学习第四章-GoogleNet" class="headerlink" title="深度学习第四章-GoogleNet"></a>深度学习第四章-GoogleNet</h1><blockquote><p>本模型位于：E:\python文件\deep-learning-for-image-processing-master\pytorch_classification\Test4_googlenet</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><ul><li><p>引入了Inception结构（融合不同尺度的特征信息）</p><ul><li><img src="https://s21.ax1x.com/2024/09/02/pAV3x41.png" alt="pAV3x41.png"></li></ul></li><li><p>使用1x1的卷积核进行降维以及映射处理 （减少模型参数）</p><ul><li><img src="https://s21.ax1x.com/2024/09/02/pAV8Z4I.png" alt="pAV8Z4I.png"></li></ul></li><li><p>添加两个辅助分类器帮助训练</p></li><li>丢弃全连接层，使用平均池化层（大大减少模型参数）</li></ul><p>图示：</p><p><img src="https://s21.ax1x.com/2024/09/03/pAV0PJg.jpg" alt="pAV0PJg.jpg"></p><h2 id="二-数据集-花分类数据集"><a href="#二-数据集-花分类数据集" class="headerlink" title="二.数据集-花分类数据集"></a>二.数据集-花分类数据集</h2><ul><li>如同前一章的内容</li></ul><h2 id="三-网络模型搭建"><a href="#三-网络模型搭建" class="headerlink" title="三.网络模型搭建"></a>三.网络模型搭建</h2><h3 id="1-普通卷积层模版"><a href="#1-普通卷积层模版" class="headerlink" title="1.普通卷积层模版"></a>1.普通卷积层模版</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv2d</span>(nn.Module): <span class="comment">#基本的卷积层模版</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv2d, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="2-inception模块模版"><a href="#2-inception模块模版" class="headerlink" title="2.inception模块模版"></a>2.inception模块模版</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module): <span class="comment">#定义inception模版</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="number">1</span>) <span class="comment">#分支一</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.branch2 = nn.Sequential( <span class="comment">#分支二</span></span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)   <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.branch3 = nn.Sequential( <span class="comment">#分支三</span></span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)   <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.branch4 = nn.Sequential( <span class="comment">#分支四</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment">#定义前向传播函数</span></span><br><span class="line">        branch1 = <span class="variable language_">self</span>.branch1(x)</span><br><span class="line">        branch2 = <span class="variable language_">self</span>.branch2(x)</span><br><span class="line">        branch3 = <span class="variable language_">self</span>.branch3(x)</span><br><span class="line">        branch4 = <span class="variable language_">self</span>.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>) <span class="comment">#进行合并</span></span><br></pre></td></tr></table></figure><h3 id="3-辅助分类器模版"><a href="#3-辅助分类器模版" class="headerlink" title="3.辅助分类器模版"></a>3.辅助分类器模版</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionAux</span>(nn.Module): <span class="comment">#定义辅助分类器模版</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionAux, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.averagePool = nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv = BasicConv2d(in_channels, <span class="number">128</span>, kernel_size=<span class="number">1</span>)  <span class="comment"># output[batch, 128, 4, 4]</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span></span><br><span class="line">        x = <span class="variable language_">self</span>.averagePool(x)</span><br><span class="line">        <span class="comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        <span class="comment"># N x 128 x 4 x 4</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="comment"># N x 2048</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x), inplace=<span class="literal">True</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">        <span class="comment"># N x num_classes</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="4-GooleNet网络"><a href="#4-GooleNet网络" class="headerlink" title="4.GooleNet网络"></a>4.GooleNet网络</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GoogLeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GoogLeNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = BasicConv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>) <span class="comment">#向上取整</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = BasicConv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv3 = BasicConv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool2 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.inception3a = Inception(<span class="number">192</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception3b = Inception(<span class="number">256</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool3 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.inception4a = Inception(<span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception4b = Inception(<span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception4c = Inception(<span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception4d = Inception(<span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception4e = Inception(<span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool4 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.inception5a = Inception(<span class="number">832</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.inception5b = Inception(<span class="number">832</span>, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.aux_logits:</span><br><span class="line">            <span class="variable language_">self</span>.aux1 = InceptionAux(<span class="number">512</span>, num_classes)</span><br><span class="line">            <span class="variable language_">self</span>.aux2 = InceptionAux(<span class="number">528</span>, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)) <span class="comment">#自适应池化层</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(<span class="number">0.4</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 112 x 112</span></span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv3(x)</span><br><span class="line">        <span class="comment"># N x 192 x 56 x 56</span></span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># N x 192 x 28 x 28</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception3a(x)</span><br><span class="line">        <span class="comment"># N x 256 x 28 x 28</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception3b(x)</span><br><span class="line">        <span class="comment"># N x 480 x 28 x 28</span></span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool3(x)</span><br><span class="line">        <span class="comment"># N x 480 x 14 x 14</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception4a(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> <span class="variable language_">self</span>.aux_logits:    <span class="comment"># 若处于训练模式则添加辅助分类器1</span></span><br><span class="line">            aux1 = <span class="variable language_">self</span>.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.inception4b(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception4c(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception4d(x)</span><br><span class="line">        <span class="comment"># N x 528 x 14 x 14</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> <span class="variable language_">self</span>.aux_logits:    <span class="comment"># 若处于训练模式则添加辅助分类器2</span></span><br><span class="line">            aux2 = <span class="variable language_">self</span>.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.inception4e(x)</span><br><span class="line">        <span class="comment"># N x 832 x 14 x 14</span></span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool4(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception5a(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = <span class="variable language_">self</span>.inception5b(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 7 x 7</span></span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.avgpool(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 1 x 1</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="comment"># N x 1000 (num_classes)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> <span class="variable language_">self</span>.aux_logits:   <span class="comment"># eval model lose this layer</span></span><br><span class="line">            <span class="keyword">return</span> x, aux2, aux1</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>): <span class="comment">#初始化参数函数</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="四-训练模型"><a href="#四-训练模型" class="headerlink" title="四.训练模型"></a>四.训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">net = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0003</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">save_path = <span class="string">&#x27;./googleNet.pth&#x27;</span></span><br><span class="line">train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        logits, aux_logits2, aux_logits1 = net(images.to(device))</span><br><span class="line">        loss0 = loss_function(logits, labels.to(device))</span><br><span class="line">        loss1 = loss_function(aux_logits1, labels.to(device))</span><br><span class="line">        loss2 = loss_function(aux_logits2, labels.to(device))</span><br><span class="line">        loss = loss0 + loss1 * <span class="number">0.3</span> + loss2 * <span class="number">0.3</span> <span class="comment">#总损失结合相应带权重的辅助分类器的损失</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                 epochs,</span><br><span class="line">                                                                 loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))  <span class="comment"># eval model only have last output layer</span></span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    val_accurate = acc / val_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">          (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">        best_acc = val_accurate</span><br><span class="line">        torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;深度学习第四章-GoogleNet&quot;&gt;&lt;a href=&quot;#深度学习第四章-GoogleNet&quot; class=&quot;headerlink&quot; title=&quot;深度学习第四章-GoogleNet&quot;&gt;&lt;/a&gt;深度学习第四章-GoogleNet&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本模型位于：E:&#92;python文件&#92;deep-learning-for-image-processing-master&#92;pytorch_classification&#92;Test4_googlenet&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="深度学习基础" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习基础第三章-VGG网络</title>
    <link href="http://example.com/2024/09/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E7%AB%A0-VGG%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2024/09/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E7%AB%A0-VGG%E7%BD%91%E7%BB%9C/</id>
    <published>2024-09-02T00:59:46.000Z</published>
    <updated>2024-09-13T08:09:10.110Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习基础第三章-VGG网络"><a href="#深度学习基础第三章-VGG网络" class="headerlink" title="深度学习基础第三章-VGG网络"></a>深度学习基础第三章-VGG网络</h1><blockquote><p>本模型存放于目录：</p><p>E:\python文件\deep-learning-for-image-processing-master\pytorch_classification\Test3_vggnet</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><p>特点：</p><ul><li>通过堆叠多个3x3的卷积核来替代大尺度卷积核（减少所需参数）</li><li>论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核 （拥有相同的感受野）</li></ul><p><img src="https://s21.ax1x.com/2024/09/02/pAVk8Ag.jpg" alt="pAVk8Ag.jpg"></p><h2 id="二-数据集-花分类数据集"><a href="#二-数据集-花分类数据集" class="headerlink" title="二.数据集-花分类数据集"></a>二.数据集-花分类数据集</h2><h3 id="1-定义预处理函数"><a href="#1-定义预处理函数" class="headerlink" title="1.定义预处理函数"></a>1.定义预处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data_transform = &#123; <span class="comment">#对训练集与测试集图片进行预处理</span></span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment">#裁剪图片尺寸</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(), <span class="comment">#对图片进行随机翻转</span></span><br><span class="line">                                 transforms.ToTensor(), <span class="comment">#转换为张量形式</span></span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]), <span class="comment">#标准化数据</span></span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br></pre></td></tr></table></figure><h3 id="2-从磁盘中读取数据集"><a href="#2-从磁盘中读取数据集" class="headerlink" title="2.从磁盘中读取数据集"></a>2.从磁盘中读取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;../..&quot;</span>))  <span class="comment"># get data root path</span></span><br><span class="line">image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># flower data set path</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br></pre></td></tr></table></figure><h3 id="3-保存各类比的字典索引"><a href="#3-保存各类比的字典索引" class="headerlink" title="3.保存各类比的字典索引"></a>3.保存各类比的字典索引</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br></pre></td></tr></table></figure><h3 id="4-加载训练集与测试集"><a href="#4-加载训练集与测试集" class="headerlink" title="4.加载训练集与测试集"></a>4.加载训练集与测试集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                              num_workers=nw)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                       val_num))</span><br></pre></td></tr></table></figure><h2 id="三-网络模型搭建"><a href="#三-网络模型搭建" class="headerlink" title="三.网络模型搭建"></a>三.网络模型搭建</h2><h3 id="1-根据版本提供相应的网络结构"><a href="#1-根据版本提供相应的网络结构" class="headerlink" title="1.根据版本提供相应的网络结构"></a>1.根据版本提供相应的网络结构</h3><ul><li>由于vgg网络有很多版本，因此通过字典保存相应不同的结构</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#字典文件保存各网络模型的配置文件 （特征提取部分）</span></span><br><span class="line">cfgs = &#123; </span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>): <span class="comment">#根据字典的列表得到相应的网络模型结构</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg: <span class="comment">#遍历列表</span></span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>: <span class="comment">#此时为最大池化层</span></span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">#其他为卷积层与激活层</span></span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers) <span class="comment">#最终返回网络模型</span></span><br></pre></td></tr></table></figure><h3 id="2-定义网络模型"><a href="#2-定义网络模型" class="headerlink" title="2.定义网络模型"></a>2.定义网络模型</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.features = features <span class="comment">#定义特征提取层</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(  <span class="comment">#定义全连接层</span></span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights: <span class="comment">#判断是否初始化参数</span></span><br><span class="line">            <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment">#前向传播过程</span></span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = <span class="variable language_">self</span>.features(x) <span class="comment">#特征提取层</span></span><br><span class="line">        <span class="comment"># N x 512 x 7 x 7</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>) <span class="comment">#展平</span></span><br><span class="line">        <span class="comment"># N x 512*7*7</span></span><br><span class="line">        x = <span class="variable language_">self</span>.classifier(x) <span class="comment">#全连接分类层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>): <span class="comment">#初始化参数函数</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules(): <span class="comment">#遍历所有层</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight) <span class="comment">#使用xavier方法对卷积层参数初始化</span></span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>) <span class="comment">#若采用偏置，将其初始化为0</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="comment"># nn.init.normal_(m.weight, 0, 0.01)</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="3-实例化网络模型（使用vgg16）"><a href="#3-实例化网络模型（使用vgg16）" class="headerlink" title="3.实例化网络模型（使用vgg16）"></a>3.实例化网络模型（使用vgg16）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, **kwargs</span>): <span class="comment">#实例化模型</span></span><br><span class="line">    <span class="keyword">assert</span> model_name <span class="keyword">in</span> cfgs, <span class="string">&quot;Warning: model number &#123;&#125; not in cfgs dict!&quot;</span>.<span class="built_in">format</span>(model_name)</span><br><span class="line">    cfg = cfgs[model_name]</span><br><span class="line">    model = VGG(make_features(cfg), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h2 id="四·训练模型"><a href="#四·训练模型" class="headerlink" title="四·训练模型"></a>四·训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">model_name = <span class="string">&quot;vgg16&quot;</span> <span class="comment">#使用vgg16版本</span></span><br><span class="line">net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">save_path = <span class="string">&#x27;./&#123;&#125;Net.pth&#x27;</span>.<span class="built_in">format</span>(model_name) <span class="comment">#设置保存参数文件的路径</span></span><br><span class="line">train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()  <span class="comment">#将网络设置为训练模式，此时dropout层将发挥作用</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    train_bar = tqdm(train_loader, file=sys.stdout) <span class="comment">#利用了 tqdm 库来在训练过程中添加一个进度条，使得用户可以直观地看到数据加载和训练的进度</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># 更新 train_bar（即之前通过 tqdm 包装的 train_loader 迭代器）的描述（description）字段。这个描述字段通常用于在进度条旁边显示额外的信息，比如当前的训练轮次（epoch）、总轮次、以及某个指标（如损失值）的当前值。</span></span><br><span class="line">        train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                 epochs,</span><br><span class="line">                                                                 loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    val_accurate = acc / val_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">          (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">        best_acc = val_accurate</span><br><span class="line">        torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="五-测试模型效果"><a href="#五-测试模型效果" class="headerlink" title="五.测试模型效果"></a>五.测试模型效果</h2><ul><li>代码与AlnexNet部分一致</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img_path = <span class="string">&quot;../tulip.jpg&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line">json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = vgg(model_name=<span class="string">&quot;vgg16&quot;</span>, num_classes=<span class="number">5</span>).to(device)</span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">weights_path = <span class="string">&quot;./vgg16Net.pth&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line">model.load_state_dict(torch.load(weights_path, map_location=device))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                             predict[predict_cla].numpy())</span><br><span class="line">plt.title(print_res)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                              predict[i].numpy()))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;深度学习基础第三章-VGG网络&quot;&gt;&lt;a href=&quot;#深度学习基础第三章-VGG网络&quot; class=&quot;headerlink&quot; title=&quot;深度学习基础第三章-VGG网络&quot;&gt;&lt;/a&gt;深度学习基础第三章-VGG网络&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本模型存放于目录：&lt;/p&gt;
&lt;p&gt;E:&#92;python文件&#92;deep-learning-for-image-processing-master&#92;pytorch_classification&#92;Test3_vggnet&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="深度学习基础" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习第二章-AlexNet</title>
    <link href="http://example.com/2024/08/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0-AlexNet/"/>
    <id>http://example.com/2024/08/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0-AlexNet/</id>
    <published>2024-08-30T03:34:33.000Z</published>
    <updated>2024-09-19T08:59:33.275Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习第二章-AlexNet搭建"><a href="#深度学习第二章-AlexNet搭建" class="headerlink" title="深度学习第二章-AlexNet搭建"></a>深度学习第二章-AlexNet搭建</h1><blockquote><p>本模型存放于目录：</p><p>E:\python文件\deep-learning-for-image-processing-master\tensorflow_classification\Test2_alexnet</p></blockquote><span id="more"></span><h2 id="一-模型介绍"><a href="#一-模型介绍" class="headerlink" title="一.模型介绍"></a>一.模型介绍</h2><ul><li>首次利用GPU进行网络加速训练。</li><li>使用了ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数。</li><li>使用了LRN局部响应归一化。</li><li>在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。<ul><li><img src="https://s21.ax1x.com/2024/08/30/pAAq9vn.png" alt="pAAq9vn.png"></li></ul></li></ul><h2 id="二-数据集-花分类数据集"><a href="#二-数据集-花分类数据集" class="headerlink" title="二.数据集-花分类数据集"></a>二.数据集-花分类数据集</h2><h3 id="1-定义预处理函数"><a href="#1-定义预处理函数" class="headerlink" title="1.定义预处理函数"></a>1.定义预处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data_transform = &#123; <span class="comment">#处理训练集与测试集的方法</span></span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment">#随机裁剪</span></span><br><span class="line">                                     transforms.RandomHorizontalFlip(), <span class="comment">#随机翻转</span></span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),  <span class="comment"># cannot 224, must (224, 224)</span></span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-从磁盘中读取数据集"><a href="#2-从磁盘中读取数据集" class="headerlink" title="2.从磁盘中读取数据集"></a>2.从磁盘中读取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;../..&quot;</span>))  <span class="comment"># 计算数据集的根目录，从当前目录向上回溯两级目录</span></span><br><span class="line">image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># 从根目录下找到数据集所在的目录</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path) <span class="comment">#检查图片路径是否存在，若不存在，则抛出一个异常</span></span><br><span class="line">train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])  <span class="comment">#从指定的路径加载，创建训练数据集的对象，并使用预处理方法</span></span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset) <span class="comment">#计算训练集中的样本总数</span></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>), </span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>]) <span class="comment">#从指定的路径加载，创建测试数据集的对象，并使用预处理方法</span></span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset) <span class="comment">#计算测试集中的样本总数</span></span><br></pre></td></tr></table></figure><h3 id="3-保存各类别的字典索引"><a href="#3-保存各类别的字典索引" class="headerlink" title="3.保存各类别的字典索引"></a>3.保存各类别的字典索引</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx  <span class="comment">#保存一个字典文件,将每个类别的名称映射到该类别的索引</span></span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items()) <span class="comment">#创建一个逆映射，将每个类别的索引映射到该类别的名称</span></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>) <span class="comment">#将cla_dict字典转换成JSON格式的字符串，通过indent=4参数设置缩进来提高可读性</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file: <span class="comment">#保存到指定的JSON文件中</span></span><br><span class="line">    json_file.write(json_str)</span><br></pre></td></tr></table></figure><h3 id="4-加载训练集与测试集"><a href="#4-加载训练集与测试集" class="headerlink" title="4.加载训练集与测试集"></a>4.加载训练集与测试集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, <span class="comment">#加载数据集</span></span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset, <span class="comment">#加载测试集</span></span><br><span class="line">                                              batch_size=<span class="number">4</span>, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                       val_num))</span><br></pre></td></tr></table></figure><h2 id="三-网络模型搭建"><a href="#三-网络模型搭建" class="headerlink" title="三.网络模型搭建"></a>三.网络模型搭建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>): <span class="comment">#设置类别个数，以及是否初始化权重</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.features = nn.Sequential( <span class="comment">#将各层打包为一个模块, input[3, 224, 224]</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),  <span class="comment"># output[48, 55, 55]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[48, 27, 27]</span></span><br><span class="line">            nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),           <span class="comment"># output[128, 27, 27]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[128, 6, 6]</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>), <span class="comment">#50%概率使全连接层失活</span></span><br><span class="line">            nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            <span class="variable language_">self</span>._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.features(x)</span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>) <span class="comment">#展平</span></span><br><span class="line">        x = <span class="variable language_">self</span>.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>): <span class="comment">#参数的初始化</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules(): <span class="comment">#遍历模型的所有模块，判断模块类型并进行权重初始化</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="四-训练模型"><a href="#四-训练模型" class="headerlink" title="四.训练模型"></a>四.训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">net = AlexNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span> <span class="comment">#设置保存参数文件的路径</span></span><br><span class="line">best_acc = <span class="number">0.0</span> <span class="comment">#设置最佳准确率</span></span><br><span class="line">train_steps = <span class="built_in">len</span>(train_loader) <span class="comment">#保存训练集的长度</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs): </span><br><span class="line">    <span class="comment"># 训练</span></span><br><span class="line">    net.train() <span class="comment">#将网络设置为训练模式，此时dropout层将发挥作用 </span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    train_bar = tqdm(train_loader, file=sys.stdout) <span class="comment">#利用了 tqdm 库来在训练过程中添加一个进度条，使得用户可以直观地看到数据加载和训练的进度</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"><span class="comment"># 更新 train_bar（即之前通过 tqdm 包装的 train_loader 迭代器）的描述（description）字段。这个描述字段通常用于在进度条旁边显示额外的信息，比如当前的训练轮次（epoch）、总轮次、以及某个指标（如损失值）的当前值。</span></span><br><span class="line">        train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                 epochs,</span><br><span class="line">                                                                 loss)</span><br><span class="line">        net.<span class="built_in">eval</span>() <span class="comment">#设置为验证模式，此时dropout层效果失效</span></span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader, file=sys.stdout) <span class="comment">#进度条显示</span></span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %  <span class="comment">#每一次迭代后，打印相关信息</span></span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate)) </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc: <span class="comment">#保存历史最优准确率，并将该准确率下的参数情况传入到指定文件中</span></span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><p>训练结果如下：</p><p><img src="https://s21.ax1x.com/2024/08/31/pAEsrFK.png" alt="pAEsrFK.png"></p><h2 id="五-测试模型效果"><a href="#五-测试模型效果" class="headerlink" title="五.测试模型效果"></a>五.测试模型效果</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img_path = <span class="string">&quot;../tulip.jpg&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">plt.imshow(img) <span class="comment">#展示图片</span></span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img) <span class="comment">#对图片进行预处理</span></span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>) <span class="comment">#添加一个维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line">json_path = <span class="string">&#x27;./class_indices.json&#x27;</span> </span><br><span class="line"><span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f: <span class="comment">#读取类别映射文件，并解码</span></span><br><span class="line">    class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = AlexNet(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">weights_path = <span class="string">&quot;./AlexNet.pth&quot;</span> </span><br><span class="line"><span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line">model.load_state_dict(torch.load(weights_path)) <span class="comment">#读取之前保存的参数文件</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment">#设置为验证模式</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img.to(device))).cpu() <span class="comment">#输出，并移除张量中所有大小为1的维度</span></span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>) <span class="comment">#使用softmax将输出中的张量变成概率分布形式</span></span><br><span class="line">    predict_cla = torch.argmax(predict).numpy() <span class="comment">#找到其中最大的值</span></span><br><span class="line"></span><br><span class="line">print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)], <span class="comment">#返回预测的类别名称与预测概率</span></span><br><span class="line">                                             predict[predict_cla].numpy())</span><br><span class="line">plt.title(print_res) <span class="comment">#展示图片与预测结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)): <span class="comment">#遍历显示所用的预测结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                              predict[i].numpy()))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>效果如图所示：</p><ul><li><p><img src="https://s21.ax1x.com/2024/08/31/pAEyAmR.png" alt="pAEyAmR.png"></p></li><li><p><img src="https://s21.ax1x.com/2024/08/31/pAEySYT.png" alt="pAEySYT.png"></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;深度学习第二章-AlexNet搭建&quot;&gt;&lt;a href=&quot;#深度学习第二章-AlexNet搭建&quot; class=&quot;headerlink&quot; title=&quot;深度学习第二章-AlexNet搭建&quot;&gt;&lt;/a&gt;深度学习第二章-AlexNet搭建&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本模型存放于目录：&lt;/p&gt;
&lt;p&gt;E:&#92;python文件&#92;deep-learning-for-image-processing-master&#92;tensorflow_classification&#92;Test2_alexnet&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="深度学习基础" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>深度学习第一章-LeNet搭建</title>
    <link href="http://example.com/2024/08/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E7%AB%A0-LeNET%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2024/08/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E7%AB%A0-LeNET%E6%90%AD%E5%BB%BA/</id>
    <published>2024-08-29T11:51:21.000Z</published>
    <updated>2024-09-19T09:01:29.394Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习第一章-LeNet搭建"><a href="#深度学习第一章-LeNet搭建" class="headerlink" title="深度学习第一章-LeNet搭建"></a>深度学习第一章-LeNet搭建</h1><blockquote><p>基于PyTorch框架，本模型存放于目录：</p><p>E:\python文件\deep-learning-for-image-processing-master\pytorch_classification\Test1_official_demo</p><p>经卷积后的矩阵尺寸大小计算公式为：</p><p>N=(W-F+2P)/S+1</p><ul><li>输入图片大小W×W</li><li>Filter大小FXF</li><li>步长S</li><li>padding的像素数P</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure></blockquote><span id="more"></span><h2 id="一-设置运行设备：GPU运行"><a href="#一-设置运行设备：GPU运行" class="headerlink" title="一.设置运行设备：GPU运行"></a>一.设置运行设备：GPU运行</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) <span class="comment">#确认运行设备为GPU</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;定义了一个名字为Net的网络模型&#x27;&#x27;&#x27;</span></span><br><span class="line">net = Net().to(device) <span class="comment">#实例化一个网络模型,并将网络模型在GPU上运算</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;定义训练方法&#x27;&#x27;&#x27;</span></span><br><span class="line">data,target=data.to(device),target.to(device) <span class="comment">#将数据集添加到GPU上运算</span></span><br></pre></td></tr></table></figure><h2 id="二-下载数据集-CIFAR10"><a href="#二-下载数据集-CIFAR10" class="headerlink" title="二.下载数据集-CIFAR10"></a>二.下载数据集-CIFAR10</h2><p>It has the classes:’airplane’,’automobile’,’bird’,’cat’,’deer’,dog’,’frog’,’horse’, ship’,’truck’.</p><p>The images in CIFAR-10 are of size 3x32x32</p><h3 id="1-定义预处理函数"><a href="#1-定义预处理函数" class="headerlink" title="1.定义预处理函数"></a>1.定义预处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose( <span class="comment">#预处理函数</span></span><br><span class="line">        [transforms.ToTensor(), <span class="comment">#将图片数据转换为张量</span></span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]) <span class="comment">#进行标准化,分别为均值与标准差，              #output[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br></pre></td></tr></table></figure><h3 id="2-分别下载训练集，测试集并加载"><a href="#2-分别下载训练集，测试集并加载" class="headerlink" title="2.分别下载训练集，测试集并加载"></a>2.分别下载训练集，测试集并加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 50000张训练图片</span></span><br><span class="line"><span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,  <span class="comment">#下载训练集集</span></span><br><span class="line">                                         download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,  <span class="comment">#加载训练集</span></span><br><span class="line">                                           shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 10000张验证图片</span></span><br><span class="line"><span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">5000</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="3-设置一个数据迭代器"><a href="#3-设置一个数据迭代器" class="headerlink" title="3.设置一个数据迭代器"></a>3.设置一个数据迭代器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val_data_iter = <span class="built_in">iter</span>(val_loader) <span class="comment">#将数据转换为迭代器</span></span><br><span class="line">val_image, val_label = <span class="built_in">next</span>(val_data_iter) <span class="comment">#设置迭代器下的输入与输出</span></span><br><span class="line">val_image, val_label = val_image.to(device), val_label.to(device) <span class="comment">#移到GPU</span></span><br></pre></td></tr></table></figure><h2 id="三-定义网络模型"><a href="#三-定义网络模型" class="headerlink" title="三.定义网络模型"></a>三.定义网络模型</h2><ul><li><strong>张量的序列：（batch,channel,height,width）</strong></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>): <span class="comment">#网络模型搭建</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, <span class="variable language_">self</span>).__init__() <span class="comment">#必要的初识化函数</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>) </span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment">#前向传播设置</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5),此处在进入全连接层时，需要将张量展平</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="四-训练网络模型"><a href="#四-训练网络模型" class="headerlink" title="四.训练网络模型"></a>四.训练网络模型</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">net = LeNet().to(device) <span class="comment">#实例化神经网络模型</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss() <span class="comment">#设置损失函数为交叉熵函数</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>) <span class="comment">#设置参数更新方法</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line">    </span><br><span class="line">    running_loss = <span class="number">0.0</span> <span class="comment">#损失率累加</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        inputs, labels = data <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device) <span class="comment">#移到GPU</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()  <span class="comment">#梯度清零以防止梯度累计</span></span><br><span class="line">        outputs = net(inputs) <span class="comment">#输入数据训练，得到预测值</span></span><br><span class="line">        loss = loss_function(outputs, labels) <span class="comment">#计算损失值</span></span><br><span class="line">        loss.backward()  <span class="comment">#根据损失值进行反向传播，计算梯度</span></span><br><span class="line">        optimizer.step() <span class="comment">#更新参数</span></span><br><span class="line">        running_loss += loss.item() <span class="comment">#进行损失值累加</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():  <span class="comment">#在验证过程中不要计算损失梯度</span></span><br><span class="line">                outputs = net(val_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = torch.eq(predict_y, val_label).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="https://s21.ax1x.com/2024/08/31/pAEswe1.png" alt="pAEswe1.png"></p><h2 id="五-保存训练完成之后的模型参数文件"><a href="#五-保存训练完成之后的模型参数文件" class="headerlink" title="五.保存训练完成之后的模型参数文件"></a>五.保存训练完成之后的模型参数文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path) </span><br></pre></td></tr></table></figure><h2 id="六-使用任意图片测试分类效果"><a href="#六-使用任意图片测试分类效果" class="headerlink" title="六.使用任意图片测试分类效果"></a>六.使用任意图片测试分类效果</h2><ul><li>此处在文件夹里面添加了一个文件名为“1.jpg”的飞机图片</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)), <span class="comment">#将图像分辨率改变</span></span><br><span class="line">     transforms.ToTensor(), <span class="comment">#将图像数据变为张量形式</span></span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]) <span class="comment">#标准化图像</span></span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>)) <span class="comment">#载入参数文件</span></span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W] #调整图像</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W] #增添一个维度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;深度学习第一章-LeNet搭建&quot;&gt;&lt;a href=&quot;#深度学习第一章-LeNet搭建&quot; class=&quot;headerlink&quot; title=&quot;深度学习第一章-LeNet搭建&quot;&gt;&lt;/a&gt;深度学习第一章-LeNet搭建&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;基于PyTorch框架，本模型存放于目录：&lt;/p&gt;
&lt;p&gt;E:&#92;python文件&#92;deep-learning-for-image-processing-master&#92;pytorch_classification&#92;Test1_official_demo&lt;/p&gt;
&lt;p&gt;经卷积后的矩阵尺寸大小计算公式为：&lt;/p&gt;
&lt;p&gt;N=(W-F+2P)/S+1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入图片大小W×W&lt;/li&gt;
&lt;li&gt;Filter大小FXF&lt;/li&gt;
&lt;li&gt;步长S&lt;/li&gt;
&lt;li&gt;padding的像素数P&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.nn &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.optim &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torchvision.transforms &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; PIL &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="硕士阶段学习笔记(入门阶段)" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/"/>
    
    <category term="模型" scheme="http://example.com/categories/%E7%A1%95%E5%A3%AB%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="深度学习基础" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>MRI超分辨率-初见</title>
    <link href="http://example.com/2024/08/23/MRI%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E5%88%9D%E8%A7%81/"/>
    <id>http://example.com/2024/08/23/MRI%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87-%E5%88%9D%E8%A7%81/</id>
    <published>2024-08-23T03:04:29.000Z</published>
    <updated>2024-10-15T09:40:04.098Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MRI超分辨率-初见"><a href="#MRI超分辨率-初见" class="headerlink" title="MRI超分辨率-初见"></a>MRI超分辨率-初见</h1><blockquote><p>参考文献：<a href="https://kns.cnki.net/kcms2/article/abstract?v=MBTPQIn9ZKHwJKNtmL5eu7ZFUIb7_nCdbjKrKYFXDX6PgaFW9ljQXL28jn2X8Tj-Fz9N66Pw2G-7sZKyd45rdpBDmk8uzaCVlHLs8CrT9djwL1vEujSi471jNVkdUlEig7F0PF8coO7qxlD8DotHOeCi2IyxGNPoEJVYW6xeQwx-YP19kSVBS-Q5b6eyw2jueAmJScamN0AezEUaa59P5Xn_eLIAQ_aMAfpnTy3Ubv6W8vCSIDYLpFbFr3BReGkWAXsly07QS-ieh65-u_RMjowiogGdel8q&amp;uniplatform=NZKPT&amp;language=CHS">单幅3D磁共振图像超分辨率算法研究</a></p></blockquote><span id="more"></span><h2 id="一-研究背景"><a href="#一-研究背景" class="headerlink" title="一.研究背景"></a>一.研究背景</h2><h3 id="1-MRI图像存在的问题"><a href="#1-MRI图像存在的问题" class="headerlink" title="1.MRI图像存在的问题"></a>1.MRI图像存在的问题</h3><ul><li><p>MRI图像的质量受到信噪比（SNR，Signal to Noise Ratio）、分辨率和扫描时间等多方面因素影响</p></li><li><p>层厚的概念</p><ul><li><blockquote><p>层厚的定义：表示成像层面在三维空间中的厚度。在MRI扫描中，由于技术的限制，无法直接获取无限薄的层面，因此层面的选取在实际操作中都是有一定厚度的。</p></blockquote></li></ul></li><li><p>层厚对图片质量的影响</p><ul><li>分辨率：层厚直接影响到MRI图像的分辨率。层厚越小，图像的分辨率越高，能够显示更细微的解剖结构。但过小的层厚会导致扫描时间增加，且可能因信号强度不足而影响图像质量。</li><li>信噪比：层厚还影响图像的信噪比。层厚较小时，每个体素内质子数量减少，产生的信号强度降低，可能导致信噪比下降。而适当增加层厚，可以提高信号强度，改善图像质量。</li><li>扫描时间：层厚越大，扫描时间越短</li></ul></li></ul><h3 id="2-优化MRI图像的方法—-超分辨率"><a href="#2-优化MRI图像的方法—-超分辨率" class="headerlink" title="2.优化MRI图像的方法—-超分辨率"></a>2.优化MRI图像的方法—-超分辨率</h3><ul><li>定义：超分辨率（SR，Super-resolution）算法是一种从软件层面提高 MRI 图像分辨率的有效方案。从软件方面提升 MRI 图像分辨率的方式具有良好的可移植性与扩展性。</li><li>MRI 图像超分辨率问题是典型的病态逆问题，其主要目的是从一幅或多幅低分辨率MRI图像中重建出对应的高分辨率 MRI 图像</li></ul><h3 id="3-超分辨率的不同研究类别"><a href="#3-超分辨率的不同研究类别" class="headerlink" title="3.超分辨率的不同研究类别"></a>3.超分辨率的不同研究类别</h3><ul><li><p>静态对象与动态对象</p></li><li><p>单幅低分辨率图像和多幅低分辨率图像</p><ul><li><p>多幅的方法需要将多幅低分辨率的 MRI 图像进行配准与重采样</p></li><li><p>配准概念</p><blockquote><ul><li><p>配准（Image Registration）也被称为图像匹配或图像相关，是图像处理中的一个关键步骤。它旨在将两幅或多幅图像中的相应部分进行空间上的对齐，使它们在同一坐标系下具有相同的空间位置。这个过程要求相邻图像之间有一部分在逻辑上是相同的，即相邻的图像有一部分反映了同一目标区域，这是实现图像配准的基本条件。</p><p>配准通常包括两个主要步骤：空间变换和灰度变换。</p><ul><li><strong>空间变换</strong>：将图像像素的坐标从一个坐标系映射到另一个新的坐标系中，通常使用多项式函数或其他变换模型来描述这种映射关系。对于具有全局性形变的图像配准问题，非线性变换（如将直线映射为曲线）是一个常用的选择。</li><li><strong>灰度变换</strong>：在空间变换完成后，对变换后的图像值进行重新赋值，以确保图像在视觉上保持一致性和连续性。这一步骤与重采样紧密相关。</li></ul></li></ul></blockquote></li><li><p>重采样概念</p><blockquote><ul><li><p>重采样（Resampling）是指根据一类象元（像素）的信息内插出另一类象元信息的过程。在遥感、图像处理及GIS等领域中，重采样常用于从高分辨率图像中提取低分辨率图像，或者对图像进行几何校正、尺寸调整等操作。</p><p>重采样的方法多种多样，常见的包括最邻近法、双线性内插法和三次卷积内插法等。</p><ul><li><strong>最邻近法</strong>：将距离某像元位置最近的像元值作为该像元的新值。这种方法简单高效，但可能会产生半个像元大小的位移，计算不够精确。</li><li><strong>双线性内插法</strong>：通过取采样点到周围4个邻域像元的距离加权来计算其新值。这种方法通常比最邻近法产生的结果更加光滑，但可能会改变原始栅格值，丢失一些局部细微的特征。</li><li><strong>三次卷积内插法</strong>：通过增加参与内插计算的邻近像元的数目来提高重采样的精度。这种方法能够增强图像的细节表现，但计算量较大，且同样会改变原始栅格值。</li></ul></li></ul></blockquote></li></ul></li></ul><ul><li><p>频域与空间域：空间域中处理更优</p></li><li><p>各向同性与各向异性</p><ul><li>各向同性 3D MRI 图像超分辨率方法主要目标是提高 3D MRI 图像所有层面的分辨率，使其整体的分辨率更高。</li><li>各向异性：由于成像技术的限制，图像在不同方向上的分辨率往往是不均等的。这种在不同方向上分辨率存在差异的现象被称为“各向异性”。<ul><li>对于3D MRI图像来说，这种各向异性主要体现在层面选择方向（通常指的是沿着成像序列中切片堆叠的方向，即深度或厚度方向）与层面内方向（即每个切片内部的二维空间，包括宽度和高度方向）的分辨率差异上</li><li>在3D MRI图像中，沿着层面选择方向（深度或厚度）的像素（或体素）尺寸通常比层面内方向的像素尺寸要大，因此在这个方向上的图像细节相对较少，分辨率较低。</li><li>相比之下，层面内的切片包含了更多的细节信息，即高频信息（图像中变化较快的部分，如边缘、纹理等），这些信息的分辨率较高。</li><li>对于各向异性的3D MRI图像，超分辨率方法的主要目标是提高层面选择方向的分辨率，以减小或消除与层面内方向分辨率之间的差异。</li><li>通过这种方法，可以使得3D MRI图像在所有方向上的分辨率更加均匀，从而提高图像的整体质量和可用性。</li></ul></li></ul><h3 id="4-超分辨率的研究算法分类"><a href="#4-超分辨率的研究算法分类" class="headerlink" title="4.超分辨率的研究算法分类"></a>4.超分辨率的研究算法分类</h3><ul><li>基于插值的超分辨率算法<ul><li>方法：预定义一个变换函数，并利用已知的 MRI 图像像素或体素信息来对未知的像素或体素信息进行拟合。</li><li>该类算法虽然简单高效，但也存在着一定的缺陷，如插值后的图像具有比较明显的块效应、振铃效应与锯齿效应。</li></ul></li><li>基于重构的超分辨算法<ul><li>方法：从图像的降质退化模型出发，对高分辨率 MRI 图像退化到低分辨率 MRI 图像的过程进行建模（运动变换、模糊及噪声等），而后求解成像系统的逆过程。这种算法会提取低分辨率图像中的关键信息，并通过先验知识来约束高分辨率图像的的重建过程。</li><li>该类算法在重建系数较小时能达到令人满意的结果，但当重建系数较大时，很难获得合适的人工定义的先验知识与正则参数，因此难以保证超分辨率图像的质量。</li></ul></li><li>基于学习的超分辨率算法（✪）<ul><li>从大量的训练数据中学习高分辨率图像和低分辨率图像之间某种映射关系，并根据学习到的映射关系提高目标低分辨率图像的分辨率</li><li>分类<ul><li>基于浅层学习的超分辨率算法<ul><li>将整个超分辨率过程分为样本库的建立（特征提取）、特征映射（学习与搜索）、高频信息重建三个阶段，且每个阶段独立优化</li></ul></li><li>基于深度学习的超分辨率算法（✪）<ul><li>直线结构    <ul><li>指整个图像超分辨率网络结构是一个不包含任何跳接或分支的线性结构，即模型是由多个卷积层依次堆叠组成。该类结构具有简单、效率高等特点</li><li>使用线性结构的算法具有结构简单、重建速度快等优点，但同时存在收敛速度慢，训练过程中容易产生梯度消失与爆炸的问题</li></ul></li><li>跳接结构<ul><li>是指在线性结构的基础上加入卷积层之间的跨层跳接。跳接结构通过信息跨层传递的方式来缓解梯度消失与爆炸问题，同时为设计更深的网络结构提供可能。</li><li>残差跳接是将不同卷积层的特征进行对应通道的相加，即融合后的特征图保持通道数量不变，但特征图内容发生了变化。</li><li>通道连接跳接则是将不同卷积层的特征以通道方向进行拼接，融合后的特征图不变，但通道数量增加。</li></ul></li><li>递归结构<ul><li>将卷积层的输出继续作为该层卷积的输入，由于多次卷积操作的参数是一样的，该种递归卷积的方式可以有效地减少网络的参数数量。</li></ul></li><li>生成对抗结构<ul><li>采用的是一种博弈论的思想，该类模型由生成器与鉴别器两部分组成。生成器生成高分辨率图像，鉴别器区分真实的高分辨率图像与生成器生成的高分辨率图像。</li></ul></li><li>注意力结构<ul><li>注意力结构则是利用人类视觉中的注意力机制，对网络所提取的特征进行重新校准</li><li>注意力结构可以有效的调整特征通道或特征本身不同区域的权重，专注于模型中对最终结果贡献大的特征或特征区域</li></ul></li></ul></li><li>图示<ul><li><img src="https://s21.ax1x.com/2024/08/27/pAk4BcT.png" alt="pAk4BcT.png"></li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="二-基础知识（基于CNN的算法）"><a href="#二-基础知识（基于CNN的算法）" class="headerlink" title="二.基础知识（基于CNN的算法）"></a>二.基础知识（基于CNN的算法）</h2><h3 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1.数据预处理"></a>1.数据预处理</h3><ul><li><p><img src="https://s21.ax1x.com/2024/08/27/pAk4DjU.png" alt="pAk4DjU.png"></p></li><li><h4 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h4><ul><li>需将 MRI 图像的体素值归一化到相同的取值范围（如[0，1]），使优化时大部分位置的梯度方向近似于最优搜索方向，从而提高训练效率。否则会导致模型收敛慢。</li></ul></li><li><h4 id="模拟退化"><a href="#模拟退化" class="headerlink" title="模拟退化"></a>模拟退化</h4><ul><li>首先将高分辨率 MRI 图像经过傅里叶变换至 k 空间。<ul><li>k 空间中央部分包含的数据具有高信号振幅和低分辨率，决定 MRI 图像的对比度</li><li>边缘的部分具有低信号振幅和高分辨率，决定 MRI 图像的解剖细节。</li></ul></li><li>k 空间的模拟退化中，本文仅保留中央部分的信息。根据超分辨率重建系数对 k 空间数据的边缘部分进行截断处理，并用零填充的方式对截断的部分进行填充。随后对填充过的 k 空间数据进行傅里叶逆变换，将其转化至图像空间。</li><li>最后，对 MRI 图像进行空间下采样至目标大小，生成最终的低分辨率 MRI 图像</li><li>傅里叶变换：将图像从空间域（spatial domain）转换到频率域（frequency domain）。这种转换使我们能够分析图像的频率成分，即图像中不同模式的强度或频率。</li><li><img src="https://s21.ax1x.com/2024/08/27/pAk4f9x.png" alt="pAk4f9x.png"></li></ul></li><li><h4 id="块切分"><a href="#块切分" class="headerlink" title="块切分"></a>块切分</h4><ul><li>在构建训练集时将整幅 3D MRI 图像切割成固定大小的 3D MRI 图像块。本文采用固定步长的滑动窗口方式来对图像进行切割，保证相邻图像块既有相似重叠区域又有不同区域，从而提升训练数据的 数量与训练数据的丰富度。</li></ul></li></ul><h3 id="2-模型框架"><a href="#2-模型框架" class="headerlink" title="2.模型框架"></a>2.模型框架</h3><ul><li><p><img src="https://s21.ax1x.com/2024/08/27/pAk4h36.png" alt="pAk4h36.png"></p></li><li><p>预采样模型框架</p><ul><li>该类框架需将低分辨率图像在输入网络前用传统的插值方法（线性插值法或双三次插值法）上采样到目标高分辨率图像的大小，而后再用 CNN 模型重建出高质量的纹理细节， 进一步提高图像的质量。</li></ul></li><li><p>后上采样模型框架</p><ul><li>该类模型框架以原始的低分辨率图像作为输入，将上采样任务放在模型的尾端。该类模型直接从原始低分辨率图像中提取特征并学习数据的原始分布，用可学习的上采样方式（如：反卷积与亚像素卷积）对图像进行上采样与重建。</li></ul></li><li><p>渐进式上采样模型框架</p><ul><li>该框架将大尺度超分辨率重建问题分解为多个小尺度的超分辨率重建问题。该框架利用级联的方式进行对图像进行逐步的上采样，并在此过程中融入多监督机制来缓解学习难度大的问题。</li></ul></li><li>迭代上下采样模型框架<ul><li>该类模型框架通过反复的将低分辨率空间图像上采样至高分辨率空间，再将高分辨率空间图像下采样至低分辨率空间，在此过程中利用投影误差来反复纠正超分辨率结果，达到提升超分辨性能的目的。</li></ul></li></ul><h2 id="三-评价标准"><a href="#三-评价标准" class="headerlink" title="三.评价标准"></a>三.评价标准</h2><ul><li>峰值信噪比（PSNR）<ul><li><script type="math/tex; mode=display">M S E = \frac { 1 } { N } \sum _ { I = 1 } ^ { N } ( I _ { y } ( i ) - \widehat { I } _ { y } ( i ) ) ^ { 2 }</script></li><li><script type="math/tex; mode=display">P S N R = 1 0 \cdot \log _ { 1 0 } ( \frac { L ^ { 2 } } { M S E } )</script></li></ul></li><li><p>结构相似度指数（SSIM）</p><ul><li><img src="https://s21.ax1x.com/2024/08/27/pAk45jO.png" alt="pAk45jO.png"></li></ul></li><li><p>主观评价</p></li></ul><h2 id="四-超分辨率的相关总结"><a href="#四-超分辨率的相关总结" class="headerlink" title="四.超分辨率的相关总结"></a>四.超分辨率的相关总结</h2><h3 id="1-超分辨率算法分类"><a href="#1-超分辨率算法分类" class="headerlink" title="1.超分辨率算法分类"></a>1.超分辨率算法分类</h3><h4 id="①-基于插值的算法"><a href="#①-基于插值的算法" class="headerlink" title="① 基于插值的算法"></a>① 基于插值的算法</h4><h4 id="②-基于重建的算法"><a href="#②-基于重建的算法" class="headerlink" title="② 基于重建的算法"></a>② 基于重建的算法</h4><h4 id="③-基于学习的算法-（常用）"><a href="#③-基于学习的算法-（常用）" class="headerlink" title="③ 基于学习的算法 （常用）"></a>③ 基于学习的算法 （常用）</h4><ul><li>基于深度学习的算法：基于深度学习的ＳＲ重建算法通常是构建一个端对端的网络模型，将ＬＲ图像输入到该特定网络模型中，通过特征映射和尺度放大等方式优化网络的损失函数，进而得到ＨＲ图 像</li></ul><h3 id="2-尺度放大方式"><a href="#2-尺度放大方式" class="headerlink" title="2.尺度放大方式"></a>2.尺度放大方式</h3><h4 id="①-上采样方法"><a href="#①-上采样方法" class="headerlink" title="① 上采样方法"></a>① 上采样方法</h4><h5 id="基于插值的上采样"><a href="#基于插值的上采样" class="headerlink" title="基于插值的上采样"></a>基于插值的上采样</h5><h5 id="基于反卷积的上采样-（常用）"><a href="#基于反卷积的上采样-（常用）" class="headerlink" title="基于反卷积的上采样 （常用）"></a>基于反卷积的上采样 （常用）</h5><h5 id="基于亚像素卷积的上采样"><a href="#基于亚像素卷积的上采样" class="headerlink" title="基于亚像素卷积的上采样"></a>基于亚像素卷积的上采样</h5><h4 id="②-上采样实施方式"><a href="#②-上采样实施方式" class="headerlink" title="② 上采样实施方式"></a>② 上采样实施方式</h4><h5 id="预先上采样"><a href="#预先上采样" class="headerlink" title="预先上采样"></a>预先上采样</h5><h5 id="单次上采样"><a href="#单次上采样" class="headerlink" title="单次上采样"></a>单次上采样</h5><h5 id="渐进上采样"><a href="#渐进上采样" class="headerlink" title="渐进上采样"></a>渐进上采样</h5><h5 id="迭代上采样-（常用）"><a href="#迭代上采样-（常用）" class="headerlink" title="迭代上采样 （常用）"></a>迭代上采样 （常用）</h5><h3 id="3-模型结构组成"><a href="#3-模型结构组成" class="headerlink" title="3.模型结构组成"></a>3.模型结构组成</h3><h4 id="①-基于CNN的模型（一般不使用池化层）"><a href="#①-基于CNN的模型（一般不使用池化层）" class="headerlink" title="① 基于CNN的模型（一般不使用池化层）"></a>① 基于CNN的模型（一般不使用池化层）</h4><h5 id="直线连接模型"><a href="#直线连接模型" class="headerlink" title="直线连接模型"></a>直线连接模型</h5><ul><li>最大问题就是随着网络深度的加深，参数逐渐增加，网络训练的难度越来越大，导致网络难以收敛，</li></ul><h5 id="残差连接模型"><a href="#残差连接模型" class="headerlink" title="残差连接模型"></a>残差连接模型</h5><ul><li>由于原始ＬＲ图像和输出的ＨＲ图像在很大程度上是相似的， 也就是说ＬＲ图像携带的低频信息与ＨＲ图像的低频信息基本一致。残差连接的应用使得原始的稠密矩阵学习转化为稀疏矩阵学习，因而使得计算量大幅度降低</li></ul><h5 id="密集连接模型"><a href="#密集连接模型" class="headerlink" title="密集连接模型"></a>密集连接模型</h5><ul><li>在保证网络中层与层之间最大程度的信息传输的前提下，直接将所有层连接起来，使网络中每一层输入为之前卷积层输出的总和，极大地增强了信息流动的能力，有效抑制了梯度爆炸和消失的问题。</li></ul><h5 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h5><ul><li>通过学习不同通道的重要性得到一个权重值，这相当于对信道间特征的相互关系进行建模， 自适应调整每个信道特征，从而在有效强化有用特 征通道的同时抑制无用特征通道，使计算资源得到更充分的利用。</li></ul><h4 id="②-基于CNN-RNN的模型"><a href="#②-基于CNN-RNN的模型" class="headerlink" title="② 基于CNN-RNN的模型"></a>② 基于CNN-RNN的模型</h4><ul><li>递归神经网络就是充分利用参数共享机制，使其在不增加参数的情况下加深网络的深度，降低网络的复杂度，加快训练速度</li></ul><h4 id="③-基于GAN的模型"><a href="#③-基于GAN的模型" class="headerlink" title="③ 基于GAN的模型"></a>③ 基于GAN的模型</h4><ul><li><img src="https://s21.ax1x.com/2024/08/27/pAk7O6x.png" alt="pAk7O6x.png"></li></ul><h3 id="4-损失函数分类"><a href="#4-损失函数分类" class="headerlink" title="4.损失函数分类"></a>4.损失函数分类</h3><h4 id="①基于像素的损失函数"><a href="#①基于像素的损失函数" class="headerlink" title="①基于像素的损失函数"></a>①基于像素的损失函数</h4><ul><li>均方误差（MSE）</li><li>平均绝对值误差（MAE）</li><li>本质上都是反映对应像素之间的误差关系，忽略了像素与邻域像素间存在的内在联系，因 而重建图像质量存在边缘模糊和振铃现象。</li></ul><h4 id="②基于感知的损失函数"><a href="#②基于感知的损失函数" class="headerlink" title="②基于感知的损失函数"></a>②基于感知的损失函数</h4><ul><li>内容损失函数</li><li>对抗损失函数</li><li>上下文损失函数</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;MRI超分辨率-初见&quot;&gt;&lt;a href=&quot;#MRI超分辨率-初见&quot; class=&quot;headerlink&quot; title=&quot;MRI超分辨率-初见&quot;&gt;&lt;/a&gt;MRI超分辨率-初见&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考文献：&lt;a href=&quot;https://kns.cnki.net/kcms2/article/abstract?v=MBTPQIn9ZKHwJKNtmL5eu7ZFUIb7_nCdbjKrKYFXDX6PgaFW9ljQXL28jn2X8Tj-Fz9N66Pw2G-7sZKyd45rdpBDmk8uzaCVlHLs8CrT9djwL1vEujSi471jNVkdUlEig7F0PF8coO7qxlD8DotHOeCi2IyxGNPoEJVYW6xeQwx-YP19kSVBS-Q5b6eyw2jueAmJScamN0AezEUaa59P5Xn_eLIAQ_aMAfpnTy3Ubv6W8vCSIDYLpFbFr3BReGkWAXsly07QS-ieh65-u_RMjowiogGdel8q&amp;amp;uniplatform=NZKPT&amp;amp;language=CHS&quot;&gt;单幅3D磁共振图像超分辨率算法研究&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="学术论文总结" scheme="http://example.com/categories/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="MRI超分辨率" scheme="http://example.com/tags/MRI%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>操作系统第五章-输入/输出(I/O)管理</title>
    <link href="http://example.com/2024/08/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%94%E7%AB%A0-%E8%BE%93%E5%85%A5-%E8%BE%93%E5%87%BA-I-O-%E7%AE%A1%E7%90%86/"/>
    <id>http://example.com/2024/08/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%94%E7%AB%A0-%E8%BE%93%E5%85%A5-%E8%BE%93%E5%87%BA-I-O-%E7%AE%A1%E7%90%86/</id>
    <published>2024-08-11T17:34:20.000Z</published>
    <updated>2024-08-12T03:18:37.355Z</updated>
    
    <content type="html"><![CDATA[<h2 id="操作系统第五章-输入-输出（I-O）管理"><a href="#操作系统第五章-输入-输出（I-O）管理" class="headerlink" title="操作系统第五章 输入/输出（I/O）管理"></a>操作系统第五章 输入/输出（I/O）管理</h2><blockquote><p>计算机学科基础：操作系统第五章输入/输出(I/O)管理的学习笔记</p></blockquote><span id="more"></span><h3 id="一-I-O管理概述（✠）"><a href="#一-I-O管理概述（✠）" class="headerlink" title="一.I/O管理概述（✠）"></a>一.I/O管理概述（✠）</h3><h4 id="1-I-O设备"><a href="#1-I-O设备" class="headerlink" title="1.I/O设备"></a>1.I/O设备</h4><ul><li><p>I/O设备的定义</p><ul><li>I/O设备就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件</li><li>UNIX系统将外部设备抽象为一种特殊的文件，用户可以使用与文件操作相同的方式对外部设备进行操作。</li><li>Write:操作：向外部设备写出数据；Read操作：从外部设备读入数据</li></ul></li><li><p>I/O设备的分类</p><ul><li>按信息交换的单位分类<ul><li>块设备：信息交换以数据块为单位。它属于有结构设备，<strong>如磁盘等</strong>。<br>磁盘设备的基本特征是传输速率较高、可寻址，即对它可随机地读/写任意一块，<strong>如共享设备</strong>。</li><li>字符设备：信息交换以字符为单位。它属于无结构类型，<strong>如交互式终端机、打印机等</strong>。<br>传输速率较慢，不可寻址，在输入/输出时常采用<strong>中断驱动方式</strong></li></ul></li><li>按使用特性分类<ul><li>人机交互类外部设备：鼠标、键盘、打印机等一一用于人机交互，数据传输速度慢</li><li>存储设备：移动硬盘、光盘等一一用于数据存储，数据传输速度快</li><li>网络通信设备：调制解调器等一一用于网络通信，数据传输速度介于上述二者之间</li></ul></li><li>按传输速率分类<ul><li>低速设备。传输速率仅为每秒几字节到数百字节的一类设备，如键盘、鼠标等。</li><li>中速设备。传输速率为每秒数千字节至数万字节的一类设备，如激光打印机等。</li><li>高速设备。传输速率在数百千字节至千兆字节的一类设备，如磁盘机、光盘机等。</li></ul></li></ul></li><li>I/O设备的组成<ul><li>机械部件<ul><li>I/O设备的机械部件主要用来执行具体I/O操作<br>如我们看得见摸得着的鼠标/键盘的按钮；显示器的LED屏；移动硬盘的磁臂、磁盘盘面。</li></ul></li><li>电子部件<ul><li>I/O设备的电子部件通常是一块插入主板扩充槽的印刷电路板</li><li>I/O接口（I/O控制器，设备控制器）<ul><li>I/O接口（设备控制器）位于CPU与设备之间（作为中介），<br>它既要与CPU通信，又要与设备通信，还要具有按CPU发来的命令去控制设备工作的功能</li><li>I/O设备的功能<ul><li>接受和识别CPU发出的命令（<strong>要有控制寄存器</strong>）<ul><li>如CPU发来的read/write命令，I/O控制器中会有相应的控制寄存器来存放命令和参数</li></ul></li><li>向CPU报告设备的状态（<strong>要有状态寄存器</strong>）<ul><li>I/O控制器中会有相应的状态寄存器用于记录1/0设备的当前状态。如：1表示空闲，0表示忙碌</li></ul></li><li>数据交换（<strong>要有数据寄存器，暂存输入输出的数据</strong>）<ul><li>I/O控制器中会设置相应的数据寄存器。输出时，数据寄存器用于暂存CPU发来的数据，之后再由控制器传送设备。</li><li>输入时，数据寄存器用于暂存设备发来的数据，之后CPU从数据寄存器中取走数据</li></ul></li><li>地址识别（<strong>由I/O逻辑实现</strong>)<ul><li>类似于内存的地址，为了区分设备控制器中的各个寄存器，也需要给各个寄存器设置一个特定的“地址”。</li><li>I/O控制器通过CPU提供的“地址”来判断CPU要读/写的是哪个寄存器</li></ul></li></ul></li><li>I/O接口的组成<ul><li>CPU与控制器之间的接口（<strong>实现控制器与CPU之间的通信</strong>）<ul><li>用于实现CPU与控制器之间的通信。</li><li>CPU通过控制线发出命令；通过地址线指明要操作的设备；<br>通过数据线来取出（输入）数据，或放入（输出）数据</li><li>数据线常与两类寄存器相连：数据寄存器（存放从设备送来的输入数据或从CPU送来的输出数据）和控制/状态寄存器(存放从CPU送来的控制信息或设备的状态信息)。</li></ul></li><li>I/O逻辑（<strong>负责识别CPU发出的命令，并向设备发出命令，实现对设备的控制</strong>）<ul><li>用于实现对设备的控制。它通过一组控制线与CPU交互，对从CPU收到的I/O命令进行译码。</li><li>CPU启动设备时，将启动命令发送给控制器，同时通过地址线把地址发送给控制器，由控制器的I/O逻辑对地址进行译码，并相应地对所选设备进行控制。</li></ul></li><li>控制器与设备之间的接口（<strong>实现控制器与设备之间的通信</strong>）<ul><li>一个设备控制器可以连接一个或多个设备，因此控制器中有一个或多个设备接口。每个接口中都存在数据、控制和状态三种类型的信号。</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtdZlT.png" alt="pPtdZlT.png"></li></ul></li></ul></li></ul></li><li>I/O端口<ul><li>I/O端口是指设备控制器中可被CPU直接访问的寄存器</li><li>寄存器的分类<ul><li>数据寄存器：实现CPU和外设之间的数据缓冲。</li><li>状态寄存器：获取执行结果和设备的状态信息，以让CPU知道是否准备好。</li><li>控制寄存器：由CPU写入，以便启动命令或更改设备模式。</li></ul></li><li>寄存器的两种编址方式<ul><li>独立编址。为每个端口分配一个I/O端口号，所有I/O端口形成I/O端口空间，普通用户程序不能对其进行访问，只有操作系统使用特殊的I/O指令才能访问端口</li><li>统一编址。又称<strong>内存映射I/O</strong>，每个端口被分配唯一的内存地址，且不会有内存被分配这一地址，通常分配给端口的地址靠近地址空间的顶端。可以采用对内存进行操作的指令来对控制器进行操作</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtdx41.png" alt="pPtdx41.png"></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><h4 id="2-I-O控制方式"><a href="#2-I-O控制方式" class="headerlink" title="2.I/O控制方式"></a>2.I/O控制方式</h4><ul><li>程序直接控制方式（轮询）<ul><li>完成一次读/写操作的流程<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPt0FzV.png" alt="pPt0FzV.png"></li></ul></li><li>流程图<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPt0AMT.png" alt="pPt0AMT.png"></li></ul></li><li>CPU干预的频率<ul><li>很频繁，I/O操作开始之前、完成之后需要CPU介入，并且在等待I/O完成的过程中CPU需要不断地轮询检查。</li></ul></li><li>数据传送的单位：每次读/写一个字</li><li>数据的流向<ul><li>读操作（数据输入）：I/O设备→CPU→内存</li><li>写操作（数据输出）：内存→CPU→I/O设备</li><li>每个字的读/写都需要CPU的帮助</li></ul></li><li>主要缺点和主要优点<ul><li>优点：实现简单。在读/写指令之后，加上实现循环检查的一系列指令即可(因此才称为“程序直接控制方式”)</li><li><strong>缺点：CPU和I/O设备只能串行工作，CPU需要一直轮询检查，长期处于“忙等”状态，CPU利用率低</strong>。</li></ul></li></ul></li><li>中断驱动方式<ul><li>完成一次读写操作的流程<ul><li>引入中断机制。由于I/O设备速度很慢，因此在CPU发出读/写命令后，可将等待I/O的进程阻塞，先切换到别的进程执行。</li><li>当I/O完成后，控制器会向CPU发出一个中断信号，CPU检测到中断信号后，会保存当前进程的运行环境信息，转去执行中断处理程序处理该中断。</li><li>处理中断的过程中，CPU从I/O控制器读一个字的数据传送到CPU寄存器，再写入主存。接着，CPU恢复等待I/O的进程（或其他进程）的运行环境，然后继续执行。</li><li>注意<ul><li>①CPU会在每个指令周期的末尾检查中断</li><li>②中断处理过程中需要保存、恢复进程的运行环境，这个过程是需要一定时间开销的。可见，如果中断发生的频率太高，也会降低系统性能。</li></ul></li></ul></li><li>流程图<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPt0Lk9.png" alt="pPt0Lk9.png"></li></ul></li><li>CPU干预的频率<ul><li>每次I/O操作开始之前、完成之后需要CPU介入。</li><li>等待I/O完成的过程中CPU可以切换到别的进程执行。</li></ul></li><li>数据传送的单位：每次读/写一个字</li><li>数据的流向<ul><li>读操作（数据输入）：I/O设备→CPU→内存</li><li>写操作（数据输出）：内存→CPU→I/O设备</li></ul></li><li>主要缺点和主要优点<ul><li>优点<ul><li>与“程序直接控制方式”相比，在“中断驱动方式”中，I/O控制器会通过中断信号主动报告I/O已完成，CPU不再需要不停地轮询。</li><li>CPU和I/O设备可并行工作，CPU利用率得到明显提升。</li></ul></li><li>缺点：每个字在I/O设备与内存之间的传输，都需要经过CPU。而频繁的中断处理会消耗较多的CPU时间。</li></ul></li></ul></li><li>DMA方式（直接存储器存取，外设—内存）<ul><li>特点<ul><li><strong>数据的传送单位是“块”</strong>。不再是一个字、一个字的传送，<strong>适用于磁盘设备</strong></li><li><strong>数据的流向是从设备直接放入内存，或者从内存直接到设备。不再需要CPU作为中介</strong></li><li>仅在传送一个或多个数据块的开始和结束时，才需要CPU干预。<ul><li>CPU指明此次要进行的操作(如：读操作)，并说明要读入多少数据、数据要存放在内存的什么位置，数据在外部设备上的地址(如：在磁盘上的地址)</li><li>控制器会根据CPU提出的要求完成数据的读/写工作，整块数据的传输完成后，才向CPU发出中断信号</li></ul></li></ul></li><li>DMA控制器<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtBYcV.png" alt="pPtBYcV.png"></li></ul></li><li>CPU干预的频率：<strong>仅在传送一个或多个数据块的开始和结束时，才需要CPU干预</strong>。</li><li>数据传送的单位：每次读/写一个或多个块（注意：<strong>每次读写的只能是连续的多个块，且这些块读入内存后在内存中也必须是连续的</strong>）</li><li>数据的流向  (不再需要经过CPU)<ul><li>读操作（数据输入）：I/O设备→内存</li><li>写操作（数据输出）：内存→I/O设备</li></ul></li><li>主要缺点和主要优点<ul><li>优点：数据传输以“块”为单位，CPU介入频率进一步降低。<br>数据的传输不再需要先经过CPU再写入内存，数据传输效率进一步增加。CPU和I/O设备的并行性得到提升。</li><li>缺点：CPU每发出一条I/O指令，只能读/写一个或多个连续的数据块。<br>如果要读/写多个离散存储的数据块，或者要将数据分别写到不同的内存区域时，CPU要分别发出多条I/O指令，进行多次中断处理才能完成。</li></ul></li></ul></li><li>通道控制方式（<strong>硬件</strong>）<ul><li>通道是一种硬件，与CPU相比，通道可以执行的指令很单一，并且通道程序是放在主机内存中的，也就是说通道与CPU共享内存</li><li>完成一次读写操作的流程<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtDiuT.png" alt="pPtDiuT.png"></li></ul></li><li>CPU干预的频率<strong>：极低，通道会根据CPU的指示执行相应的通道程序，只有完成一组数据块的读/写后才需要发出中断信号，请求CPU干预。</strong></li><li>数据传送的单位：每次读/写一组数据块</li><li>数据的流向（在通道的控制下进行）<ul><li>读操作（数据输入）：I/O设备→内存</li><li>写操作（数据输出）：内存→I/O设备</li></ul></li><li>主要缺点和主要优点<ul><li>缺点：实现复杂，需要专门的通道硬件支持</li><li>优点：CPU、通道、I/O设备可并行作，资源利用率很高</li></ul></li></ul></li></ul><h4 id="3-I-O软件层次结构"><a href="#3-I-O软件层次结构" class="headerlink" title="3.I/O软件层次结构"></a>3.I/O软件层次结构</h4><ul><li>概览<ul><li>分为四层，越上层越接近用户，下层为上层提供服务，屏蔽实现的具体细节，越下层越接近硬件</li><li>中间的三层处于内核部分，称为I/O（核心子系统）系统</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtD1bD.png" alt="pPtD1bD.png"></li></ul></li></ul></li><li>I/O操作的流程：用户程序→系统调用处理程序→设备驱动程序→中断处理程序。</li><li>用户层I/O软件<ul><li>用户层软件实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数对设备进行操作</li><li><strong>用户层软件将用户请求翻译成格式化的I/O请求，并通过“系统调用”请求操作系统内核的服务</strong></li></ul></li><li>设备独立性软件<ul><li><strong>设备独立性软件，又称设备无关性软件</strong>。与设备的硬件特性无关的功能几乎都在这一层实现。<br><strong>处理上层的系统调用参数</strong></li><li>功能<ul><li>①向上层提供统一的调用接口(如read/write系统调用) </li><li>②设备的保护</li><li>③差错控制</li><li><strong>④设备的分配与回收</strong></li><li><strong>⑤数据缓冲区管理</strong></li><li>⑥<strong>建立逻辑设备名到物理设备名的映射关系；</strong><ul><li>根据设备类型选择调用相应的驱动程序用户或用户层软件发出I/O操作相关系统调用的系统调用时，需要指明此次要操作的I/O设备的逻辑设备名，不同类型的I/O设备需要有不同的驱动程序处理</li><li>设备独立性软件需要通过逻辑设备表来确定逻辑设备对应的物理设备，并找到该设备对应的设备驱动程序</li></ul></li><li>管理逻辑设备表的（LUT）方式<ul><li>第一种方式，整个系统只设置一张LUT，这就意味着所有用户不能使用相同的逻辑设备名，因此这种方式只适用于单用户操作系统。</li><li>第二种方式，为每个用户设置一张ULT，各个用户使用的逻辑设备名可以重复，适用于多用户操作系统。<br>系统会在用户登录时为其建立一个用户管理进程，而LUT就存放在用户管理进程的PCB中。</li></ul></li></ul></li></ul></li><li>设备驱动程序（<strong>驱动程序与操作系统无关</strong>）<ul><li>不同的I/O设备有不同的硬件特性，具体细节只有设备的厂家才知道，因此厂家需要根据设备的硬件特性设计并提供相应的驱动程序，驱动程序一般以一个独立的进程存在</li><li><strong>负责对硬件设备的具体控制，将上层发出的一系列命令（如read/write)转化成特定设备“能听得懂”的一系列操作。</strong><br><strong>包括设置设备寄存器，检查设备状态等</strong></li><li><strong>计算数据所在磁盘的柱面号、磁头号、扇区号</strong></li></ul></li><li>中断处理程序<ul><li><strong>当I/O任务完成时，I/O控制器会发送一个中断信号，系统会根据中断信号类型找到相应的中断处理程序并执行。</strong></li></ul></li></ul><h4 id="4-应用程序I-O接口"><a href="#4-应用程序I-O接口" class="headerlink" title="4.应用程序I/O接口"></a>4.应用程序I/O接口</h4><ul><li>输入/输出应用程序接口<ul><li>包括：字符设备接口、块设备接口、网络设备接口(网络套接字)<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtgkb6.png" alt="pPtgkb6.png"></li></ul></li><li>阻塞I/O与非阻塞I/O<ul><li>阻塞I/O：应用程序发出I/O系统调用，进程需转为阻塞态等待。<br>如字符设备接口一一从键盘读一个字符get</li><li>非阻塞I/O：应用程序发出I/O系统调用，系统调用可迅速返回，进程无需阻塞等待。<br>如块设备接口一一往磁盘写数据write</li></ul></li></ul></li><li>设备驱动程序接口（<strong>驱动程序只与厂商有关，与操作系统无关</strong>）<ul><li>不同的操作系统，对设备驱动程序接口的标准各不相同。</li><li>设备厂商必须根据操作系统的接口要求，开发相应的设备驱动程序，设备才能被使用</li></ul></li></ul><h4 id="5-提高磁盘I-O速度的方法"><a href="#5-提高磁盘I-O速度的方法" class="headerlink" title="5.提高磁盘I/O速度的方法"></a>5.提高磁盘I/O速度的方法</h4><ul><li>提前读。在读磁盘当前块时，把下一磁盘块也读入内存缓冲区。</li><li>延迟写。仅在缓冲区首部设置延迟写标志，然后释放此缓冲区并将其链入空闲缓冲区链表的尾部，<br>当其他进程申请到此缓冲区时，才真正把缓冲区信息写入磁盘块。</li><li>虚拟盘。是指用内存空间去仿真磁盘，又叫RAM盘。虚拟盘是一种易失性存储器。虚拟盘常用于存放临时文件。</li></ul><h3 id="二-设备独立性软件（✠）"><a href="#二-设备独立性软件（✠）" class="headerlink" title="二.设备独立性软件（✠）"></a>二.设备独立性软件（✠）</h3><h4 id="1-假脱机（SPOOLing）技术"><a href="#1-假脱机（SPOOLing）技术" class="headerlink" title="1.假脱机（SPOOLing）技术"></a>1.假脱机（SPOOLing）技术</h4><ul><li>脱机技术<ul><li>在外围控制机的控制下，慢速输入设备的数据先被输入到更快速的磁带上<br>之后主机可以从快速的磁带上读入数据，从而缓解了速度矛盾</li><li><strong>引入脱机技术后，缓解了CPU与慢速I/O设备的速度矛盾。另一方面，即使CPU在忙碌，也可以提前将数据输入到磁带；</strong><br><strong>即使慢速的输出设备正在忙碌，也可以提前将数据输出到磁带</strong>。</li></ul></li><li>假脱机技术（<strong>用软件的方式模拟脱机技术</strong>）<ul><li>输入井和输出井<ul><li><strong>在磁盘上开辟出两个存储区域一一“输入井”和“输出井”</strong></li><li>“输入井”模拟脱机输入时的磁带，用于收容I/O设备输入的数据</li><li>“输出井”模拟脱机输出时的磁带，用于收容用户进程输出的数据</li></ul></li><li>输入进程和输出进程<ul><li><strong>要实现SPOOLing技术，必须要有多道程序技术的支持。系统会建立“输入进程”和“输出进程”</strong>。</li><li>输入进程模拟脱机输入时的外围控制机</li><li>输出进程模拟脱机输出时的外围控制机</li></ul></li><li>输入缓冲区和输出缓冲区<ul><li><strong>两个缓冲区都是在内存中的</strong></li><li>在输入进程的控制下，“输入缓冲区”用于暂存从输入设备输入的数据，之后再转存到输入井中</li><li>在输出进程的控制下，“输出缓冲区”用于暂存从输出井送来的数据，之后再传送到输出设备上</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtWvLR.png" alt="pPtWvLR.png"></li></ul></li></ul></li><li>共享打印机<ul><li>独占式设备一一只允许各个进程串行使用的设备。一段时间内只能满足一个进程的请求。</li><li>共享设备一一允许多个进程“同时”使用的设备（宏观上同时使用，微观上可能是交替使用）可以同时满足多个进程的使用请求。</li><li><strong>打印机是种“独占式设备”，SPOOLing技术可以把一台物理设备虚拟成逻辑上的多台设备，可将打印机变为共享设备</strong><ul><li><strong>虽然系统中只有一个台打印机，但每个进程提出打印请求时，系统都会为在输出井中为其分配一个存储区（外存中）；</strong><br><strong>相当于分配了一个逻辑设备，使每个用户进程都觉得自己在独占一台打印机，从而实现对打印机的共享。</strong></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtf3lQ.png" alt="pPtf3lQ.png"></li></ul></li></ul></li></ul></li></ul><h4 id="2-设备的分配与回收"><a href="#2-设备的分配与回收" class="headerlink" title="2.设备的分配与回收"></a>2.设备的分配与回收</h4><ul><li><strong>设备独立性是指用户在编程序时使用的设备与实际设备无关。一个程序应独立于分配给它的某类设备的具体设备，</strong><br><strong>即在用户程序中只指明I/O使用的设备类型即可。</strong></li><li>设备分配时应考虑的因素<ul><li>设备的固有属性<ul><li>独占设备：一个时段只能分配给一个进程（如打印机）</li><li>共享设备：可同时分配给多个进程使用（如磁盘），各进程往往是宏观上同时共享使用设备，而微观上交替使用。</li><li><strong>虚拟设备：采用SPOOLing技术将独占设备改造成虚拟的共享设备，可同时分配给多个进程使用</strong><br><strong>(如采用SPOOLing技术实现的共享打印机)</strong></li></ul></li><li>设备分配算法<ul><li>先来先服务、优先级高者优先、短任务优先等算法</li></ul></li><li>设备分配中的安全性<ul><li>安全分配方式：为进程分配一个设备后就将进程阻塞，本次I/O完成后才将进程唤醒。(考虑进程请求打印机打印输出的例子)一个时段内每个进程只能使用一个设备<ul><li>优点：破坏了“请求和保持”条件，不会死锁</li><li>缺点：对于一个进程来说，CPU和/O设备只能串行工作</li></ul></li><li>不安全分配方式：进程发出I/O请求后，系统为其分配I/O设备，进程可继续执行，之后还可以发出新的I/O请求。只有某I/O请求得不到满足时才将进程阻塞。一个进程可以同时使用多个设备<ul><li>优点：进程的计算任务和I/O任务可以并行处理，使进程迅速推进</li><li>缺点：有可能发生死锁（死锁避免、死锁的检测和解除)</li></ul></li></ul></li></ul></li><li>静态分配与动态分配<ul><li>静态分配：进程运行前为其分配全部所需资源，运行结束后归还资源，破坏了“请求和保持”条件，不会发生死锁</li><li>动态分配：进程运行过程中动态申请设备资源</li></ul></li><li>设备分配管理中的数据结构<ul><li>一个通道可控制多个设备控制器，每个设备控制器可控制多个设备。</li><li>设备控制表(DCT)：系统为每个设备配置一张DCT，用于记录设备情况<ul><li><strong>设备类型（逻辑设备名）：如打印机/扫描仪/键盘</strong></li><li><strong>设备标识符：即物理设备名，系统中的每个设备的物理设备名唯一</strong></li><li>设备状态：忙碌/空闲/故障</li><li><strong>指向控制器表的指针：每个设备由一个控制器控制，该指针可找到相应控制器的信息</strong></li><li>重复执行次数或时间：当重复执行多次I/O操作后仍不成功，才认为此次I/O失败</li><li>设备队列的队首指针：指向正在等待该设备的进程队列(由进程PCB组成队列)<br>系统会根据阻塞原因不同，将进程PCB挂到不同的阻塞队列中</li></ul></li><li>控制器控制表(COCT)：每个设备控制器都会对应一张COCT。操作系统根据COCT的信息对控制器进行操作和管理。<ul><li><strong>控制器标识符：各个控制器的唯一ID</strong></li><li>控制器状态：忙碌/空闲/故障</li><li><strong>指向通道表的指针：每个控制器由一个通道控制，该指针可找到相应通道的信息</strong></li><li>控制器队列的队首指针</li><li>控制器队列的队尾指针：指向正在等待该控制器的进程队列(由进程PCB组成队列)</li></ul></li><li>通道控制表(CHCT)：每个通道都会对应一张CHCT。操作系统根据CHCT的信息对通道进行操作和管理<ul><li>通道标识符：各个通道的唯一ID</li><li>通道状态：忙碌/空闲/故障</li><li>与通道连接的控制器表首址：可通过该指针找到该通道管理的所有控制器相关信息(COCT)</li><li>通道队列的队首指针</li><li>通道队列的队尾指针：指向正在等待该通道的进程队列(由进程PCB组成队列)</li></ul></li><li><strong>系统设备表(SDT)：记录了系统中全部设备的情况，每个设备对应一个表目。</strong></li></ul></li><li>设备分配的步骤<ul><li>步骤<ul><li>①根据进程请求的物理设备名查找SDT(注：物理设备名是进程请求分配设备时提供的参数)</li><li>②根据SDT找到DCT，若设备忙碌则将进程PCB挂到设备等待队列中，不忙碌则将设备分配给进程。</li><li>③根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列中，不忙碌则将控制器分配给进程。</li><li>④根据COCT找到CHCT，若通道忙碌则将进程PCB挂到通道等待队列中，不忙碌则将通道分配给进程。</li></ul></li><li>注：只有设备、控制器、通道三者都分配成功时，这次设备分配才算成功，之后便可启动I/O设备进行数据传送</li><li>缺点<ul><li>①用户编程时必须使用“物理设备名”，底层细节对用户不透明，不方便编程</li><li>②若换了一个物理设备，则程序无法运行</li><li>③若进程请求的物理设备正在忙碌，则即使系统中还有同类型的设备，进程也必须阻塞等待</li></ul></li><li><strong>改进方法：建立逻辑设备名与物理设备名的映射机制，用户编程时只需提供逻辑设备名</strong></li></ul></li><li><p>设备分配的改进</p><ul><li><p>增加设备的独立性并考虑多通路情况</p><ul><li><p>增加设备的独立性</p><ul><li>进程使用逻辑设备名请求I/O。这样，系统首先从SDT中找出第一个该类设备的DCT。</li><li>若该设备忙，则又查找第二个该类设备的DCT。仅当所有该类设备都忙时，才把进程挂到该类设备的等待队列上</li><li>只要有一个该类设备可用，系统便进一步计算分配该设备的安全性。</li></ul></li><li><p>考虑多通路情况</p><ul><li>为防止I/O系统的“瓶颈”现象，通常采用多通路的I/O系统结构。此时对控制器和通道的分配同样要经过几次反复，<br>即若设备（控制器）所连接的第一个控制器（通道）忙时，则应查看其所连接的第二个控制器（通道）</li><li>仅当所有控制器（通道）都忙时，此次的控制器（通道）分配才算失败，才把进程挂到控制器（通道）的等待队列上<br>而只要有一个控制器（通道）可用，系统便可将它分配给进程。</li><li>设备分配过程中，先后分别访问的数据结构为SDT→DCT→COCT→CHCT。要成功分配一个设备，必须要：<br>①设备可用；②控制器可用；③通道可用。所以，“设备分配，要过三关”。</li></ul></li></ul></li><li><p>逻辑设备表(LUT)：<strong>建立了逻辑设备名与物理设备名之间的映射关系</strong></p><ul><li>某用户进程第一次使用设备时使用逻辑设备名向操作系统发出请求，操作系统根据用户进程指定的设备类型（逻辑设备名）查找系统设备表，找到一个空闲设备分配给进程，并在LUT中增加相应表项。</li><li>如果之后用户进程再次通过相同的逻辑设备名请求使用设备，则操作系统通过LUT表即可知道用户进程实际要使用的是哪个物理设备了，并且也能知道该设备的驱动程序入口地址。</li><li>此时不仅可以通过物理设备名查找物理设备，还可以通过逻辑设备名访问物理设备</li><li>此时更改物理设备后不用修改访问改设备的应用程序</li></ul></li><li>设备分配的步骤<ul><li>①根据进程请求的逻辑设备名查找SDT(注：用户编程时提供的逻辑设备名其实就是“设备类型”)</li><li><strong>②查找SDT，找到用户进程指定类型的、并且空闲的设备，将其分配给该进程。操作系统在逻辑设备表(LUT)中新增一个表项。</strong></li><li>③根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列中，不忙碌则将控制器分配给进程。</li><li>④根据COCT找到CHCT，若通道忙碌则将进程PCB挂到通道等待队列中，不忙碌则将通道分配给进程。</li></ul></li><li>逻辑设备表的设置问题<ul><li>整个系统只有一张LUT：各用户所用的逻辑设备名不允许重复，适用于单用户操作系统</li><li>每个用户一张LUT：不同用户的逻辑设备名可重复，适用于多用户操作系统</li></ul></li></ul></li></ul><h4 id="3-高速缓存与缓冲区"><a href="#3-高速缓存与缓冲区" class="headerlink" title="3.高速缓存与缓冲区"></a>3.高速缓存与缓冲区</h4><ul><li><p>高速缓存</p><ul><li>操作系统中使用磁盘高速缓存技术来提高磁盘的I/O速度<br>利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中</li><li><strong>磁盘高速缓存逻辑上属于磁盘，物理上则是驻留在内存中的盘块。</strong></li><li>高速缓存在内存中分为两种形式<ul><li>一种是在内存中开辟一个单独的空间作为磁盘高速缓存，大小固定</li><li>另一种是把未利用的内存空间作为一个缓冲池，供请求分页系统和磁盘I/O时共享。</li></ul></li></ul></li><li><p>缓冲区的定义</p><ul><li>缓冲区是一个存储区域，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区。</li><li>使用硬件作为缓冲区的成本较高，容量也较小，一般仅用在对速度要求非常高的场合；<br>如存储器管理中所用的联想寄存器（快表），由于对页表的访问频率极高，因此使用速度很快的联想寄存器来存放页表项的副本</li><li>一般情况下，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区</li></ul></li><li>缓冲区的作用<ul><li>缓和CPU与I/O设备之间速度不匹配的矛盾<ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtI6gO.png" alt="pPtI6gO.png"></li></ul></li><li>减少对CPU的中断频率，放宽对CPU中断响应时间的限制<ul><li>如果是字符型设备则每输出完一个字符就要向CPU发送一次中断信号</li></ul></li><li>解决数据粒度不匹配的问题<ul><li>输出进程每次可以生成一块数据但I/O设备每次只能输出一个字符</li></ul></li><li>提高CPU与I/O设备之间的并行性</li></ul></li><li>单缓冲<ul><li>操作系统会在主存中为其分配一个缓冲区，用户进程的内存空间中，会分出一片工作区来接受输入/输出数据（一般也默认工作区大小与缓冲区相同）</li><li>当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出；</li><li>当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满以后，才能从缓冲区把数据传出。</li><li><strong>分析问题的初始状态：工作区满；缓冲区空处理一块数据的平均耗时时间：Max(C,T)+M</strong><ul><li><img src="https://s1.ax1x.com/2023/08/25/pPtHKzV.png" alt="pPtHKzV.png"></li></ul></li></ul></li><li>双缓冲<ul><li><strong>分析问题的初始状态：工作区空，一个缓冲区满，另一个缓冲区空；处理一块数据平均耗时Max(T,C+M)</strong></li></ul></li><li>单缓冲与双缓冲的区别<ul><li>两台机器之间通信时，可以配置缓冲区用于数据的发送和接受。</li><li>若两个相互通信的机器只设置单缓冲区，在任一时刻只能实现数据的单向传输。</li><li>若两个相互通信的机器设置双缓冲区，则同一时刻可以实现双向的数据传输。</li></ul></li><li>例题<ul><li>例1<ul><li>选B<img src="https://s1.ax1x.com/2023/08/25/pPN9BOs.png" alt="pPN9BOs.png"></li><li><img src="https://s1.ax1x.com/2023/08/25/pPN9ckV.png" alt="pPN9ckV.png"></li></ul></li><li>例2<ul><li>选C<img src="https://s1.ax1x.com/2023/08/25/pPN9fl4.png" alt="pPN9fl4.png"></li></ul></li></ul></li></ul><h3 id="三-磁盘与固态硬盘（✪）"><a href="#三-磁盘与固态硬盘（✪）" class="headerlink" title="三.磁盘与固态硬盘（✪）"></a>三.磁盘与固态硬盘（✪）</h3><h4 id="1-磁盘的结构"><a href="#1-磁盘的结构" class="headerlink" title="1.磁盘的结构"></a>1.磁盘的结构</h4><ul><li>磁盘、磁道、扇区的概念<ul><li>磁盘由表面涂有磁性物质的圆形盘片组成</li><li>每个盘片被划分为一个个磁道，每个磁道又划分为一个个扇区</li><li>每个扇区就是一个磁盘块”。各个扇区存放的数据量相同(如1KB)</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPN3pHx.png" alt="pPN3pHx.png"></li></ul></li></ul></li><li>如何在磁盘中读/写数据<ul><li>磁头移动到目标位置，盘片旋转，对应扇区划过磁道才能完成读/写（机械操作）</li><li>存储一个文件时，当一个磁道存储不下时，选择同一个柱面的不同盘面进行存储，此时可以避免磁臂移动，减少了处理时间</li></ul></li><li>盘面、柱面的概念<ul><li>磁盘有多个盘片“摞”起来，每个盘片有两个盘面</li><li>所有盘面中相对位置相同的磁道组成柱面</li></ul></li><li>磁盘的物理地址<ul><li><strong>可用(柱面号，盘面号，扇区号)来定位任意一个“磁盘块”。</strong></li><li>①根据“柱面号”移动磁臂，让磁头指向指定柱面</li><li>②激活指定盘面对应的磁头；</li><li>③磁盘旋转的过程中，指定的扇区会从磁头下面划过，这样就完成了对指定扇区的读/写。</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNutDf.png" alt="pPNutDf.png"></li></ul></li></ul></li><li>磁盘的分类<ul><li>根据磁头是否可移动<ul><li>固定头磁盘（每个磁道有一个磁头，则一个盘面有多个磁头）</li><li>移动头磁盘（每个盘面只有一个磁头）</li></ul></li><li>根据盘片是否可更换：固定盘磁盘可换盘磁盘</li></ul></li><li>簇/块：操作系统限制的存储空间分配基本单位<br>簇：windows系统的说法；块：Linux、Uniⅸ系统的说法<ul><li>本题需为簇的整数倍，选2048B<img src="https://s1.ax1x.com/2023/08/26/pPNDsk4.png" alt="pPNDsk4.png"></li></ul></li></ul><h4 id="2-磁盘的管理"><a href="#2-磁盘的管理" class="headerlink" title="2.磁盘的管理"></a>2.磁盘的管理</h4><ul><li>磁盘初始化<ul><li>Step1：进行低级格式化（物理格式化）：将磁盘的各个磁道划分为扇区。一个扇区通常可分为头、数据区域（如512B大小）、尾三个部分组成。<ul><li>管理扇区所需要的各种数据结构一般存放在头、尾两个部分，包括扇区校验码，如奇偶校验、CRC循环冗余校验码等，校验码用于校验扇区中的数据是否发生错误</li></ul></li><li>Step2：将磁盘分区，每个分区由若干柱面组成（即分为我们熟悉的C盘、D盘、E盘）</li><li>Step3：进行逻辑格式化（高级格式化），创建文件系统。包括创建文件系统的根目录、初始化存储空间管理所用的数据结构（如位示图、空闲分区表）、产生引导扇区</li></ul></li><li>引导块<ul><li>计算机启动时需要运行初始化程序（自举程序）来完成初始化</li><li>ROM中存放很小的自举装入程序，ROM(只读存储器）中的数据在出厂时就写入了，并且以后不能再修改</li><li>完整的自举程序存放在初始块（引导块/启动分区）上，启动分区位于磁盘的固定位置，拥有启动分区的磁盘为系统磁盘或启动磁盘</li><li>开机时计算机先运行“自举装入程序”，通过执行该程序就可找到引导块，并将完整的“自举程序”读入内存，完成初始化</li></ul></li><li>坏块管理<ul><li>简单的磁盘：逻辑格式化时对整个磁盘进行坏块检查，将坏块标记出来；<br>如在FAT表上标明。（在这种方式中，坏块对操作系统不透明）</li><li>复杂的磁盘：磁盘控制器维护一个坏块链，在磁盘出厂前进行低级格式化（物理格式化）时就将坏块链进行初始化<br>并会保留一些“备用扇区”，用于替换坏块。这种方案称为扇区备用。且这种处理方式中，坏块对操作系统透明。</li></ul></li></ul><h4 id="3-磁盘调度算法（♚）"><a href="#3-磁盘调度算法（♚）" class="headerlink" title="3.磁盘调度算法（♚）"></a>3.磁盘调度算法（♚）</h4><ul><li>一次读/写操作需要的时间<ul><li>寻道（找）时间${\mathrm{T}_{\mathrm{S}}}$: 在读/写数据前, <strong>将磁头移动到指定磁道所花的时间</strong>。<ul><li>启动磁头臂是需要时间的。假设耗时为${s}$;</li><li><strong>移动磁头也是需要时间的。假设磁头匀速移动, 每跨越一 个磁道耗时为${m}$, 总共需要跨越${n}$条磁道。则:</strong><br><strong>寻道时间${T_{s}=s+m * n}$</strong></li><li>现在的硬盘移动一个磁道大约需要0.2ms,磁臂启动时间约为2ms</li><li>寻道时间在所有时间中，寻道时间需要移动磁臂，所占用的时间最长</li></ul></li><li>延迟时间${\mathrm{T}_{\mathrm{R}}}$: 通过旋转磁盘, <strong>使磁头定位到目标扇区所需要的时间</strong>。<ul><li><strong>设磁盘转速为${r}$(单位: 转/秒, 或转/分), 则平均所需的延迟时间${T_{R}=(1 / 2) *(1 / r)=1 / 2 r}$</strong></li><li>1/r就是转一圈需要的时间。找到目标扇区平均需要转半圈，因此再乘以1/2</li><li>硬盘的典型转速为5400转/分，或7200转/分</li></ul></li><li>传输时间${\mathrm{T}_{\mathrm{t}}}$: <strong>从磁盘读出或向磁盘写入数据所经历的时间</strong><ul><li><strong>设磁盘转速为${r}$，此次读/写的字节数为${b}$，每个磁道上的字节数为${\mathrm{N}}$。则传输时间${T_{t}=(1 / r) *(b / N)=b /(r N)}$</strong></li><li>每个磁道要可存N字节的数据，因此b字节的数据需要b/N个磁道才能存储。而读/写一个磁道所需的时间刚好又是转一圈所需要的时间1/r</li></ul></li><li>注意事项<ul><li><strong>寻道时间主要受磁盘调度算法的影响</strong></li><li><strong>延迟时间受到磁盘空闲空间分配程序以及文件的物理结构的影响</strong></li><li><strong>扇区数据的处理时间对旋转延迟有影响但是影响不大。</strong></li></ul></li></ul></li><li>磁盘调度算法（最优化传输时间）<ul><li>先来先服务(FCFS)<ul><li>根据进程请求访问磁盘的先后顺序进行调度。</li><li>优点：公平；如果请求访问的磁道比较集中的话，算法性能还算过的去</li><li>缺点：如果有大量进程竞争使用磁盘，请求访问的破道很分散，则FCFS在性能上很差，寻道时间长。</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNQCE8.png" alt="pPNQCE8.png"></li></ul></li></ul></li><li>最短寻找时间优先(SSTF)<ul><li>SSTF算法会优先处理的磁道是与当前磁头最近的磁道。可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短。(其实就是贪心算法的思想，只是选择眼前最优，但是总体未必最优)</li><li>优点：性能较好，平均寻道时间短</li><li>缺点：<strong>可能产生“饥饿”现象</strong>，磁头有可能在一个小区域内来回来去地移动</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNQNb6.png" alt="pPNQNb6.png"></li></ul></li></ul></li><li>扫描算法(SCAN)<ul><li>解决饥饿问题：只有磁头移动到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。这就是扫描算法(SCAN)的思想。由于磁头移动的方式很像电梯，因此也叫<strong>电梯算法</strong>。（<strong>移动时，只有到了最边上的磁道才能改变磁头移动方向</strong>）</li><li><strong>优点：性能较好，平均寻道时间较短，不会产生饥饿现象</strong></li><li>缺点<ul><li><strong>①只有到达最边上的磁道时才能改变磁头移动方向；</strong><br><strong>事实上，处理了184号磁道的访问请求之后就不需要再往右移动磁头了。</strong></li><li><strong>②SCAN算法对于各个位置磁道的响应频率不平均</strong></li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNlkdK.png" alt="pPNlkdK.png"></li></ul></li></ul></li><li>LOOK调度算法<ul><li><strong>还是要向一个边上移动，但是不用移动到底</strong>，如果在磁头移动方向上已经<strong>没有别的请求，就可以立即改变磁头移动方向</strong>。(边移动边观察，因此叫LOOK)，解决扫描算法非要移动到最边上的问题</li><li>优点：比起SCAN算法来，不需要每次都移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短</li><li>缺点：未解决响应不均衡的问题</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNl2l9.png" alt="pPNl2l9.png"></li></ul></li></ul></li><li>C-SCAN算法<ul><li>规定只有磁头朝某个特定方向移动时才处理磁道访问请求，而返回时<strong>直接快速移动至起始端</strong>而不处理任何请求。<br>解决对于各个位置磁道的响应频率不平均</li><li>优点：比起SCAN来，对于各个位置磁道的响应频率很平均。</li><li>缺点：只有到达最边上的磁道时才能改变磁头移动方向，另外，比起SCAN算法来，平均寻道时间更长。</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNl5TK.png" alt="pPNl5TK.png"></li></ul></li></ul></li><li>C-LOOK算法<ul><li>如果磁头移动的方向上已经没有磁道访问请求了，就可以立即让磁头返回，磁头只需要返回到<strong>最靠近边缘的并且需要访问的磁道上即可</strong></li><li>优点：比起C-SCAN算法来，不需要每次都移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNlbSH.png" alt="pPNlbSH.png"></li></ul></li></ul></li></ul></li><li>减少延迟时间的方法<ul><li>关于延迟时间的产生<ul><li><strong>假设要连续读取几个相邻扇区：磁头读取一块的内容后，需要一小段时间处理，而盘片又在不停地旋转</strong><br>因此，如果扇区相邻着排列，则读完1号扇区后无法连续不断地读入2号扇区，必须等盘片继续旋转，2号扇区再次划过磁头，才能完成扇区读入</li><li>结论：<strong>磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，则读入几个连续的逻辑扇区，可能需要很长的延迟时间</strong></li></ul></li><li>磁盘地址结构的设计<ul><li>为什么？磁盘的物理地址是(柱面号，盘面号，扇区号)，而不是(盘面号，柱面号，扇区号)</li><li>答：读取地址连续的磁盘块时，采用（柱面号盘面号，扇区号）的地址结构可以<strong>减少磁头移动消耗的时间</strong></li></ul></li><li>两种方法（使<strong>读取连续的逻辑扇区</strong>所需要的延迟时间更小）<ul><li>交替编号：让编号相邻的扇区在物理上不相邻</li><li>错位命名：让相邻盘面的扇区编号“错位”</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNJSDs.png" alt="pPNJSDs.png"></li></ul></li></ul></li></ul></li><li><p>例题</p><ul><li><p>例1</p><ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNDMOf.png" alt="pPNDMOf.png"></li></ul></li><li><p>例2</p><ul><li>此时转1圈需要60/3000秒，每个扇区的时间再除以10，选C<br><img src="https://s1.ax1x.com/2023/08/26/pPNDGkQ.png" alt="pPNDGkQ.png"></li></ul></li></ul></li></ul><h4 id="4-固态磁盘（SSD）"><a href="#4-固态磁盘（SSD）" class="headerlink" title="4.固态磁盘（SSD）"></a>4.固态磁盘（SSD）</h4><ul><li>原理：基于闪存技术Flash Memory，属于电可擦除ROM，即EEPROM</li><li>组成<ul><li>闪存翻译层：负责翻译逻辑块号，找到对应页(Page)</li><li>存储介质：包含多个闪存芯片(Flash Chip)，每个芯片包含多个块(block)，每个块包含多个页(page)</li></ul></li><li>读写性能特征<ul><li><strong>以页(page)为单位读/写：相当于磁盘的”扇区”</strong></li><li><strong>以块(bock)为单位”擦除”：擦干净的块，其中的每页都可以写一次，读无限次</strong></li><li>支持随机访问，系统给定一个逻辑地址，闪存翻译层可通过电路迅速定位到对应的物理地址</li><li><strong>读快、写慢。要写的页如果有数据，则不能写入，需要将块内其他页全部复制到一个新的（擦除过的）块中，再写入新的页</strong></li></ul></li><li>与机械硬盘相比的特点<ul><li>SSD读写速度快，<strong>随机访问性能高</strong>，用电路控制访问位置；<br>机械硬盘通过移动磁臂旋转磁盘控制访问位置，有寻道时间和旋转延迟</li><li>SSD安静无噪音、耐摔抗震、能耗低、造价更贵</li><li><strong>SSD的一个”块”被擦除次数过多（重复写同一个块）可能会坏掉，而机械硬盘的扇区不会因为写的次数太多而坏掉</strong></li></ul></li><li>磨损均衡技术<ul><li>思想：将“擦除”平均分布在各个块上，以提升使用寿命</li><li>动态磨损均衡：写入数据时，优先选择累计擦除次数少的新闪存块</li><li>静态磨损均衡：SSD监测并自动进行数据分配、迁移，让老旧的闪存块承担以读为主的储存任务，让较新的闪存块承担更多的写任务（<strong>更优秀</strong>）</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/26/pPNM9fJ.png" alt="pPNM9fJ.png"></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;操作系统第五章-输入-输出（I-O）管理&quot;&gt;&lt;a href=&quot;#操作系统第五章-输入-输出（I-O）管理&quot; class=&quot;headerlink&quot; title=&quot;操作系统第五章 输入/输出（I/O）管理&quot;&gt;&lt;/a&gt;操作系统第五章 输入/输出（I/O）管理&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;计算机学科基础：操作系统第五章输入/输出(I/O)管理的学习笔记&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="计算机基础学习笔记" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>操作系统第四章-文件管理</title>
    <link href="http://example.com/2024/08/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/"/>
    <id>http://example.com/2024/08/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</id>
    <published>2024-08-11T17:33:29.000Z</published>
    <updated>2024-08-12T03:28:31.006Z</updated>
    
    <content type="html"><![CDATA[<h2 id="操作系统第四章-文件管理"><a href="#操作系统第四章-文件管理" class="headerlink" title="操作系统第四章 文件管理"></a>操作系统第四章 文件管理</h2><blockquote><p>计算机学科基础：操作系统第四章文件管理的学习笔记</p></blockquote><span id="more"></span><h3 id="一-文件系统基础（✪）"><a href="#一-文件系统基础（✪）" class="headerlink" title="一.文件系统基础（✪）"></a>一.文件系统基础（✪）</h3><h4 id="1-文件控制块（FCB）和索引结点"><a href="#1-文件控制块（FCB）和索引结点" class="headerlink" title="1.文件控制块（FCB）和索引结点"></a>1.文件控制块（FCB）和索引结点</h4><ul><li><p>文件的概念：以硬盘为载体的存储在计算机上的信息集合</p></li><li><p>FCB（目录项）</p><ul><li><p>定义：一个文件对应一个FCB，一个FCB就是一个目录项；文件系统在创建文件时，建立一个文件目录项；多个FCB组成文件目录</p></li><li><p>FCB的组成</p><ul><li>文件的基本信息（文件名、物理地址、逻辑结构、物理结构等）<ul><li>FCB实现了文件名和文件之间的映射。使用户（用户程序）可以实现“按名存取“</li></ul></li><li>存取控制信息（是否可读/可写、禁止访问的用户名单等）</li><li>使用信息(如文件的建立时间、修改时间等)</li></ul></li></ul></li><li><p>索引结点（FCB的瘦身策略，iNode）</p><ul><li><strong>除了文件名之外的所有信息都放到索引结点中，每个文件对应一个索引结点，简称i结点</strong><br><strong>目录项中只包含文件名、索引结点指针，因此每个目录项的长度大幅减小</strong></li><li><strong>由于目录项长度减小，因此每个磁盘块可以存放更多个目录项，因此检索文件时磁盘I/O的次数就少了很多</strong></li><li><strong>当找到文件名对应的目录项时，才需要将索引结点调入内存，索引结点中记录了文件的各种信息，包括文件在外存中的存放位置，根据“存放位置”即可找到文件。</strong></li><li><strong>存放在外存中的索引结点称为“磁盘索引结点”，当索引结点放入内存后称为“内存/活动索引结点”</strong><br>相比之下内存索引结点中需要增加一些信息，比如：文件是否被修改、此时有几个进程正在访问该文件</li><li>文件的打开过程描述<ul><li>①检索目录，要求打开的文件应该是已经创建的文件，它应登记在文件目录中，否则会出错。<br>在检索到指定文件后，就将其磁盘Node复制到活动iNode表中。</li><li>②把参数mode所给出的打开方式与活动iNode中在创建文件时所记录的文件访问权限相比较，如果合法，则此次打开操作成功。</li><li>③当打开合法时，为文件分配用户打开文件表表项和系统打开文件表表项，并为后者设置初值，<br>通过指针建立表项与活动Node之间的联系，再把文件描述符fd返回给调用者。</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYZtTs.png" alt="pPYZtTs.png"></li></ul></li></ul></li></ul><h4 id="2-目录的结构（一种特殊的文件）"><a href="#2-目录的结构（一种特殊的文件）" class="headerlink" title="2.目录的结构（一种特殊的文件）"></a>2.目录的结构（一种特殊的文件）</h4><ul><li>单级目录结构：一个系统只有一张目录表，<strong>不允许文件重名</strong></li><li>两级目录结构<ul><li>分为主文件目录和用户文件目录<ul><li>主文件目录记录用户名及相应用户文件目录的存放位置</li><li>用户文件目录由该用户的文件FCB组成</li></ul></li><li><strong>不同用户的文件可以重名，但不能对文件进行分类</strong></li></ul></li><li>树形目录结构<ul><li><strong>不同目录下的文件可以重名，可以对文件进行分类，不方便文件共享</strong></li><li>系统根据”文件路径”找到目标文件</li><li>从根目录出发的路径是“绝对路径”，<br>从”当前目录出发的路径是相对路径”，可以减少磁盘I/O次数</li></ul></li><li>无环图目录结构<ul><li>在树形目录结构的基础上，增加一些指向同一节点的有向边，使整个目录成为一个有向无环图<br><strong>可以更方便地实现多个用户间的文件共享</strong>。</li><li>为共享结点设置一个共享计数器，计数器为0时才真正删除该结点</li><li>共享文件不同于复制文件。在共享文件中，由于各用户指向的是同一个文件，因此只要其中一个用户修改了文件数据，那么所有用户都可以看到文件数据的变化。</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJ7FHA.png" alt="pPJ7FHA.png"></li></ul></li></ul></li></ul><h4 id="3-文件的逻辑结构"><a href="#3-文件的逻辑结构" class="headerlink" title="3.文件的逻辑结构"></a>3.文件的逻辑结构</h4><ul><li>逻辑结构：在用户看来文件内部的数据应该是如何组织起来的。</li><li>无结构文件（流式文件）<ul><li>文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”。如：Windows操作系统中的txt文件</li></ul></li><li>有结构文件（记录式文件）<ul><li>定义<ul><li>由一组相似的记录组成，又称“记录式文件”。每条记录又若干个数据项组成。如：数据库表文件。</li><li><strong>一般来说，每条记录有一个数据项可作为关键字</strong>。</li><li>根据各条记录的长度（占用的存储空间）是否相等，又可分为定长记录和可变长记录两种。</li></ul></li><li>分类（逻辑上如何组织）<ul><li>顺序文件<ul><li>定义：文件中的记录一个接一个地顺序排列（逻辑上），记录可以是定长的或可变长的。<strong>各个记录在物理上可以顺序存储或链式存储。</strong></li><li>两种结构<ul><li>串结构：记录之间的顺序与关键字无关</li><li>顺序结构：记录之间的顺序按关键字顺序排列</li></ul></li><li><strong>可变长记录的顺序文件无法实现随机存取，定长记录的顺序存储方式可以</strong></li><li><strong>定长记录、顺序结构的顺序文件可以快速检索（根据关键字快速找到记录）</strong></li><li>最大缺点：不方便增加/删除记录</li></ul></li><li>索引文件<ul><li>建立一张索引表，每个记录对应一个表项。各记录不用保持顺序，方便增加/删除记录</li><li>索引表本身就是定长记录的顺序文件，一个索引表项就是一条定长记录，<strong>因此索引文件可支持随机存取</strong></li><li><strong>若索引表按关键字顺序排列，则可支持快速检索</strong></li><li><strong>解决了顺序文件不方便增/删记录的问题，同时让不定长记录的文件实现了随机存取。但索引表可能占用很多空间</strong></li></ul></li><li>索引顺序文件<ul><li>将记录分组，每组对应一个索引表项</li><li>检索记录时先顺序查索引表，找到分组，再顺序查找分组</li><li>当记录过多时，可建立多级索引表</li><li><strong>当只有一级索引号时，对于n个记录最好的分组记录为：$分为\sqrt{n}组,每组\sqrt{n}个记录$，此时平均查询次数为$\sqrt{n}/2*2$</strong><ul><li>若要为N个记录的文件建立K级索引，则最优的分组是每组$N^{\frac{1}{K+1}}$个记录（一般）采用一级索引即可k=1</li><li>检索一个记录的平均查找次数是$N^{\frac{1}{K+1}}/2*(K+1)$</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJzaJH.png" alt="pPJzaJH.png"></li></ul></li></ul></li></ul></li></ul></li><li>例题<ul><li>本题可以看做是只有一张索引表，此时的查找记录最少时为$\sqrt{10000}/2*2=100$，此时为D<br><img src="https://s1.ax1x.com/2023/08/23/pPYUNWT.png" alt="pPYUNWT.png"></li></ul></li></ul><h4 id="4-文件的物理结构（♚）"><a href="#4-文件的物理结构（♚）" class="headerlink" title="4.文件的物理结构（♚）"></a>4.文件的物理结构（♚）</h4><ul><li><p>磁盘块</p><ul><li>在内存管理中，进程的逻辑地址空间被分为一个一个页面，在外存管理中，文件的逻辑地址空间也被分为了一个一个的文件“块”<br>很多操作系统中，磁盘块的大小与内存块、页面的大小相同</li><li>内存与磁盘之间的数据交换（即读/写操作、磁盘I/O)都是以块”为单位进行的。即每次读入一块，或每次写出一块</li><li>文件的逻辑地址也可以表示为(逻辑块号，块内地址)的形式。</li><li>操作系统为文件分配存储空间都是以块为单位的，用户通过逻辑地址来操作自己的文件，操作系统要负责实现从逻辑地址到物理地址的映射</li></ul></li><li><p>文件的分配方式（<strong>对非空闲磁盘块的管理，实现逻辑地址到物理地址的映射</strong>）</p><ul><li>连续分配<ul><li><strong>连续分配方式要求每个文件在磁盘上占有一组连续的块。</strong></li><li><strong>文件目录中记录存放的起始块号和长度（总共占用几个块）</strong><ul><li>给出要访问的逻辑块号，操作系统找到该文件对应的目录项(FCB)，物理块号=起始块号+逻辑块号</li><li>只需转换块号就行，块内地址保持不变，此时可实现到物理块号的映射</li></ul></li><li><strong>连续分配支持顺序访问和直接访问（即随机访问）</strong><ul><li>读取某个磁盘块时，需要移动磁头。访问的两个磁盘块相隔越远，移动磁头所需时间就越长。</li><li>连续分配的文件在顺序读/写时速度最快</li></ul></li><li><strong>缺点：不方便文件拓展：存储空间利用率低，会产生磁盘碎片</strong><br>可以用紧凑来处理碎片，但是需要耗费很大的时间代价。</li></ul></li><li>链接分配（离散分配）<ul><li>隐式链接<ul><li><strong>除了文件的最后一个磁盘块之外，每个磁盘块中都会保存指向下一个盘块的指针，这些指针对用户是透明的</strong></li><li><strong>目录中记录了文件存放的起始块号和结束块号</strong>。也可以增加一个字段来表示文件的长度<ul><li>操作系统找到该文件对应的目录项(FCB)，从目录项中找到起始块号(即0号块)，将0号逻辑块读入内存，<br>由此知道1号逻辑块存放的物理块号，以此类推，读入i号逻辑块总共需要$i+1$次磁盘I/O</li></ul></li><li>优点：<strong>很方便文件拓展，不会有碎片问题，外存利用率高</strong>。<ul><li>若此时要拓展文件，则可以随便找一个空闲磁盘块，挂到文件的磁盘块链尾，并修改文件的FCB</li></ul></li><li>缺点：<strong>只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间。</strong></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJbo1f.png" alt="pPJbo1f.png"></li></ul></li></ul></li><li>显式链接<ul><li><strong>目录中只需记录文件的起始块号，把用于链接文件各物理块的指针显式地存放在一张表中，即文件分配表（FAT）</strong><ul><li>FAT的各个表项在物理上连续存储，且每一个表项长度相同，因此“物理块号”字段可以是隐含的</li><li><strong>逻辑块号转换成物理块号的过程不需要读磁盘操作</strong><ul><li>用户给出要访问的逻辑块号ⅰ，操作系统找到该文件对应的目录项 (FCB)，从目录项中找到起始块号，<br>之后查询内存中的文件分配表FAT，往后找到ⅰ号逻辑块对应的物理块号。</li></ul></li></ul></li><li><strong>一个磁盘仅设置一张FAT，开机时，将FAT读入内存，并常驻内存</strong>。</li><li>FAT不仅记录了文件中各个块的先后链接顺序，同时还标记了空闲的磁盘块，操作系统可以通过FAT对文件空闲存储空间实现管理</li><li>优点<ul><li><strong>采用链式分配（显式链接）方式的文件，支持顺序访问，也支持随机访问</strong></li><li><strong>由于块号转换的过程不需要访问磁盘，因此相比于隐式链接来说，访问速度快很多</strong>。</li><li><strong>显式链接也不会产生外部碎片，也可以很方便地对文件进行拓展，外存利用率高</strong></li></ul></li><li>缺点：文件分配表的需要占用一定的存储空间</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJqxVH.png" alt="pPJqxVH.png"></li></ul></li></ul></li></ul></li><li>索引分配（离散分配）<ul><li>索引表<ul><li><strong>系统会为每个文件建立一张索引表，一张索引表的每个索引表项记录了文件的各个逻辑块对应的物理块，索引表中的“逻辑块号”可以是隐含的。</strong></li><li><strong>索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块；目录需要记录文件名和其对应的索引块</strong></li><li><strong>索引表的功能类似于内存管理中的页表：建立逻辑页面到物理页之间的映射关系</strong><ul><li>用户给出要访问的逻辑块号ⅰ，操作系统找到该文件对应的目录项(FCB)，从目录项中可知索引表存放位置，<strong>将索引表从外存读入内存，并查找索引表即可知道ⅰ号逻辑块在外存中的存放位置</strong></li></ul></li><li>优点：<strong>索引分配方式可以支持随机访问，文件拓展也很容易实现</strong>，需要给文件分配一个空闲块，并增加一个索引表项</li><li>缺点：但是索引表需要占用一定的存储空间</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJOFYR.png" alt="pPJOFYR.png"></li></ul></li></ul></li><li>解决由于文件太大导致，一个磁盘块装不下此文件索引表的问题<ul><li>链接方案：如果索引表太大，一个索引块装不下，那么可以将多个索引块链接起来存放，需要很多的I/O操作，太低效</li><li>多层索引<ul><li>原理类似于多级页表，使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。</li><li>若采用多层索引，则各层索引表大小不能超过一个磁盘块</li><li><strong>采用K层索引结构，且顶级索引表未调入内存，则访问一个数据块只需要K+1次读磁盘操作</strong></li><li><strong>文件的最大长度：$最多存放索引项个数^{k}*磁盘块大小$</strong></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJx3VS.png" alt="pPJx3VS.png"></li></ul></li><li>缺点：即使是小文件，访问一个数据块依然需要K+1次读磁盘。</li></ul></li><li>混合索引<ul><li>多种索引分配方式的结合。例如，一个文件的顶级索引表中，既包含直接地址索引（直接指向数据块），又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表）</li><li>对于小文件，只需较少的读磁盘次数就可以访问目标数据块（一般计算机中小文件更多）</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPJxDVU.png" alt="pPJxDVU.png"></li></ul></li></ul></li></ul></li></ul></li><li><p>三种外存分配方式的区别</p><ul><li>连续分配：需访问磁盘1次</li><li>链接分配：需访问磁盘n次</li><li>索引分配：m级需访问磁盘m+1次</li><li><img src="https://s1.ax1x.com/2023/08/23/pPJxoIe.png" alt="pPJxoIe.png"></li></ul></li><li><p>例题</p><ul><li>例1：此时最大长度直接套公式计算：1KB/4=$2^8$个项，此时最大长度为${2^{8<em>2}}$</em>1KB=64MB<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYaeB9.png" alt="pPYaeB9.png"></li></ul></li><li>例2：若此题的磁盘块没有读入内存，还需要分别加1(读入索引结点)，此时选D<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYahCV.png" alt="pPYahCV.png"></li></ul></li></ul></li></ul><h4 id="5-文件的操作"><a href="#5-文件的操作" class="headerlink" title="5.文件的操作"></a>5.文件的操作</h4><ul><li><p>文件描述符（即索引号）</p><ul><li><strong>打开文件时，将目录项中的信息复制到内存中的打开文件表中，并将打开文件表的索引号返回给用户进程</strong><br><strong>“索引号”也称“文件描述符”</strong></li><li><strong>打开文件时并不会把文件数据直接读入内存，读数据时才需要读入内存，写数据时需要写出外存。</strong></li><li><strong>读/写文件时用“文件描述符”即可指明文件，不再需要用到文件名</strong></li></ul></li><li><p>创建文件(create系统调用)</p><ul><li>分配外存空间<ul><li>利用空闲链表法、位示图、成组链接法等管理策略，在外存中找到空闲空间</li></ul></li><li>在目录中创建目录项<ul><li>目录项中包含了文件名、文件在外存中的存放位置等信息。</li></ul></li></ul></li><li>删除文件(delete系统调用)<ul><li>回收外存空间<ul><li>回收磁盘块时，根据空闲表法、空闲链表法、位图法等管理策略的不同，需要做不同的处理</li></ul></li><li>从目录表中删除文件对应的目录项</li></ul></li><li>打开文件(open系统调用)<ul><li>过程<ul><li>从目录中找到文件名对应的的目录项，并检查该用户是否有指定的操作权限。</li><li><strong>将目录项中的信息复制到内存中的打开文件表中，并将打开文件表的索引号返回给用户</strong><ul><li>打开文件时并不会把文件数据直接读入内存。“索引号”也称“文件描述符”</li></ul></li><li><strong>打开文件之后，对文件的操作不再需要每次都查询目录，可以根据内存中的打开文件表进行操作</strong></li><li>每个进程有自己的打开文件表，系统中也有一张总的打开文件表<ul><li>进程打开文件表中特有的属性：读写指针、访问权限(只读？读写？)</li><li>系统打开文件表中特有的属性：打开计数器（有多少个进程打开了该文件）</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYkxeA.png" alt="pPYkxeA.png"></li></ul></li></ul></li><li>关于打开文件表（注意用户打开文件表的读写指针和访问权限以及系统打开文件表的打开计数器）<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYAPW8.png" alt="pPYAPW8.png"></li></ul></li></ul></li><li>关闭文件(close系统调用)<ul><li>将用户进程的打开文件表相应表项删除</li><li>回收分配给该文件的内存空间等资源</li><li>系统打开文件表的打开计数器count减1，若count=0，则删除对应表项。</li></ul></li><li>读文件(read系统调用)<ul><li><strong>根据读指针、读入数据量、内存位置等信息将文件数据从外存读入内存</strong></li><li>将文件数据读入内存，才能让CPU处理，双击后，应用程序通过read系统调用，将文件数据从外存读入内存，并显示在屏幕上（必须要打开文件之后）</li><li><strong>读/写文件“文件描述符”即可指明文件不再需要用到“文件名</strong></li></ul></li><li>写文件(write系统调用)<ul><li>根据写指针、写出数据量、内存位置将文件数据从内存写出外存</li><li>点击“保存”后，应用程序通过write系统调用，将文件数据从内存写回外存</li></ul></li></ul><h4 id="6-文件的保护"><a href="#6-文件的保护" class="headerlink" title="6.文件的保护"></a>6.文件的保护</h4><ul><li><p>口令保护</p><ul><li>为文件设置一个“口令”，用户想要访问文件时需要提供口令，由系统验证口令是否正确</li><li>实现开销小，但“口令”一般存放在FCB或索引结点中（也就是存放在系统中）因此不太安全</li></ul></li><li><p>加密保护</p><ul><li>用一个“密码”对文件加密，用户想要访问文件时，需要提供相同的“密码”才能正确的解密</li><li>安全性高，但加密/解密需要耗费一定的时间 (如异或加密)</li></ul></li><li>访问控制<ul><li>在每个文件的FCB（或索引结点）中增加一个访问控制表(ACL)，记录各个用户（或各组用户）对文件的访问权限<br>对文件的访问类型可以分为：读/写/执行/删除等</li><li>精简的访问列表：以“组”为单位，标记各“组”用户可以对文件执行哪些操作，系统需要管理分组的信息<ul><li>如：分为系统管理员、文件主、文件主的伙伴、其他用户几个分组。</li><li>当某用户想要访问文件时，系统会检查该用户所属的分组是否有相应的访问权限。</li><li>若想要让某个用户能够读取文件，只需要把该用户放入文件主的伙伴这个分组即可</li></ul></li><li>实现灵活，可以实现复杂的文件保护功能</li></ul></li></ul><h4 id="7-文件共享"><a href="#7-文件共享" class="headerlink" title="7.文件共享"></a>7.文件共享</h4><ul><li><p>文件共享与文件复制的区别</p><ul><li>操作系统为用户提供文件共享功能，可以让多个用户共享地使用同一个文件</li><li>多个用户共享同一个文件，意味着系统中只有“一份”文件数据。并且只要某个用户修改了该文件的数据，其他用户也可以看到文件数据的变化。</li><li>如果是多个用户都“复制”了同一个文件，那么系统中会有“好几份”文件数据。其中一个用户修改了自己的那份文件数据，对其他用户的文件数据并没有影响。</li></ul></li><li><p><strong>基于索引结点的共享方式（硬链接）</strong></p><ul><li>各个用户的目录项指向同一个索引结点，索引结点中需要有链接计数count，用于表示链接到本索引结点上的用户目录项数<br>若cout=2，说明此时有两个用户目录项链接到该索引结点上，或者说是有两个用户在共享此文件</li><li>若某个用户决定“删除”该文件，则只是要把用户目录中与该文件对应的目录项删除，且索引结点的count值减1.<ul><li>若cout&gt;0,说明还有别的用户要使用该文件，暂时不能把文件数据删除，否则会导致指针悬空。</li><li>当count=0时系统负责删除文件。</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYe7vT.png" alt="pPYe7vT.png"></li></ul></li></ul></li><li><strong>基于符号链的共享方式（软链接）</strong><ul><li><strong>在一个Link型的文件中记录共享文件的存放路径(Windows快捷方式)</strong></li><li>操作系统根据路径一层层查找目录，最终找到共享文件即使软链接指向的共享文件已被删除，Link型文件依然存在，<br>只是通过Link型文件中的路径去查找共享文件会失败（找不到对应目录项）</li><li><strong>由于用软链接的方式访问共享文件时要查询多级目录，会有多次磁盘I/O，因此用软链接访问共享文件的速度要比硬链接更慢</strong></li></ul></li><li>例题<ul><li>例1：此时新创建硬链接的文件的索引节点指向F1的索引结点，删除F1后其技术值变为1，软链接的计数值不变，即选B<br><img src="https://s1.ax1x.com/2023/08/23/pPYwWlT.png" alt="pPYwWlT.png"></li></ul></li></ul></li></ul><h3 id="二-文件系统（✪）"><a href="#二-文件系统（✪）" class="headerlink" title="二.文件系统（✪）"></a>二.文件系统（✪）</h3><h4 id="1-文件系统布局"><a href="#1-文件系统布局" class="headerlink" title="1.文件系统布局"></a>1.文件系统布局</h4><ul><li>文件系统的概述<ul><li><strong>操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统</strong></li><li>文件系统由三部分组成：与文件管理有关的软件、被管理文件及实施文件管理所需的数据结构。</li><li>文件系统的功能<ul><li>对于用户而言，文件系统最主要的功能是实现对文件的基本操作，<br><strong>让用户可以按名存储和查找文件</strong>，组织成合适的结构，并应当具有基本的文件共享和文件保护功能。</li><li>从系统角度看，文件系统负责对文件的存储空间进行组织、分配；负责文件的存储并对存入文件进行保护、检索。</li></ul></li></ul></li><li>文件系统在磁盘中的结构<ul><li>磁盘的物理格式化：即低级格式化，划分扇区，检测坏扇区，并用备用扇区替换坏扇区</li><li>磁盘的逻辑格式化：磁盘分区(分卷Volume)后，对各分区进行逻辑格式化，完成文件系统初始化</li><li>文件系统在磁盘中的组成<ul><li>主引导记录(MBR)<ul><li>位于磁盘的0号扇区，用来引导计算机，MBR后面是分区表，该表给出每个分区的起始和结束地址。</li><li>表中的一个分区被标记为活动分区，当计算机启动时，BIOS读入并执行MBR，MBR做的第一件事是确定活动分区，读<br>入它的第一块，即引导块。</li></ul></li><li>引导块<ul><li><strong>MBR执行引导块中的程序后，该程序负责启动该分区中的操作系统</strong>。为统一起见，每个分区都从一个引导块开始。Windows系统称之为分区引导扇区。</li></ul></li><li>超级块<ul><li><strong>包含文件系统的所有关键信息，在计算机启动时，或者在该文件系统首次使用时，超级块会被读入内存</strong>。</li><li>超级块中的典型信息包括分区的块的数量、块的大小、空闲块的数量和指针、空闲的FCB数量和FCB指针等。</li></ul></li><li>其它组成<ul><li>文件系统中空闲块的信息，可以使用位示图或指针链接的形式给出。</li><li>后面也许跟的是一组i结点，每个文件对应一个结点，ⅰ结点说明了文件的方方面面。</li><li>接着可能是根目录，它存放文件系统目录树的根部。最后，磁盘的其他部分存放了其他所有的目录和文件。</li></ul></li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/24/pPYhUy9.png" alt="pPYhUy9.png"></li></ul></li></ul></li><li>文件系统在内存中的结构<ul><li>近期访问过的目录文件会缓存在内存中，不用每次都从磁盘读入，这样可以加快目录检索速度</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/24/pPY58v4.png" alt="pPY58v4.png"></li></ul></li></ul></li><li>文件系统的层次结构（了解）<ul><li><img src="https://s21.ax1x.com/2024/08/12/pApQybF.png" alt="pApQybF.png"></li></ul></li></ul><h4 id="2-外存空闲空间管理（♚）"><a href="#2-外存空闲空间管理（♚）" class="headerlink" title="2.外存空闲空间管理（♚）"></a>2.外存空闲空间管理（♚）</h4><ul><li><p>存储空间的划分与初始化</p><ul><li>包含文件系统的物理磁盘分区被称为卷（逻辑卷、逻辑盘）C盘、D盘……</li><li>存储空间的初始化：将各个文件卷划分为目录区、文件区<ul><li>目录区主要存放文件目录信息(FCB)、用于磁盘存储空间管理的信息</li><li>文件区用于存放文件数据</li></ul></li><li>有的系统支持超大型文件，可支持由多个物理磁盘组成一个文件卷</li></ul></li><li><p>存储空间管理（对空闲块的组织、分配与回收）</p><ul><li><p>空闲表法（连续分配方式）</p><ul><li>与内存的动态分配相似，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表<br>每个空闲区对应一个空闲表项，包括表项序号，空闲区的第一个盘块号，空闲盘块数，再以起始盘块号递增的次序排列</li><li>分配磁盘块：与内存管理中的动态分区分配很类似，为一个文件分配连续的存储空间，同样可采用首次适应、最佳适应、最坏适应等算法来决定要为文件分配哪个区间。</li><li>回收磁盘块：与内存管理中的动态分区分配很类似，回收时需要注意表项的合并问题。</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYiJeI.png" alt="pPYiJeI.png"></li></ul></li></ul></li><li><p>空闲链表法</p><ul><li>空闲盘块链（适用于离散分配）<ul><li>以盘块为单位组成一条空闲链，空闲盘块中存储着下一个空闲盘块的指针<br>操作系统保存着链头、链尾指针。</li><li>分配磁盘块：若某文件申请K个盘块，则从链头开始依次摘下K个盘块分配，并修改空闲链的链头指针。</li><li>回收磁盘块：回收的盘块依次挂到链尾，并修改空闲链的链尾指针。</li><li>为文件分配多个盘块时可能要重复多次操作</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYi6wq.png" alt="pPYi6wq.png"></li></ul></li></ul></li><li>空闲盘区链（离散分配、连续分配都适用）<ul><li>以盘区为单位组成一条空闲链；连续的空闲盘块组成一个空闲盘区；空闲盘区中的第一个盘块内记录了盘区的长度、下一个盘区的指针；操作系统保存着链头、链尾指针。</li><li>分配磁盘块<ul><li>若某文件申请K个盘块，则可以采用首次适应、最佳适应等算法，从链头开始检索按照算法规则找到一个大小符合要求的空闲盘区，分配给文件</li><li>若没有合适的连续空闲块，也可以将不同盘区的盘块同时分配给一个文件，注意分配后可能要修改相应的链指针、盘区大小等数据</li></ul></li><li>回收磁盘块<ul><li>若回收区和某个空闲盘区相邻，则需要将回收区合并到空闲盘区中。</li><li>若回收区没有和任何空闲区相邻，将回收区作为单独的一个空闲盘区挂到链尾。</li></ul></li><li>为个文件分配多个盘块时效率更高</li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYdrPx.png" alt="pPYdrPx.png"></li></ul></li></ul></li></ul></li><li><p>位示图法（离散分配、连续分配都适用）</p><ul><li><p>位示图</p><ul><li><p>每个二进制位对应一个盘块。“0”代表盘块空闲，“1”代表盘块已分配。</p></li><li><p>位示图一般用连续的“字”来表示，字的字长是16位，字中的每一位对应一个盘块。<br>因此可以用（字号，位号）对应一个盘块号。</p></li><li><p>计算方法</p><ul><li><p><strong>位示图法中行和列都从1开始编号</strong></p><ul><li>(字号，位号)=(i，j) 的二进制位对应的盘块号：$b=n(i-1)+j$</li><li>b号盘块对应的字号：$i=(b-1)/n +1$，位号：$j=(b-1)\%n+1$</li></ul></li><li><p><strong>位示图法中行和列都从0开始编号</strong></p><ul><li><p>(字号，位号)=(i，j) 的二进制位对应的盘块号：$b=ni+j$</p></li><li><p>b号盘块对应的字号：$i=b/n$，位号：$j=b\%n$</p></li></ul></li></ul></li><li><p>图片</p><ul><li><img src="https://s1.ax1x.com/2023/08/23/pPYF0N6.png" alt="pPYF0N6.png"></li></ul></li></ul></li><li><p>磁盘的分配</p><ul><li>若文件需要K个块，①顺序扫描位示图，找到K个相邻或不相邻的“0”</li><li>②根据字号、位号算出对应的盘块号，将相应盘块分配给文件，并将相应位设置为“1”</li></ul></li><li><p>磁盘的回收</p><ul><li>①根据回收的盘块号计算出对应的字号、位号；②将相应二进制位设为“0”</li></ul></li></ul></li><li><p>成组链接法（了解）</p><ul><li><strong>空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大</strong>。<br>UNIX系统中采用了成组链接法对磁盘空闲块进行管理。</li><li>文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。<br>并且要保证内存与外存的“超级块”数据一致，<strong>适合大型文件系统</strong></li></ul></li></ul></li><li><p>例题</p><ul><li>盘块号${=}$起始块号${+\lfloor}$盘块号${/(1024 \times 8)\rfloor=32+\lfloor 409612 /(1024 \times 8)\rfloor=32+50=82}$, 这里问的是块内字节号而不是位号, 因此还需除以${8(1 \mathrm{B}=8}$位${)}$, 块内字节号${=\lfloor(}$盘块号${\%(1024 \times 8)) / 8\rfloor=1}$。<br><img src="https://s1.ax1x.com/2023/08/24/pPYHxKS.png" alt="pPYHxKS.png"></li></ul></li></ul><h4 id="3-虚拟文件系统-VFS-与文件系统挂载"><a href="#3-虚拟文件系统-VFS-与文件系统挂载" class="headerlink" title="3.虚拟文件系统(VFS)与文件系统挂载"></a>3.虚拟文件系统(VFS)与文件系统挂载</h4><ul><li>虚拟文件系统<ul><li>虚拟文件系统的特点<ul><li><strong>向上层用户进程提供统一标准的系统调用接口，屏蔽底层具体文件系统的实现差异</strong></li><li>VFS要求下层的文件系统必须实现某些规定的函数功能，如：open/read/write<br>一个新的文件系统想要在某操作系统上被使用，就必须满足该操作系统VFS的要求</li><li>每打开一个文件，VFS就在主存中新建一个vnode，用统一的数据结构表示文件，无论该文件存储在哪个文件系统<br><strong>vnode只存在于主存中，而inode既会被调入主存，也会在外存中存储</strong></li><li>打开文件后，即创建vnode，并将文件信息复制到vnode中，vnode的功能指针指向具体文件系统的函数功能</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/24/pPY5TMQ.png" alt="pPY5TMQ.png"></li></ul></li></ul></li><li>文件系统挂载（文件系统装载）<ul><li>挂载的过程<ul><li>在VFS中注册新挂载的文件系统。内存中的挂载表(mount table)包含每个文件系统的相关信息，包括文件系统类型、容量大小等</li><li>新挂载的文件系统，要向VFS提供一个<strong>函数地址列表</strong></li><li>将新文件系统加到挂载点(mount point)，也就是将新文件系统挂载在某个父目录下</li></ul></li><li>图片<ul><li><img src="https://s1.ax1x.com/2023/08/24/pPYIVJK.png" alt="pPYIVJK.png"></li></ul></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;操作系统第四章-文件管理&quot;&gt;&lt;a href=&quot;#操作系统第四章-文件管理&quot; class=&quot;headerlink&quot; title=&quot;操作系统第四章 文件管理&quot;&gt;&lt;/a&gt;操作系统第四章 文件管理&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;计算机学科基础：操作系统第四章文件管理的学习笔记&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="计算机基础学习笔记" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
